{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Welcome to OpsMx Documentation In this documentation, we will learn about the different products of OpsMx which helps to make your product release process smooth and hassle free. In the upcoming sections, we will learn about the installation process and also how to use the different features of the products in detail. The products are as follows: OpsMx Intelligent Software Delivery Platform Orchestration Module - OpsMx Enterprise for Spinnaker (OES) Data and Intelligence Module - Autopilot","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#welcome-to-opsmx-documentation","text":"In this documentation, we will learn about the different products of OpsMx which helps to make your product release process smooth and hassle free. In the upcoming sections, we will learn about the installation process and also how to use the different features of the products in detail. The products are as follows: OpsMx Intelligent Software Delivery Platform Orchestration Module - OpsMx Enterprise for Spinnaker (OES) Data and Intelligence Module - Autopilot","title":"Welcome to OpsMx Documentation"},{"location":"Application%20Dashboard_old/","text":"Application Dashboard The application dashboard helps you to get a complete detailed view of the applications along with its services and pipelines. In the application dashboard you can also view the environments and the gates that the service or the application passes through before final deployment. You can also view the details of the deployment. Click \"Dashboard\" and click \"Application Dashboard\" Summary View In the above dashboard, the first view is the summary view where you can see there are different applications with the following details: Total Applications - The number of services in the application Deployments - The deployment details Pending Approvals - Any approvals which are pending Policy Violations - Any policy violations Verification Failures - Any failures in verification process Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } Cloud Driver Deck API Caller Gate Orca Gate Gate Roscoe Orca Front50 Orca Cloud Driver Roscoe Cloud Driver Front50 Igor Front50 Roscoe Orca Igor Igor Cloud Driver Gate","title":"Application Dashboard old"},{"location":"Application%20Dashboard_old/#application-dashboard","text":"The application dashboard helps you to get a complete detailed view of the applications along with its services and pipelines. In the application dashboard you can also view the environments and the gates that the service or the application passes through before final deployment. You can also view the details of the deployment. Click \"Dashboard\" and click \"Application Dashboard\"","title":"Application Dashboard"},{"location":"Application%20Dashboard_old/#summary-view","text":"In the above dashboard, the first view is the summary view where you can see there are different applications with the following details: Total Applications - The number of services in the application Deployments - The deployment details Pending Approvals - Any approvals which are pending Policy Violations - Any policy violations Verification Failures - Any failures in verification process Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Total Applications - The number of services in the application Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } Cloud Driver Deck API Caller Gate Orca Gate Gate Roscoe Orca Front50 Orca Cloud Driver Roscoe Cloud Driver Front50 Igor Front50 Roscoe Orca Igor Igor Cloud Driver Gate","title":"Summary View"},{"location":"Application%20Deployment/","text":"Application Deployment Spinnaker's application deployment feature is responsible for the continuous delivery workflow. Some of the basic concepts of application deployment are: Pipeline Stage Deployment Strategies Let\u2019s discuss and learn how these concepts work. Pipeline The main deployment management constructor of Spinnaker is the pipeline. A pipeline defines a flow of actions in a particular sequence; for the code traversal, from commit all the way until it is deployed in the target deployment environment. A pipeline comprises a series of actions known as stages. You can add/modify stages to a pipeline as you define it, allowing you to pass parameters from one stage to the next along the pipeline. The image below shows an example pipeline. Stage In Spinnaker, an automatically created building block for the pipeline is known as a stage. A stage in a pipeline is used to define a specific and finite activity. Herein, You can specify an action to be performed on a specific pipeline here. You can have as many stages as you wish in a pipeline based on what actions you want to perform; for example, a stage for code build, a stage for static code analysis, a stage for code deploy, etc. Spinnaker can integrate with a large number of third third-party tools for performing the actions specified in a pipeline. For example, you can integrate Spinnaker with Jenkins, SonarQube, Terraform, Vault, test automation tools, etc. Deployment Strategies Spinnaker manages cloud-native deployment strategies as exclusive constructs, handling primary arrangements such as disabling old server groups, enabling new server groups, and verifying health checks. Spinnaker backs the red/black (also known as blue/green) strategy, with rolling red/black and canary strategies in active development. This enables the user to define the custom deployment strategy based on their organization requirements. Spinnaker supports: Blue/green (AKA Red/Black) Rolling Red/black Highlander Dark Rollout Blue/Green (AKA Red/Black): Blue/Green strategy, AKA Red/black strategy consists of creating new server groups and once the new server groups become healthy, removing the old server groups from the load balancer. Highlander: The highlander strategy consists of creating new server groups and once the new server groups become healthy the old server groups are deleted. Dark rollout (None): Dark roll outs involve doing nothing about the old server groups. Both old and new server groups stay on the load balancer. Refer to the figure below for a better understanding:","title":"Application Deployment"},{"location":"Application%20Deployment/#application-deployment","text":"Spinnaker's application deployment feature is responsible for the continuous delivery workflow. Some of the basic concepts of application deployment are: Pipeline Stage Deployment Strategies Let\u2019s discuss and learn how these concepts work.","title":"Application Deployment"},{"location":"Application%20Deployment/#pipeline","text":"The main deployment management constructor of Spinnaker is the pipeline. A pipeline defines a flow of actions in a particular sequence; for the code traversal, from commit all the way until it is deployed in the target deployment environment. A pipeline comprises a series of actions known as stages. You can add/modify stages to a pipeline as you define it, allowing you to pass parameters from one stage to the next along the pipeline. The image below shows an example pipeline.","title":"Pipeline"},{"location":"Application%20Deployment/#stage","text":"In Spinnaker, an automatically created building block for the pipeline is known as a stage. A stage in a pipeline is used to define a specific and finite activity. Herein, You can specify an action to be performed on a specific pipeline here. You can have as many stages as you wish in a pipeline based on what actions you want to perform; for example, a stage for code build, a stage for static code analysis, a stage for code deploy, etc. Spinnaker can integrate with a large number of third third-party tools for performing the actions specified in a pipeline. For example, you can integrate Spinnaker with Jenkins, SonarQube, Terraform, Vault, test automation tools, etc.","title":"Stage"},{"location":"Application%20Deployment/#deployment-strategies","text":"Spinnaker manages cloud-native deployment strategies as exclusive constructs, handling primary arrangements such as disabling old server groups, enabling new server groups, and verifying health checks. Spinnaker backs the red/black (also known as blue/green) strategy, with rolling red/black and canary strategies in active development. This enables the user to define the custom deployment strategy based on their organization requirements.","title":"Deployment Strategies"},{"location":"Application%20Deployment/#spinnaker-supports","text":"Blue/green (AKA Red/Black) Rolling Red/black Highlander Dark Rollout Blue/Green (AKA Red/Black): Blue/Green strategy, AKA Red/black strategy consists of creating new server groups and once the new server groups become healthy, removing the old server groups from the load balancer. Highlander: The highlander strategy consists of creating new server groups and once the new server groups become healthy the old server groups are deleted. Dark rollout (None): Dark roll outs involve doing nothing about the old server groups. Both old and new server groups stay on the load balancer. Refer to the figure below for a better understanding:","title":"Spinnaker supports:"},{"location":"Application%20Management/","text":"Application Management Microservices-based architecture is replacing legacy monolithic applications in the industry. This helps to break down a huge monolithic application into a discrete set of services (also called micro-services) that can talk to each other through APIs. Spinnaker's application management feature helps to manage these services across various cloud platforms. Regardless of the cloud architecture of each individual cloud platform, they are referred to as: Server Groups Clusters Applications Load Balancer Firewall Server Groups The basic unit of an application, The server group is the target environment in which the code is deployed, such as a virtual machine, cloud, or Docker image. Also considers basic configurations like metadata, number of instances, etc. A server group becomes a collection of instances of the currently running software after it is deployed. Clusters Clusters are logical collections of server groups in Spinnaker. Applications An application is a collection of clusters including firewalls and load balancers. It also includes the specific service which is to be deployed, all the configurations of that service and all the necessary infrastructure on which the service will run. Load Balancer Load balancers are responsible for maintaining traffic balance among instances in server groups. Also can enable health checks along with defined health criteria and the health check point. A load balancer is always connected with an ingress protocol and port range. Firewall A firewall is a set of rules defined by an IP address range (CIDR) accompanied by a communication protocol and a port range. Take note of the following in the image above: Both Applications 1 and 2 are cluster collections. Each cluster is a collection server group. The Load Balancer controls the traffic for server groups 1 and 2. The firewall controls the communication using a set of rules and protocols.","title":"Application Management"},{"location":"Application%20Management/#application-management","text":"Microservices-based architecture is replacing legacy monolithic applications in the industry. This helps to break down a huge monolithic application into a discrete set of services (also called micro-services) that can talk to each other through APIs. Spinnaker's application management feature helps to manage these services across various cloud platforms. Regardless of the cloud architecture of each individual cloud platform, they are referred to as: Server Groups Clusters Applications Load Balancer Firewall","title":"Application Management"},{"location":"Application%20Management/#server-groups","text":"The basic unit of an application, The server group is the target environment in which the code is deployed, such as a virtual machine, cloud, or Docker image. Also considers basic configurations like metadata, number of instances, etc. A server group becomes a collection of instances of the currently running software after it is deployed.","title":"Server Groups"},{"location":"Application%20Management/#clusters","text":"Clusters are logical collections of server groups in Spinnaker.","title":"Clusters"},{"location":"Application%20Management/#applications","text":"An application is a collection of clusters including firewalls and load balancers. It also includes the specific service which is to be deployed, all the configurations of that service and all the necessary infrastructure on which the service will run.","title":"Applications"},{"location":"Application%20Management/#load-balancer","text":"Load balancers are responsible for maintaining traffic balance among instances in server groups. Also can enable health checks along with defined health criteria and the health check point. A load balancer is always connected with an ingress protocol and port range.","title":"Load Balancer"},{"location":"Application%20Management/#firewall","text":"A firewall is a set of rules defined by an IP address range (CIDR) accompanied by a communication protocol and a port range. Take note of the following in the image above: Both Applications 1 and 2 are cluster collections. Each cluster is a collection server group. The Load Balancer controls the traffic for server groups 1 and 2. The firewall controls the communication using a set of rules and protocols.","title":"Firewall"},{"location":"Audit%20and%20Traceability/","text":"Audit and Traceability As software release velocity increases, so does the challenge of keeping track of the various deployments and events in the overall software delivery. Also, security and compliance events require an audit of the CD events but also traceability of the artifacts and data that led to the promotion of releases to the production. OpsMx ISD keeps a 100% audit of all CD events allowing one to understand who deployed, what, and when, and who approved the release, and what data was used to approve the release. As software release velocity increases, the challenge of keeping track of the various deployments and events in the overall software delivery increases. Autopilot helps auditors find various CD events and trace information about artifacts that led to the promotion of releases to the production. Autopilot keeps a 100% record of all delivery events such as who deployed, which software is deployed when deployed, any policy violations, who approved a release, what data was used to approve the release, etc. Overview: Autopilot gathers data from various CI/CD tools, APM, and log analyzers and applies supervised and unsupervised machine learning to find out software risks.","title":"Audit and Traceability"},{"location":"Audit%20and%20Traceability/#audit-and-traceability","text":"As software release velocity increases, so does the challenge of keeping track of the various deployments and events in the overall software delivery. Also, security and compliance events require an audit of the CD events but also traceability of the artifacts and data that led to the promotion of releases to the production. OpsMx ISD keeps a 100% audit of all CD events allowing one to understand who deployed, what, and when, and who approved the release, and what data was used to approve the release. As software release velocity increases, the challenge of keeping track of the various deployments and events in the overall software delivery increases. Autopilot helps auditors find various CD events and trace information about artifacts that led to the promotion of releases to the production. Autopilot keeps a 100% record of all delivery events such as who deployed, which software is deployed when deployed, any policy violations, who approved a release, what data was used to approve the release, etc.","title":"Audit and Traceability"},{"location":"Audit%20and%20Traceability/#overview","text":"Autopilot gathers data from various CI/CD tools, APM, and log analyzers and applies supervised and unsupervised machine learning to find out software risks.","title":"Overview:"},{"location":"Automated%20Workflows/","text":"Automated Workflows OES allows you to automate application delivery workflows with easy-to-create pipelines. OES offers templatized pipeline-as-code to enhance re-usability and provide ability to insert fine-grain policy within the pipeline, with real-time visibility and diagnostics during the pipeline execution. Easy pipeline creation: DevOps engineers can simplify delivery configuration with OES pipeline-as-code, and manage versioning and automated updates of pipeline changes. To know more about how to create a pipeline, - refer here Manage 1000\u2019s of pipeline: You can manage continuous delivery OES pipelines with the ease of using your management tools such as power UI, wizards, or JSON API. To know more about managing a pipeline, - refer here Embed Policies: OES pipelines provide flexibility to enforce static and dynamic policies so that compliance managers can guarantee adherence to SDLC compliance. To know more about policies, - refer here Pipeline Visibility: OES pipelines allow you to gain visibility from code check-in to test-automation to approval to production deployment through integration with JIRA, Jenkins, ServiceNow, AppDynamics, and other CD and APM tools. Notifications: Connect with collaboration tools of your choice (Git, Gitlab, JIRA, Jenkins, Servicenow, Slack, Hipchat) right away and get notified about deployment status, policy violations etc.","title":"Automated Workflows"},{"location":"Automated%20Workflows/#automated-workflows","text":"OES allows you to automate application delivery workflows with easy-to-create pipelines. OES offers templatized pipeline-as-code to enhance re-usability and provide ability to insert fine-grain policy within the pipeline, with real-time visibility and diagnostics during the pipeline execution. Easy pipeline creation: DevOps engineers can simplify delivery configuration with OES pipeline-as-code, and manage versioning and automated updates of pipeline changes. To know more about how to create a pipeline, - refer here Manage 1000\u2019s of pipeline: You can manage continuous delivery OES pipelines with the ease of using your management tools such as power UI, wizards, or JSON API. To know more about managing a pipeline, - refer here Embed Policies: OES pipelines provide flexibility to enforce static and dynamic policies so that compliance managers can guarantee adherence to SDLC compliance. To know more about policies, - refer here Pipeline Visibility: OES pipelines allow you to gain visibility from code check-in to test-automation to approval to production deployment through integration with JIRA, Jenkins, ServiceNow, AppDynamics, and other CD and APM tools. Notifications: Connect with collaboration tools of your choice (Git, Gitlab, JIRA, Jenkins, Servicenow, Slack, Hipchat) right away and get notified about deployment status, policy violations etc.","title":"Automated Workflows"},{"location":"Autopilot%20Installation%20Steps_old/","text":"Autopilot Installation Steps Following are the steps to install Autopilot. Download yaml file from the Enterprise Spinnaker repository in the GitHub $ wget https://raw.githubusercontent.com/OpsMx/enterprise-spinnaker/ oes3.10/charts/oes/values-APforOSS.yaml Update Autopilot UI and Autopilot Gate entries # Autopilot UI URL configuration oesUI: host: << AUTOPILOT UI URL Example autopilot.opsmx.net >> # Autopilot Gate URL configuration oesGate: host: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> Update Spinnaker Deck URL in dashboard section of values-APforOSS.yaml #Dashboard Service dashboard: config: spinnakerLink: <<SPINNAKER DECK URL Example spinaker.opsmx.net>>","title":"Autopilot Installation Steps old"},{"location":"Autopilot%20Installation%20Steps_old/#autopilot-installation-steps","text":"Following are the steps to install Autopilot. Download yaml file from the Enterprise Spinnaker repository in the GitHub $ wget https://raw.githubusercontent.com/OpsMx/enterprise-spinnaker/ oes3.10/charts/oes/values-APforOSS.yaml Update Autopilot UI and Autopilot Gate entries # Autopilot UI URL configuration oesUI: host: << AUTOPILOT UI URL Example autopilot.opsmx.net >> # Autopilot Gate URL configuration oesGate: host: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> Update Spinnaker Deck URL in dashboard section of values-APforOSS.yaml #Dashboard Service dashboard: config: spinnakerLink: <<SPINNAKER DECK URL Example spinaker.opsmx.net>>","title":"Autopilot Installation Steps"},{"location":"Autopilot%20Installation/","text":"Autopilot Installation If you are already using Open Source Spinnaker, then Autopilot can get seamlessly integrated with your Open Source Spinnaker and you get all the benefits of Autopilot product. The following section defines the procedure for installing Autopilot as a standalone module to work with Open Source Spinnaker. Note If you are installing Autopilot along with ISD, then refer the detailed installation procedure here . Refer the below installation procedure only if you are installing Autopilot as an independent module and want to integrate it with Open Source Spinnaker Prerequisites Have access to public repositories in docker.io and quay.io Have the following tools installed - wget, kubectl, helm Have access to a Kubernetes cluster with at least 2 nodes, each node having 8 CPU and 32 GB RAM Have the NGINX Ingress Controller installed in the cluster. If it is not already installation, then you can install the same using the following instructions $ kubectl create ns ingress-nginx $ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx $ helm repo update $ helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx $ kubectl get svc -n ingress-nginx Have \u201ccert-manager\u201d already available in the cluster. If it is not already available, then you can install it using the following instructions $ kubectl create namespace cert-manager $ helm repo add jetstack https://charts.jetstack.io $ helm repo update $ helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager In the Kubernetes cluster, have 3 Persistent Volumes of size 10GB each Two DNS records pointing to the IP of the Ingress Controller for the following: \u201cAutopilot UI\u201d, Eg. autopilot.opsmx.net \u201cAutopilot Gate\u201d, Eg. autopilot-gate.opsmx.net Autopilot Installation Steps Following are the steps to install Autopilot. Download yaml file from the Enterprise Spinnaker repository in the GitHub $ wget https://raw.githubusercontent.com/OpsMx/enterprise-spinnaker/oes3.10/charts/oes/values-APforOSS.yaml Update Autopilot UI and Autopilot Gate entries #Autopilot UI URL configuration oesUI: host: << AUTOPILOT UI URL Example autopilot.opsmx.net >> #Autopilot Gate URL configuration oesGate: host: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> Update Spinnaker Deck URL in dashboard section of values-APforOSS.yaml #Dashboard Service dashboard: config: spinnakerLink: <<SPINNAKER DECK URL Example spinaker.opsmx.net>> Authentication: Using LDAP Make changes in the ldap section in values-APforOSS.yaml #ldap configuration used in oes-gate, oes-platform and spinnaker gate for authentication and authorization #Change the below settings based on your LDAP server Ldap: enabled: true url: << LDAP URL: Example: ldaps://xxx.opsmx.com:636 >> managerDn: cn=manager,dc=opsmx,dc=com managerPassword: manager123 groupSearchBase: ou=groups,dc=opsmx,dc=com groupSearchFilter: member={0} groupRoleAttributes: cn userDnPattern: uid={0},ou=users,dc=opsmx,dc=com Note : managerDn : The Distinguished Name (DN) used to log into the Directory Service and to search for user accounts. manager-password : The password for the manager account specified in the managerDn property. groupSearchBase : The DN of the LDAP object where the search for the user account's groups begins. groupSearchFilter : The LDAP query string used to find the user account's group objects. The default is \u201c(member={0})\u201d. (In some LDAP implementations the name is memberof.). The {0} is a required value. It is a token that represents the user account that is being validated groupRoleAttributes : The field name to use as the Security role name for the group object DN userDnPattern : The field name to tell the authenticator how to find a user in LDAP Using SAML 2.0 Make changes in the saml section in values-APforOSS.yaml saml: enabled: true userSource: gate # Groups will be obtained from SAML keyStore: /opt/spinnaker/saml/oessaml.jks # The key in this secret must be oessamljks keyStorePassword: changeit keyStoreAliasName: saml metadataUrl: /opt/spinnaker/saml/oesmetadata.xml # The key in this secret must be oesmetadataxml redirectProtocol: https redirectHostname: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> redirectBasePath: / issuerId: << Unique Issuer Id Example opsmx.test >> jksSecretName: oessamljks metadataSecretName: oesmetadataxml Using OAuth 2.0 Autopilot supports OAuth 2.0 for authentication with GitHub organizations. Consult the GitHub OAuth 2.0 documentation and register a new OAuth 2.0 application to obtain a client ID and client secret. Make changes in the oauth2 section in values-APforOSS.yaml oauth2: enabled: true client: clientId: #CLIENT_ID clientSecret: #CLIENT_SECRET_ID accessTokenUri: https://github.com/login/oauth/access_token userAuthorizationUri: https://github.com/login/oauth/authorize scope: user-email resource: userInfoUri: https://api.github.com/user userInfoMapping: email: email firstName: firstname lastName: name username: login provider: GITHUB Specify the user groups from the authentication system; these groups will have Super Administrator privileges in Autopilot. Specify userSource for the specific authorization type. platform: config: #These groups will have superAdmin privileges in Autopilot adminGroups: admin #Source of groups for Authorization #Support sources: LDAP, FILE, GATE. In general, use \"gate\" for SAML userSource: ldap Specify Spinnaker Gate URL. When the Authentication type is X509, set the corresponding flag to true. sapor: config: spinnakerImages: OSS spinnaker: #true if authentication is enabled in Spinnaker authnEnabled: true #encryption key is needed for sapor to startup encrupt: enabled:false Add opsmx helm chart using the command $ helm repo add opsmx https://helmcharts.opsmx.com/ $ helm repo update Create a namespace for installing Autopilot $ kubectl create namespace autopilot Begin the installation using the following command $ helm install myautopilot opsmx/oes -f values-APforOSS.yaml -n autopilot --timeout 60m Run the following command to get the URLs $kubectl get ingress -n autopilot IP addresses should be linked to URLs in the DNS server Integrate Autopilot with Open Source Spinnaker After installing Autopilot, there are few changes in your Open Source Spinnaker configuration to integrate it with Autopilot. Following are the changes: Before editing yaml files in Spinnaker, first ensure their persistence. If they are not persistent already, follow these steps Example: $ kubectl edit cm ossspin-spinnaker-halyard-init-script Where ossspin is the name of the spinnaker instance. Change it as per your instance name. The following lines need to be commented out, followed by save. # rm -rf /tmp/spinnaker/.hal/default/service-settings # cp /tmp/service-settings/*/tmp/spinnaker/.hal/default/service-settings # rm -rf /tmp/spinnaker/.hal/default/profiles # cp /tmp/additionalProfileConfigMaps/*/tmp/spinnaker/.hal/default/profiles/ Enable echo events in OSS Spinnaker. Get a shell to the Spinnaker halyard pod. Example: kubectl exec -it oes-spinnaker-halyard-0 -n oss-spin -- /bin/bash Go to location: ~/.hal/default/profiles edit the file echo-local.yml ; Create a new file if not available $ vi echo-local.yml Update/Add the following lines, with the correct \"Autopilot Gate\" URL. rest: enabled: true endpoints: - wrap: false url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >>/auditservice/v1/echo/events/data - wrap: false url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >>/oes/echo Enable Custom Plugins in Spinnaker. Get a shell to the Spinnaker halyard pod. Example: $kubectl exec -it spinnaker-halyard-0 -n oss-spin -- /bin/bash Go to location: ~/.hal/default/profiles $ cd ~/.hal/default/profiles Edit the file orca-local.yml (create a new file if not available) $ vi orca-local.yml Update/Add the following lines spinnaker: extensibility: plugins: Opsmx.VerificationGatePlugin: enabled: true version: 1.0.1 config: Opsmx.VisibilityApprovalPlugin: enabled: true version: 1.0.1 config: Opsmx.TestVerificationGatePlugin: enabled: true version: 1.0.1 config: Opsmx.PolicyGatePlugin: enabled: true version: 1.0.1 config: repositories: opsmx-repo: id: opsmx-repo url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json Edit the file gate-local.yml (create a new file if not available) $ vi gate-local.yml Update/add the following lines spinnaker: extensibility: plugins: deck-proxy: enabled: true plugins: Opsmx.VerificationGatePlugin: enabled: true version: 1.0.1 Opsmx.TestVerificationGatePlugin: enabled: true version: 1.0.1 Opsmx.PolicyGatePlugin: enabled: true version: 1.0.1 Opsmx.VisibilityApprovalPlugin: enabled: true version: 1.0.1 plugins-root-path: /opt/gate/plugins repositories: opsmx-repo: url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json Edit the file front50-local.yml (create a new file if not available) $ vi front50-local.yml Update/add the following lines spinnaker: extensibility: plugins: Opsmx.StaticPolicyPlugin: enabled: true version: \"1.0.1\" config: null repositories: opsmx-repo: id: \"opsmx-repo\" url: \"https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0.staticpolicy/plugins.json\" policy: opa: enabled: true url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >> Run Hal deploy apply command to reflect the changes $ hal deploy apply Configure Spinnaker in Autopilot UI Once Spinnaker and OES are installed successfully, we need to configure Spinnaker in Autopilot UI. Navigate to Setup \u2192 Spinnaker \u2192 Add Spinnaker. The following fields need to be provided: Spinnaker Name: User defined name of Spinnaker Instance Spinnaker Gate URL: The Gate URL of the Spinnaker instance Authentication Type: Mechanism with which Autopilot communicates to Spinnaker. Mention, LDAP, for Basic Authentication (username with password) or X509, for 2 Factor Authentication systems. Using the LDAP Mechanism Provide the username and password of the user who has the access to all the pipelines in the encrypted base64 format using this command, echo -ne \u201cusername:password\u201d | base64 -w0 Using the x509 Mechanism To Enable x509 method of Authentication for Spinnaker, please refer to the steps in https://spinnaker.io/setup/security/authentication/x509/ For Autopilot to communicate with Spinnaker using x509, we need a client p12 key. Using the client.p12 key and password, we can configure Autopilot to communicate with Spinnaker on the x509 port. Assuming that we have client tls certificate and key, we can generate a p12 using the following command, $ openssl pkcs12 -export -clcerts -in x509lb.crt -inkey x509lb.key -out x509lb.p12 -name gate509lb -password pass:changeit","title":"Autopilot Installation"},{"location":"Autopilot%20Installation/#autopilot-installation","text":"If you are already using Open Source Spinnaker, then Autopilot can get seamlessly integrated with your Open Source Spinnaker and you get all the benefits of Autopilot product. The following section defines the procedure for installing Autopilot as a standalone module to work with Open Source Spinnaker. Note If you are installing Autopilot along with ISD, then refer the detailed installation procedure here . Refer the below installation procedure only if you are installing Autopilot as an independent module and want to integrate it with Open Source Spinnaker","title":"Autopilot Installation"},{"location":"Autopilot%20Installation/#prerequisites","text":"Have access to public repositories in docker.io and quay.io Have the following tools installed - wget, kubectl, helm Have access to a Kubernetes cluster with at least 2 nodes, each node having 8 CPU and 32 GB RAM Have the NGINX Ingress Controller installed in the cluster. If it is not already installation, then you can install the same using the following instructions $ kubectl create ns ingress-nginx $ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx $ helm repo update $ helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx $ kubectl get svc -n ingress-nginx Have \u201ccert-manager\u201d already available in the cluster. If it is not already available, then you can install it using the following instructions $ kubectl create namespace cert-manager $ helm repo add jetstack https://charts.jetstack.io $ helm repo update $ helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager In the Kubernetes cluster, have 3 Persistent Volumes of size 10GB each Two DNS records pointing to the IP of the Ingress Controller for the following: \u201cAutopilot UI\u201d, Eg. autopilot.opsmx.net \u201cAutopilot Gate\u201d, Eg. autopilot-gate.opsmx.net","title":"Prerequisites"},{"location":"Autopilot%20Installation/#autopilot-installation-steps","text":"Following are the steps to install Autopilot. Download yaml file from the Enterprise Spinnaker repository in the GitHub $ wget https://raw.githubusercontent.com/OpsMx/enterprise-spinnaker/oes3.10/charts/oes/values-APforOSS.yaml Update Autopilot UI and Autopilot Gate entries #Autopilot UI URL configuration oesUI: host: << AUTOPILOT UI URL Example autopilot.opsmx.net >> #Autopilot Gate URL configuration oesGate: host: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> Update Spinnaker Deck URL in dashboard section of values-APforOSS.yaml #Dashboard Service dashboard: config: spinnakerLink: <<SPINNAKER DECK URL Example spinaker.opsmx.net>> Authentication: Using LDAP Make changes in the ldap section in values-APforOSS.yaml #ldap configuration used in oes-gate, oes-platform and spinnaker gate for authentication and authorization #Change the below settings based on your LDAP server Ldap: enabled: true url: << LDAP URL: Example: ldaps://xxx.opsmx.com:636 >> managerDn: cn=manager,dc=opsmx,dc=com managerPassword: manager123 groupSearchBase: ou=groups,dc=opsmx,dc=com groupSearchFilter: member={0} groupRoleAttributes: cn userDnPattern: uid={0},ou=users,dc=opsmx,dc=com Note : managerDn : The Distinguished Name (DN) used to log into the Directory Service and to search for user accounts. manager-password : The password for the manager account specified in the managerDn property. groupSearchBase : The DN of the LDAP object where the search for the user account's groups begins. groupSearchFilter : The LDAP query string used to find the user account's group objects. The default is \u201c(member={0})\u201d. (In some LDAP implementations the name is memberof.). The {0} is a required value. It is a token that represents the user account that is being validated groupRoleAttributes : The field name to use as the Security role name for the group object DN userDnPattern : The field name to tell the authenticator how to find a user in LDAP Using SAML 2.0 Make changes in the saml section in values-APforOSS.yaml saml: enabled: true userSource: gate # Groups will be obtained from SAML keyStore: /opt/spinnaker/saml/oessaml.jks # The key in this secret must be oessamljks keyStorePassword: changeit keyStoreAliasName: saml metadataUrl: /opt/spinnaker/saml/oesmetadata.xml # The key in this secret must be oesmetadataxml redirectProtocol: https redirectHostname: << AUTOPILOT GATE URL Example autopilot-gate.opsmx.net >> redirectBasePath: / issuerId: << Unique Issuer Id Example opsmx.test >> jksSecretName: oessamljks metadataSecretName: oesmetadataxml Using OAuth 2.0 Autopilot supports OAuth 2.0 for authentication with GitHub organizations. Consult the GitHub OAuth 2.0 documentation and register a new OAuth 2.0 application to obtain a client ID and client secret. Make changes in the oauth2 section in values-APforOSS.yaml oauth2: enabled: true client: clientId: #CLIENT_ID clientSecret: #CLIENT_SECRET_ID accessTokenUri: https://github.com/login/oauth/access_token userAuthorizationUri: https://github.com/login/oauth/authorize scope: user-email resource: userInfoUri: https://api.github.com/user userInfoMapping: email: email firstName: firstname lastName: name username: login provider: GITHUB Specify the user groups from the authentication system; these groups will have Super Administrator privileges in Autopilot. Specify userSource for the specific authorization type. platform: config: #These groups will have superAdmin privileges in Autopilot adminGroups: admin #Source of groups for Authorization #Support sources: LDAP, FILE, GATE. In general, use \"gate\" for SAML userSource: ldap Specify Spinnaker Gate URL. When the Authentication type is X509, set the corresponding flag to true. sapor: config: spinnakerImages: OSS spinnaker: #true if authentication is enabled in Spinnaker authnEnabled: true #encryption key is needed for sapor to startup encrupt: enabled:false Add opsmx helm chart using the command $ helm repo add opsmx https://helmcharts.opsmx.com/ $ helm repo update Create a namespace for installing Autopilot $ kubectl create namespace autopilot Begin the installation using the following command $ helm install myautopilot opsmx/oes -f values-APforOSS.yaml -n autopilot --timeout 60m Run the following command to get the URLs $kubectl get ingress -n autopilot IP addresses should be linked to URLs in the DNS server","title":"Autopilot Installation Steps"},{"location":"Autopilot%20Installation/#integrate-autopilot-with-open-source-spinnaker","text":"After installing Autopilot, there are few changes in your Open Source Spinnaker configuration to integrate it with Autopilot. Following are the changes: Before editing yaml files in Spinnaker, first ensure their persistence. If they are not persistent already, follow these steps Example: $ kubectl edit cm ossspin-spinnaker-halyard-init-script Where ossspin is the name of the spinnaker instance. Change it as per your instance name. The following lines need to be commented out, followed by save. # rm -rf /tmp/spinnaker/.hal/default/service-settings # cp /tmp/service-settings/*/tmp/spinnaker/.hal/default/service-settings # rm -rf /tmp/spinnaker/.hal/default/profiles # cp /tmp/additionalProfileConfigMaps/*/tmp/spinnaker/.hal/default/profiles/ Enable echo events in OSS Spinnaker. Get a shell to the Spinnaker halyard pod. Example: kubectl exec -it oes-spinnaker-halyard-0 -n oss-spin -- /bin/bash Go to location: ~/.hal/default/profiles edit the file echo-local.yml ; Create a new file if not available $ vi echo-local.yml Update/Add the following lines, with the correct \"Autopilot Gate\" URL. rest: enabled: true endpoints: - wrap: false url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >>/auditservice/v1/echo/events/data - wrap: false url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >>/oes/echo Enable Custom Plugins in Spinnaker. Get a shell to the Spinnaker halyard pod. Example: $kubectl exec -it spinnaker-halyard-0 -n oss-spin -- /bin/bash Go to location: ~/.hal/default/profiles $ cd ~/.hal/default/profiles Edit the file orca-local.yml (create a new file if not available) $ vi orca-local.yml Update/Add the following lines spinnaker: extensibility: plugins: Opsmx.VerificationGatePlugin: enabled: true version: 1.0.1 config: Opsmx.VisibilityApprovalPlugin: enabled: true version: 1.0.1 config: Opsmx.TestVerificationGatePlugin: enabled: true version: 1.0.1 config: Opsmx.PolicyGatePlugin: enabled: true version: 1.0.1 config: repositories: opsmx-repo: id: opsmx-repo url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json Edit the file gate-local.yml (create a new file if not available) $ vi gate-local.yml Update/add the following lines spinnaker: extensibility: plugins: deck-proxy: enabled: true plugins: Opsmx.VerificationGatePlugin: enabled: true version: 1.0.1 Opsmx.TestVerificationGatePlugin: enabled: true version: 1.0.1 Opsmx.PolicyGatePlugin: enabled: true version: 1.0.1 Opsmx.VisibilityApprovalPlugin: enabled: true version: 1.0.1 plugins-root-path: /opt/gate/plugins repositories: opsmx-repo: url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json Edit the file front50-local.yml (create a new file if not available) $ vi front50-local.yml Update/add the following lines spinnaker: extensibility: plugins: Opsmx.StaticPolicyPlugin: enabled: true version: \"1.0.1\" config: null repositories: opsmx-repo: id: \"opsmx-repo\" url: \"https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0.staticpolicy/plugins.json\" policy: opa: enabled: true url: << AUTOPILOT GATE URL Example https://autopilot-gate.opsmx.net >> Run Hal deploy apply command to reflect the changes $ hal deploy apply Configure Spinnaker in Autopilot UI Once Spinnaker and OES are installed successfully, we need to configure Spinnaker in Autopilot UI. Navigate to Setup \u2192 Spinnaker \u2192 Add Spinnaker. The following fields need to be provided: Spinnaker Name: User defined name of Spinnaker Instance Spinnaker Gate URL: The Gate URL of the Spinnaker instance Authentication Type: Mechanism with which Autopilot communicates to Spinnaker. Mention, LDAP, for Basic Authentication (username with password) or X509, for 2 Factor Authentication systems. Using the LDAP Mechanism Provide the username and password of the user who has the access to all the pipelines in the encrypted base64 format using this command, echo -ne \u201cusername:password\u201d | base64 -w0 Using the x509 Mechanism To Enable x509 method of Authentication for Spinnaker, please refer to the steps in https://spinnaker.io/setup/security/authentication/x509/ For Autopilot to communicate with Spinnaker using x509, we need a client p12 key. Using the client.p12 key and password, we can configure Autopilot to communicate with Spinnaker on the x509 port. Assuming that we have client tls certificate and key, we can generate a p12 using the following command, $ openssl pkcs12 -export -clcerts -in x509lb.crt -inkey x509lb.key -out x509lb.p12 -name gate509lb -password pass:changeit","title":"Integrate Autopilot with Open Source Spinnaker"},{"location":"Continuous%20Compliance%20-%20Policy/","text":"Continuous Compliance - Policy Typical enterprises need to validate various policies during software releases. Some of the policies are team, corporate, security policies, while others are industry regulations like SOX, HIPPA, FedRamp, etc. OpsMx ISD integrates with 40+ eco-system tools (e.g., source code repository, CI, SAST/DAST, CD, and Monitoring tools) and ingests relevant data about the new release available for use by the policy engine. The policy engine allows the creation of extensible policies that can act on data ingested from various data sources. This capability allows OpsMx ISD to fully automate the policy check and allow for automated approval of releases. This feature lets you ensure compliance to industry standards and organizational policies while shipping your releases faster to production. Quickly identify the who, what, when, where, and how for your pipelines and applications through audit reports and traces. It caters to the rigid world of regulatory compliance with static compliance as code \u2013 while having the freedom and flexibility to tie policy and control into the rapidly changing IT services. It lets you create accurate coverage with controls by specifying them at an abstract level \u2013 while enforcing them at a pipeline level by integrating with Spinnaker.","title":"Continuous Compliance   Policy"},{"location":"Continuous%20Compliance%20-%20Policy/#continuous-compliance-policy","text":"Typical enterprises need to validate various policies during software releases. Some of the policies are team, corporate, security policies, while others are industry regulations like SOX, HIPPA, FedRamp, etc. OpsMx ISD integrates with 40+ eco-system tools (e.g., source code repository, CI, SAST/DAST, CD, and Monitoring tools) and ingests relevant data about the new release available for use by the policy engine. The policy engine allows the creation of extensible policies that can act on data ingested from various data sources. This capability allows OpsMx ISD to fully automate the policy check and allow for automated approval of releases. This feature lets you ensure compliance to industry standards and organizational policies while shipping your releases faster to production. Quickly identify the who, what, when, where, and how for your pipelines and applications through audit reports and traces. It caters to the rigid world of regulatory compliance with static compliance as code \u2013 while having the freedom and flexibility to tie policy and control into the rapidly changing IT services. It lets you create accurate coverage with controls by specifying them at an abstract level \u2013 while enforcing them at a pipeline level by integrating with Spinnaker.","title":"Continuous Compliance - Policy"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot/","text":"Data and Intelligence Module - Autopilot OpsMx Autopilot is the intelligence layer for Software Delivery, it provides real-time analytics to automate data-driven risk assessments for software releases. Autopilot analyzes the risk of all changes, automatically determining the confidence that an update can be promoted to the next pipeline stage without introducing errors. Autopilot also automated policy compliance, ensuring that all your governance rules and best practices are followed. Autopilot reduces errors in production, increases release velocity, and improves security, quality, and compliance.","title":"Data and Intelligence Module   Autopilot"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot/#data-and-intelligence-module-autopilot","text":"OpsMx Autopilot is the intelligence layer for Software Delivery, it provides real-time analytics to automate data-driven risk assessments for software releases. Autopilot analyzes the risk of all changes, automatically determining the confidence that an update can be promoted to the next pipeline stage without introducing errors. Autopilot also automated policy compliance, ensuring that all your governance rules and best practices are followed. Autopilot reduces errors in production, increases release velocity, and improves security, quality, and compliance.","title":"Data and Intelligence Module - Autopilot"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/","text":"Data and Intelligence Module - Autopilot OpsMx Autopilot is the intelligence layer for Software Delivery, it provides real-time analytics to automate data-driven risk assessments for software releases. Autopilot analyzes the risk of all changes, automatically determining the confidence that an update can be promoted to the next pipeline stage without introducing errors. Autopilot also automated policy compliance, ensuring that all your governance rules and best practices are followed. Autopilot reduces errors in production, increases release velocity, and improves security, quality, and compliance. Overview With Autopilot you get: 1. Automated Verification: Reduce software risks by analysing logs and metrics at every stage of CI/CD process. Determine the risk of every update before deploying to production. Automatically analyse data from dynamic and static scans, functional tests, metrics, and logs to identify and highlight anomalies that should be considered before approval. 2. Continuous Governance and Security: Mitigate risk and vulnerabilities by security and policy enforcement in software delivery pipelines. Provides comprehensive policy enforcement through an extensible policy engine that ensures compliance to industry standards and organizational policies while securely shipping your releases faster to production. 3. Automated Approvals: Make faster and informed decisions to approve a delivery pipeline by 360\u00b0 visibility of your CI/CD process. Perform informed application approval or promotion between different stages of software delivery (from QA to Staging & from staging to Production) through real-time information about the release, including source code changes, build information, source code analysis, SAST/DAST tool analysis, risk verifications, and policy checks. 4. Observability, Traceability and Insights: Collaborate more and make better decisions using real-time visibility and deep insights across your software deployments and delivery. Supports real-time Observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved.","title":"Data and Intelligence Module   Autopilot old"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#data-and-intelligence-module-autopilot","text":"OpsMx Autopilot is the intelligence layer for Software Delivery, it provides real-time analytics to automate data-driven risk assessments for software releases. Autopilot analyzes the risk of all changes, automatically determining the confidence that an update can be promoted to the next pipeline stage without introducing errors. Autopilot also automated policy compliance, ensuring that all your governance rules and best practices are followed. Autopilot reduces errors in production, increases release velocity, and improves security, quality, and compliance.","title":"Data and Intelligence Module - Autopilot"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#overview","text":"With Autopilot you get:","title":"Overview"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#1-automated-verification","text":"Reduce software risks by analysing logs and metrics at every stage of CI/CD process. Determine the risk of every update before deploying to production. Automatically analyse data from dynamic and static scans, functional tests, metrics, and logs to identify and highlight anomalies that should be considered before approval.","title":"1. Automated Verification:"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#2-continuous-governance-and-security","text":"Mitigate risk and vulnerabilities by security and policy enforcement in software delivery pipelines. Provides comprehensive policy enforcement through an extensible policy engine that ensures compliance to industry standards and organizational policies while securely shipping your releases faster to production.","title":"2. Continuous Governance and Security:"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#3-automated-approvals","text":"Make faster and informed decisions to approve a delivery pipeline by 360\u00b0 visibility of your CI/CD process. Perform informed application approval or promotion between different stages of software delivery (from QA to Staging & from staging to Production) through real-time information about the release, including source code changes, build information, source code analysis, SAST/DAST tool analysis, risk verifications, and policy checks.","title":"3. Automated Approvals:"},{"location":"Data%20and%20Intelligence%20Module%20-%20Autopilot_old/#4-observability-traceability-and-insights","text":"Collaborate more and make better decisions using real-time visibility and deep insights across your software deployments and delivery. Supports real-time Observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved.","title":"4. Observability, Traceability and Insights:"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/","text":"Environment setup for OpsMx ISD Environment setup Pre-requisites You should have internet access and should be able to access github.com, docker.io, and quay.io. The following tools should be installed on your system. curl git kubectl-cli kubectl-helm choco package manager (only for windows) In addition, you need to create a Github repository. Setup Laptop/machine used for ISD installation Please follow the instructions that are specific to your laptop/machine operating system. Mac: curl, git : Mac comes preinstalled with these commands kubectl : Install using instructions here , using homebrew is generally easier Helm : Install using instructions here , using homebrew is generally easier Windows: Execute the following command in Powershell (running in administrator mode) Set-ExecutionPolicy Bypass -Scope Process -Force; `iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) curl : Execute this command at the power shell prompt: choco install curl git : Execute this command at the power shell prompt: choco install git kubectl : Execute this command at the power shell prompt: choco install Kubernetes-cli helm : Execute this command at the power shell prompt: choco install kubernetes-helm Ubuntu/Linux: Curl : install using instructions here git : Install using instructions here kubectl : Install using instructions here , go with \u201cusing native package manager\u201d if you are not sure. Helm : Install helm using the instructions here , using a package manager is generally easier Verification: Execute the following commands to verify that the commands are functional: curl \u2013version git \u2013version kubectl version helm version Creating a GitHub repo (\"< gitops-repo >\") Github.com offers a free personal account. If you don't already have an account, follow the instructions here to create a new account. Login to GitHub (github.com) with your own credentials. Create a new private repository, instructions are here . While creating: Choose Private Check \u201cAdd a README file\u201d Rename \u201cmain\u201d branch as \u201cmaster\u201d branch by following the instructions here . Generate a personal access token by following the instructions here . Save this token to be updated in values.yaml later. Note If the token contains \u2018/\u2019 or \u2018\\\u2019, please generate another token as these special characters may create an issue during installation. Installing nginx ingress controller You can skip this section if you are using another ingress controller, such as one provided by the cloud provider. kubectl create ns ingress-nginx helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx Check whether it is installed correctly or not, use $kubectl get svc -n ingress-nginx Note down the IP Address (or hostname) of the \u201cingress-nginx-controller\u201d service in the output of the command above. This is required for making DNS or host entries as mentioned in the section below. Installing cert-manager You can skip this section if you're creating your own TLS certificates or the cluster doesn't have inbound port 80 access. kubectl create namespace cert-manager helm repo add jetstack https://charts.jetstack.io helm repo update helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager Adding entries to \u201chosts\u201d file Using DNS to map url-hostnames to IP addresses is the preferred method. However, in case you don\u2019t have access to a DNS server, for trial purposes, we can access the ISD by manually adding the IP->host mapping in the \u201chosts\u201d file as follows: Mac/Ubuntu/Linux section provides instructions for modifying your hosts file Please follow the instructions here . Please create 3 entries as follows. The IP address is the \u201cingress-nginx-controller\u201d service external IP address (as mentioned in the Nginx section above) and map them to the hostnames you defined for ISD. Ip-address oes.com Ip-address oes-gate.com Ip-address spin...com [Example: oes.opsmx-isd.opsmx.com] If you skipped the step in defining host-names , create these entries, replacing the \u201cip-address\u201d as explained above: Ip-address oes.isd-pov.example.com Ip-address oes-gate.isd-pov.example.com Ip-address spin.isd-pov.example.com Windows If you do NOT have DNS, add lines in hosts file as shown below, by following the instructions here : Please create add these three lines replacing the \u201cip-address\u201d with the IP-address is the \u201cingress-nginx-controller\u201d service external IP address Ip-address oes.isd-pov.example.com Ip-address oes-gate.isd-pov.example.com Ip-address spin.isd-pov.example.com [Example: 35.22.105.22 oes.isd-pov.example.com] If using DNS , add the entries in host file as shown below, by following the instructions here : Please create 3 entries as follows. The IP-address is the \u201cingress-nginx-controller\u201d service external IP address (as mentioned in the Nginx section above) and map them to the hostnames you defined for ISD. Ip-address oes.com Ip-address oes-gate.com Ip-address spin.com [Example: 35.22.105.22 oes.opsmx-isd.opsmx.com]","title":"Environment setup for OpsMx ISD"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#environment-setup-for-opsmx-isd","text":"","title":"Environment setup for OpsMx ISD"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#environment-setup","text":"","title":"Environment setup"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#pre-requisites","text":"You should have internet access and should be able to access github.com, docker.io, and quay.io. The following tools should be installed on your system. curl git kubectl-cli kubectl-helm choco package manager (only for windows) In addition, you need to create a Github repository.","title":"Pre-requisites"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#setup-laptopmachine-used-for-isd-installation","text":"Please follow the instructions that are specific to your laptop/machine operating system. Mac: curl, git : Mac comes preinstalled with these commands kubectl : Install using instructions here , using homebrew is generally easier Helm : Install using instructions here , using homebrew is generally easier Windows: Execute the following command in Powershell (running in administrator mode) Set-ExecutionPolicy Bypass -Scope Process -Force; `iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) curl : Execute this command at the power shell prompt: choco install curl git : Execute this command at the power shell prompt: choco install git kubectl : Execute this command at the power shell prompt: choco install Kubernetes-cli helm : Execute this command at the power shell prompt: choco install kubernetes-helm Ubuntu/Linux: Curl : install using instructions here git : Install using instructions here kubectl : Install using instructions here , go with \u201cusing native package manager\u201d if you are not sure. Helm : Install helm using the instructions here , using a package manager is generally easier Verification: Execute the following commands to verify that the commands are functional: curl \u2013version git \u2013version kubectl version helm version","title":"Setup Laptop/machine used for ISD installation"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#creating-a-github-repo-gitops-repo","text":"Github.com offers a free personal account. If you don't already have an account, follow the instructions here to create a new account. Login to GitHub (github.com) with your own credentials. Create a new private repository, instructions are here . While creating: Choose Private Check \u201cAdd a README file\u201d Rename \u201cmain\u201d branch as \u201cmaster\u201d branch by following the instructions here . Generate a personal access token by following the instructions here . Save this token to be updated in values.yaml later. Note If the token contains \u2018/\u2019 or \u2018\\\u2019, please generate another token as these special characters may create an issue during installation.","title":"Creating a GitHub repo (\"&lt; gitops-repo &gt;\")"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#installing-nginx-ingress-controller","text":"You can skip this section if you are using another ingress controller, such as one provided by the cloud provider. kubectl create ns ingress-nginx helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx Check whether it is installed correctly or not, use $kubectl get svc -n ingress-nginx Note down the IP Address (or hostname) of the \u201cingress-nginx-controller\u201d service in the output of the command above. This is required for making DNS or host entries as mentioned in the section below.","title":"Installing nginx ingress controller"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#installing-cert-manager","text":"You can skip this section if you're creating your own TLS certificates or the cluster doesn't have inbound port 80 access. kubectl create namespace cert-manager helm repo add jetstack https://charts.jetstack.io helm repo update helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager","title":"Installing cert-manager"},{"location":"Environment%20setup%20for%20OpsMx%20ISD/#adding-entries-to-hosts-file","text":"Using DNS to map url-hostnames to IP addresses is the preferred method. However, in case you don\u2019t have access to a DNS server, for trial purposes, we can access the ISD by manually adding the IP->host mapping in the \u201chosts\u201d file as follows: Mac/Ubuntu/Linux section provides instructions for modifying your hosts file Please follow the instructions here . Please create 3 entries as follows. The IP address is the \u201cingress-nginx-controller\u201d service external IP address (as mentioned in the Nginx section above) and map them to the hostnames you defined for ISD. Ip-address oes.com Ip-address oes-gate.com Ip-address spin...com [Example: oes.opsmx-isd.opsmx.com] If you skipped the step in defining host-names , create these entries, replacing the \u201cip-address\u201d as explained above: Ip-address oes.isd-pov.example.com Ip-address oes-gate.isd-pov.example.com Ip-address spin.isd-pov.example.com Windows If you do NOT have DNS, add lines in hosts file as shown below, by following the instructions here : Please create add these three lines replacing the \u201cip-address\u201d with the IP-address is the \u201cingress-nginx-controller\u201d service external IP address Ip-address oes.isd-pov.example.com Ip-address oes-gate.isd-pov.example.com Ip-address spin.isd-pov.example.com [Example: 35.22.105.22 oes.isd-pov.example.com] If using DNS , add the entries in host file as shown below, by following the instructions here : Please create 3 entries as follows. The IP-address is the \u201cingress-nginx-controller\u201d service external IP address (as mentioned in the Nginx section above) and map them to the hostnames you defined for ISD. Ip-address oes.com Ip-address oes-gate.com Ip-address spin.com [Example: 35.22.105.22 oes.opsmx-isd.opsmx.com]","title":"Adding entries to \u201chosts\u201d file"},{"location":"Helm%20Chart%20based%20installation/","text":"Helm Chart based installation Helm Chart based installation - Detailed The document is primarily intended to be used for Helm based ISD installation. Follow these steps if you are trying to install ISD yourself. Pre-requisites To use this document you would need prior familiarity of Helm chart concepts, YAML, Kubernetes knowledge and working knowledge of GitHub & Spinnaker tool. Chart Basics ISD helm chart is located at https://github.com/OpsMx/enterprise-spinnaker.git. We fully support installations with custom-CAs and/or airgapped installations. Note Various versions of the chart are available in separate branches of the same repo. For installation, you need the following: Standard-gitops repo: https://github.com/OpsMx/standard-gitops-repo.git . Select the \u201cbranch\u201d in this repo as appropriate AIRGAPPED: https://github.com/OpsMx/airgap-gitops.git Sample pipelines: https://github.com/OpsMx/sample-pipelines.git Plugins: https://github.com/OpsMx/datasource-plugins.git and https://github.com/OpsMx/spinnakerPluginRepository.git AIRGAPPED: See additional configuration information for oes-gate and spin-orca Chart Contents - OES It is best to clone this \u201copsmx/enterprise-spinnaker.git\u201d repo and familiarize yourself with the contents before proceeding further. In the \"enterprise-spinnaker/chars/oes\" folder, these are the key folders: Values.yaml: This is the base values.yaml file that contains all the defaults for the chart. All values here can be overridden by the \"-f values-changed.yaml\" option on the helm install command. Only the changed values need to be present in this file. Templates: This folder contains all the OES components and their configurations Charts: This contains charts that we package along with OES. These include Spinnaker, minio, redis, prometheus, elastic & more. Key changes are in the Spinnaker chart. Key files inside the \"spinnaker-chart\" are: Templates: These are the Spinnaker related templates Config: These are files that are included in the \"templates-files\" Configs: This contains files (yaml's, scripts) that are included in the OES templates Chart Options Routing UI to backend Routing traffic from web-browser (UI) to various services in the backend can be done in multiple ways depending on the environment. This includes ingress, cert-manager or custom certs (for TLS, also known as https), load balancers, node-ports, etc. To keep it simple, all we need to know at this point in time is that all UI traffic is routed via \u201cgate\u201d, a spinnaker component. Gate SAPOR service in OES talks to Spinnaker services. All the communication OES makes with Spinnaker is done thru SAPOR service and it does so via \u201cgate\u201d (or multiple gates, a gate is a spinnaker component used by the Spinnaker UI and all API callers communicate with Spinnaker). As a design choice, OES does not communicate directly with any of the spinnaker services, though front50 and echo do have outbound communication to OES SAPOR. These are the options: OES-Gate: This is the default option. All communication from the UI (OES UI & spin-deck also known as Spinnaker Gate) and the communication between SAPOR and Spinnaker happens via this \u2018common\u2019 gate. Values.yaml: global.commonGate.enabled=true Files: templates/(deployment|configmaps)/oes-gate*.yml OES-Gate: For OES components and \u201cspin-gate\u201d for spinnaker components. Values.yaml: global.commonGate.enabled=false (Note: This option is usually not used) SAPOR-Gate: This is an additional gate into Spinnaker that is configured with basic authentication i.e. simple username and password. As SAPOR connects to spinnaker services via OES-Gate (or spin-gate), the API needs to be authenticated. SAPOR-Gate is an option when 2-factor authentication is enabled on OES-Gate or spinnaker-gate. Note: SAPOR-Spinnaker authentication is not possible using UI. Values.yaml: saporGate.enabled=false (Disabled by default) saporGate.config.username, password : basic auth credentials Files: template/sapor-gate folder contains the required files X509: This is not really a gate but an option to authenticate to spin-gate via x509 certificate authentication. This requires that the TLS termination happens at the gate and not at the ingress or load balancer. Values.yaml: The configuration is part of spinnaker.gitOps and is involved. Best to configure manually as certificates need to be generated and imported into secret stores. Normally, one would not need to touch the \u201coes-gate-config\u201d configMap. However, it is good to know certain key points: services.fiat.enabled: true (Ensure that this is set to true of Spinnaker authZ (fiat) is enabled service.gate and deck: These should point to external oes-gate and spin-deck URLs spinnaker.extensibility.repositories: URL mentioned is accessed for downloading plugins related for Visibility, Verification and Policy. If they are not working (showing as JSON) in Spinnaker UI, this is a place to check. Autoconfig OES needs to configure the Spinnaker connection. In addition, even though Autopilot and OPA are installed along with the chart, these are separate data sources and need to be configured in the \u201cintegrations\u201d page of the OES set-up. Values.yaml: oesAutoConfiguration: true (Default is true) Files: templates/hooks/oes-config-job.yaml templates/configmap/datasource-creation.yaml This job runs a script in the \u201cdatasource-creation\u201d configMap that: Waits for all pods to be up Makes the curl calls to add gitops, autopilot and OPA data sources Makes a curl call to add Spinnaker Note Check the logs of \u201coes-config-*\u201d pod, if these are not auto-configured. OpenLDAP Both for authentication and authorization, OES and Spinnaker can be configured to use any third party authentication service like LDAP, OpenLDAP, OAuth etc. OES helm package includes OpenLDAP that contains the following users and groups: ID: admin / Password: opsmxadmin123 (Belongs to all groups) ID: user1 / Password: user1password (Belongs to \u201cdevelopers\u201d group) ID: user2 / Password: user2password (Belongs to \u201cqa\u201d group) ID: user3 / Password: user3password (Belongs to both developers and qa groups) Values.yaml: global.installOpenldap: true Files: charts/openldap/templates Note Default settings in \u201cstandard-gitops\u201d repo are for authentication enabled but authorization is disabled. If you want to enable, please do check \u2018fiat\u2019 param in the \u201coes-gate\u201d config as well. \u201cglobal.ldap.enabled=true\u201d is independent of openLDAP. That means, the users are free to use other LDAP. Open Policy Agent (OPA) OES supports enforcing \u201cpolicy\u201d. A policy is an execution condition, a simple policy might be \u201cdon\u2019t allow deployment on weekends\u201d. There are two kinds of policies: Static and Runtime. This is how it works in OES. Static Policy front50 has a web-hook configured that is called before a pipeline is saved. The configuration is in \u201c.hal/defaults/profile/front50-local.yml\u201d. You can see it in the standard-gitops repo \u201cdefault/profiles/front50-local.yml\u201d, policy.opa.enabled and URL that points to \u201cOES-Sapor\u201d. Note It is always possible to disable the policy enforcement using policy.opa,enabled: false. If OES is installed in a different namespace or a different cluster, this URL needs to be updated to route it correctly to OES-Sapor. OpsMx front50 image is required for this functionality, hence this feature doesn\u2019t work with Open Source Spinnaker Runtime Policy Runtime policy is enforced by adding a \u201cpolicy\u201d stage in the pipeline through the OES-UI Execution In both these cases, an API call comes to SAPOR which in turns makes a call the configured OPA server. For providing this functionality, an OPA server is required. An OPA server is installed by default in the chart, which installing OES. Values.yaml: opa.enabled: true (Enabled by default) Files: templates/deployments/opa-deployment.yaml and templates/configmaps/opa-persists,yaml Note : OPA server is required and expected by the install. If required, it can be disabled later. Customer\u2019s OPA server, if any, can be configured in addition to this OPA-server. Create-controller-secrets (Agent Configuration) OES supports Spinnaker deployment via an \u201cAgent\u201d that is installed in a remote cluster with no inbound network access (of course, outbound is required). Controller and Agent talk to each other and everyone through custom self-signed certificates that need to be made available to all parties. To this end, a custom job \u201ccreate-controller-secrets\u201d is executed at the start of the installation. It only needs to be executed once (unless the created secrets are deleted). It creates the following: ca-secret: This is the self-signed CA and its key. This is mounted as a volume in the controller so that it can generate all the required certificates. oes-control-secret: This contains the CA and x509 certs required for SAPOR to talk to the controller. From OES-UI, when we add an agent, SAPOR talks to the controller to generate the required configuration content. Jwt-secret: Used by the controller oes-cacerts: This contains the JAVA key-store \u201ccacerts\u201d that has the self-signed CA added to it. This is mounted on Igor (for remote jenkins), etc. It can be mounted in any of the pods that need to access any extra certificates. The \u201ccreate-controller-secrets\u201d custom job allows for the following (both being optional): Provide your own base \u201ccacerts\u201d: If a customer has 10-20 CAs that need to be added, we could use java \u2018key-tool\u2019 to add all of them and provide that \u201ccacerts\u201d as the base to which the controller CA is added. Provide your CAs: If a customer wants their own CA to be added, this can optionally be provided. It is added into the base \u201ccacerts\u201d that are already baked into the image. values.yaml: forwarder.enabled: true (If false, remove mounts in default/service-settings.) Files: templates/forwarder Note It is OK to rerun this job by deleting all the secrets created by it. This may be required, for example, to add another CA. However, ensure that SAPOR controller and any pods mounting \u201coes-cacerts\u201d are restarted. All agent manifests should be deleted, re-created via the OES-UI and re-applied in the remote clusters. Only to rename the \u201ccontroller-agent-grpc\u201d endpoint, rerunning this job is NOT required. Simply update the controller configMap and restart the controller. The controller creates its own certs based on the \u201cca-secret\u201d contents. As it recreates it every time on start-up, running this job is not required. Do download the agent manifests afresh. Chart-Custom CA OES Helm chart fully supports the use of a custom CA (Certificate Authority). This is done in two parts: The \u201ccreate-controller-secrets\u201d job allows you to include a CA in \u201coes-cacerts\u201d secret. Ensure that custom CA is part of \u201coes-cacerts\u201d. This secret is mounted in all the pods, both in OES and Spinnaker. In OES it is mounted by specifying the flag in \u201c values.yaml \u201d and in Spinnaker is mounted by adding entries to \u201c .hal/default/service-settings/ .yml*\u201d files values.yaml: global.customCerts.enabled: true (Default is false) global.customCerts.secretName (DO NOT CHANGE) Files: standard-gitops repo, default/service-settings/*.yml. Note To test this, access the resources and look for SSL exceptions in pod-logs. Chart-Airgapped Install OES Helm chart fully supports installing in an airgapped environment. This is done in the following way: Obtain all docker images required and upload to local image repository In \u201cvalues.yaml\u201d, update global.customImage.registry as appropriate Use the \u201copsmx/airgap-repo\u201d instead of the \u201cstandard-gitops\u201d repo. Note The repo contains \u201c.boms\u201d folder that may not be listed with ls command. Images repo locations need to be updated as appropriate In addition, OES uses \u201cplugin-framework\u201d for adding functionality to Spinnaker. Spinnaker natively supports PF4J that requires downloading files from an unauthenticated git repository. If an unauthenticated git repository is available within the airgapped environment: Update \u201c spinnaker.extensibility.repositories.url \u201d in the \u201coes-gate\u201d configmap to point to a repo that is reachable by Spinnaker. Copy the contents from the opsmx repo into the local repo. Update the same parameter in \u201c orca-local.yml \u201d (in .hal/defaults/profile) Halyard GitOps This section describes the basics of how the gitOps works and the various players in the process. There is a repo (github repo for this document, but could be S3, bitbucket, etc), typically copied from \u201c github.com/opsmx/standard-gitops repo \u201d This repo contains files that are used by Spinnaker Halyard. All the contents of \u201c /home/spinnaker/.hal \u201d inside the halyard pod are placed there by pulling them from the repo and editing them to replace certain values. OES updates the spinnaker configuration by writing to this repo. Spinnaker configuration is updated by restarting the halyard pod. This process is enabled by multiple \u201c init \u201d containers that run before the main halyard container. values.yaml: spinnaker.gitOpsHalyard.* Spinnaker.spinCli.* Files: charts/spinnaker/templates & charts/spinnaker/config Container: create-halyard-local This is the first container that executes the \u201cinit.sh\u201d script that is located in the \"*-opsmx-spinnaker-halyard-init-script\u201d configMap. Note that the script gets modified based on the repo-type during the installation process. Here is a high-level description of the script: Clone the \u201cgit-repo\u201d Replace \u201cSPINNAKER_NAMESPACE\u201d string in \u201c.hal/config, default/profiles/fiat-local.yml\u201d, \u201corca-local.yml\u201d (custom jobs) Replace \u201cRELEASE_NAME\u201d string in \u201c.hal/config, redis.yml\u201d in \u201cdefault/service-settings\u201d Replaces \u201cGIT_TOKEN\u201d, \u201cGIT_USER\u201d and \u201cDYNAMIC_ACCNT_CONFIG\u201d in \u201cdefault/profiles/spinnakerconfig.yml\u201d Container: halyardconfig-update As we use git-repo for halyard configuration, secrets used by halyard (for example, account passwords) could be exposed to anyone who has git-repo access. OES chart supports using Kubernetes secrets in halyard configuration. The procedure is as follows: Manually create a Kubernetes secret with a key and password in the spinnaker namespace. Create it as: K create secret generic --from-literal =MYSECRET In the \u201c git-repo \u201d, refer to it as encrypted:: in the files where it is used If need to encrypt a File, create the secret and refer to it as encryptedFile:: Create it as, k create secret generic SECRETNAME --from-file This init container runs the \u201crun.sh\u201d script in -opsmx-spinnaker-spin-secret-decoder configMap that searches and replaces all values as appropriate. Container: halyard-overrideurl OES requires 3 (max 5 including controller) end-points that need to be reachable from the web-browser. These are: oes-ui oes-gate Spin-deck spin-gate (only if NOT using the common-gate, usually not required) \"agent-grpc\" service of the controller (if configuring agent/controller) Routing Web-URLs to OES and Spinnaker pods requires multiple configurations depending on the following URLs type: Ingress: In this model there is one loadbalancer/IP that routes traffic to an ingress controller (e.g. nginx). The ingress controller looks at the URL string (example, spin.saas.opsmx.com or oes.saas.opsmx.com) and based on this string routes the traffic to the appropriate pod. Note that for this to work, DNS (example, www.godaddy.com) is a critical requirement as IP address needs to be translated to URLs. Load Balancers: Most cloud providers have automatic load balancer provisioning. This allows for any service to have an external IP and traffic is directly routed to the appropriate service or pod. In addition, we can still use the DNS to reach the LB. Node Port: In case load balancer is not available, Kubernetes allows IP address of any of the worker nodes to be used with a \u201cnode port\u201d (instead of the service-port) to route the traffic to pods HTTP or HTTPS If using HTTPS, additional complexity comes in the form TLS certificates and termination. Ingress: In most cases, ingress will allow for TLS termination. Coupled with cert-manager+ACME, automatic certificates can be generated. Default OES installation assumes \u201cnginx\u201d and \u201ccert-manager\u201d. If using custom-certificates, these need to be generated and provided to ingress controller for TLS termination. This is easily done by create the TLS secrets mentioned in the default ingress objects created (kubectl get ing) If using any other ingress (other than nginx), the ingress object configuration has to be changed accordingly. Load Balancers: Most cloud providers provide options for TLS termination at the Load Balancer. If this option is chosen (makes sense only if DNS is in place), the certificates need to be loaded to the cloud provider for TLS termination. Node Port: In this case, it is assumed that we are in development mode and HTTPS is not supported. values.yaml: global.spinDeck.host, oesUI.host, oesGate.host, spinGate.host, protocol k8sServiceType: ClusterIP or LoadBalancer This init container runs the \u201ccall_overrides.sh\u201d script in *-opsmx-spinnaker-halyard-overrideurl configMap. This is designed to support 3 situations: Gate and deck use ingress and URLs are provided and gitops is in use. In this case, the hal/config overrideUrls are edited to appropriate values. No URLs are provided, load-balancer IP is used for figuring out the URLs for gate and deck. No URLs are provided and there is no external IP for the load-balancer after waiting for 5 minutes. In this case, Node IP with node-ports is used for configuring the gate and deck URLs. Container: halyard This is the main halyard container that runs the halyard executable. There is a postStart lifecycle hook that waits for the halyard process to be ready and then executes \u201c hal deploy apply \u201d. Note If you see any errors, check the logs of the \u201ccreate-halyard-local container\u201d. In most cases, it is unable to fetch the repo because the git-token may be incorrect or has expired. If the halyard pod stays hung in \u201cpodInitializing\u201d state for more than 5 minutes, it means that the halyard daemon process is unable to start. The issue here is most likely related to \u201chalyard-local.yml\u201d file in the \u201cstandard-gitops repo\u201d. Easiest way to debug is to remove the \u201cpoststart\u201d lifecycle hook and check the container logs, \u201cexec\u201d into the container and execute \u201chal-deploy-apply\u201d manually. If we see \u201cdecryption\u201d errors in \u201chal-deploy-apply\u201d, most likely the cause is the mismatch between SAPOR encryption and halyard decryption. SAPOR encrypt key can be found in bootstrap secret and oes-sapor-config CM. Halyard decrypt key is found in .hal/default/profiles/spinnakerconfig.yml Install-using-hal This is the primary installer in the Spinnaker helm-chart. This has been modified to add a container. values.yaml: spinnaker.spinCli.* Files: charts/spinnaker/templates/hooks/install-using-hal.yaml & charts/spinnaker/templates/secrets/spin-config.yaml sample-pipeline-install This creates the following applications in Spinnaker, \u201cOpsmx-gitops\u201d application in spinnaker is needed for \u201cRestart Spinnaker\u201d in OES UI to work. It also contains the \u201csyncToGit\u201d and \u201csyncToSpinnaker\u201d pipeline promotion pipelines for backing up Spinnaker applications. \u201csampleapp\u201d application contains a few sample pipelines to demonstrate spinnaker functionality and also act as a quick reference. This container (not an init container) executes the \u201cspin-pipeline-import.sh\u201d script that: Waits for all spinnaker services to be up. Clones the sample pipeline repo at \u201c https://github.com/OpsMx/sample-pipelines.git \u201d. Executes \u201cspin-cli\u201d commands to push sample pipelines into Spinnaker. For this it needs the gate-API url, username and password that is taken from a secret created from values.yaml, spinnaker.spinCli section. Note This step is mandatory. Opsmx-gitops application is needed for restart functionality to work. If sampleapp is not there in spinnaker after install, check the logs of this container.","title":"Helm Chart based installation"},{"location":"Helm%20Chart%20based%20installation/#helm-chart-based-installation","text":"","title":"Helm Chart based installation"},{"location":"Helm%20Chart%20based%20installation/#helm-chart-based-installation-detailed","text":"The document is primarily intended to be used for Helm based ISD installation. Follow these steps if you are trying to install ISD yourself.","title":"Helm Chart based installation - Detailed"},{"location":"Helm%20Chart%20based%20installation/#pre-requisites","text":"To use this document you would need prior familiarity of Helm chart concepts, YAML, Kubernetes knowledge and working knowledge of GitHub & Spinnaker tool.","title":"Pre-requisites"},{"location":"Helm%20Chart%20based%20installation/#chart-basics","text":"ISD helm chart is located at https://github.com/OpsMx/enterprise-spinnaker.git. We fully support installations with custom-CAs and/or airgapped installations. Note Various versions of the chart are available in separate branches of the same repo. For installation, you need the following: Standard-gitops repo: https://github.com/OpsMx/standard-gitops-repo.git . Select the \u201cbranch\u201d in this repo as appropriate AIRGAPPED: https://github.com/OpsMx/airgap-gitops.git Sample pipelines: https://github.com/OpsMx/sample-pipelines.git Plugins: https://github.com/OpsMx/datasource-plugins.git and https://github.com/OpsMx/spinnakerPluginRepository.git AIRGAPPED: See additional configuration information for oes-gate and spin-orca","title":"Chart Basics"},{"location":"Helm%20Chart%20based%20installation/#chart-contents-oes","text":"It is best to clone this \u201copsmx/enterprise-spinnaker.git\u201d repo and familiarize yourself with the contents before proceeding further. In the \"enterprise-spinnaker/chars/oes\" folder, these are the key folders: Values.yaml: This is the base values.yaml file that contains all the defaults for the chart. All values here can be overridden by the \"-f values-changed.yaml\" option on the helm install command. Only the changed values need to be present in this file. Templates: This folder contains all the OES components and their configurations Charts: This contains charts that we package along with OES. These include Spinnaker, minio, redis, prometheus, elastic & more. Key changes are in the Spinnaker chart. Key files inside the \"spinnaker-chart\" are: Templates: These are the Spinnaker related templates Config: These are files that are included in the \"templates-files\" Configs: This contains files (yaml's, scripts) that are included in the OES templates","title":"Chart Contents - OES"},{"location":"Helm%20Chart%20based%20installation/#chart-options","text":"","title":"Chart Options"},{"location":"Helm%20Chart%20based%20installation/#routing-ui-to-backend","text":"Routing traffic from web-browser (UI) to various services in the backend can be done in multiple ways depending on the environment. This includes ingress, cert-manager or custom certs (for TLS, also known as https), load balancers, node-ports, etc. To keep it simple, all we need to know at this point in time is that all UI traffic is routed via \u201cgate\u201d, a spinnaker component.","title":"Routing UI to backend"},{"location":"Helm%20Chart%20based%20installation/#gate","text":"SAPOR service in OES talks to Spinnaker services. All the communication OES makes with Spinnaker is done thru SAPOR service and it does so via \u201cgate\u201d (or multiple gates, a gate is a spinnaker component used by the Spinnaker UI and all API callers communicate with Spinnaker). As a design choice, OES does not communicate directly with any of the spinnaker services, though front50 and echo do have outbound communication to OES SAPOR. These are the options: OES-Gate: This is the default option. All communication from the UI (OES UI & spin-deck also known as Spinnaker Gate) and the communication between SAPOR and Spinnaker happens via this \u2018common\u2019 gate. Values.yaml: global.commonGate.enabled=true Files: templates/(deployment|configmaps)/oes-gate*.yml OES-Gate: For OES components and \u201cspin-gate\u201d for spinnaker components. Values.yaml: global.commonGate.enabled=false (Note: This option is usually not used) SAPOR-Gate: This is an additional gate into Spinnaker that is configured with basic authentication i.e. simple username and password. As SAPOR connects to spinnaker services via OES-Gate (or spin-gate), the API needs to be authenticated. SAPOR-Gate is an option when 2-factor authentication is enabled on OES-Gate or spinnaker-gate. Note: SAPOR-Spinnaker authentication is not possible using UI. Values.yaml: saporGate.enabled=false (Disabled by default) saporGate.config.username, password : basic auth credentials Files: template/sapor-gate folder contains the required files X509: This is not really a gate but an option to authenticate to spin-gate via x509 certificate authentication. This requires that the TLS termination happens at the gate and not at the ingress or load balancer. Values.yaml: The configuration is part of spinnaker.gitOps and is involved. Best to configure manually as certificates need to be generated and imported into secret stores. Normally, one would not need to touch the \u201coes-gate-config\u201d configMap. However, it is good to know certain key points: services.fiat.enabled: true (Ensure that this is set to true of Spinnaker authZ (fiat) is enabled service.gate and deck: These should point to external oes-gate and spin-deck URLs spinnaker.extensibility.repositories: URL mentioned is accessed for downloading plugins related for Visibility, Verification and Policy. If they are not working (showing as JSON) in Spinnaker UI, this is a place to check.","title":"Gate"},{"location":"Helm%20Chart%20based%20installation/#autoconfig","text":"OES needs to configure the Spinnaker connection. In addition, even though Autopilot and OPA are installed along with the chart, these are separate data sources and need to be configured in the \u201cintegrations\u201d page of the OES set-up. Values.yaml: oesAutoConfiguration: true (Default is true) Files: templates/hooks/oes-config-job.yaml templates/configmap/datasource-creation.yaml This job runs a script in the \u201cdatasource-creation\u201d configMap that: Waits for all pods to be up Makes the curl calls to add gitops, autopilot and OPA data sources Makes a curl call to add Spinnaker Note Check the logs of \u201coes-config-*\u201d pod, if these are not auto-configured.","title":"Autoconfig"},{"location":"Helm%20Chart%20based%20installation/#openldap","text":"Both for authentication and authorization, OES and Spinnaker can be configured to use any third party authentication service like LDAP, OpenLDAP, OAuth etc. OES helm package includes OpenLDAP that contains the following users and groups: ID: admin / Password: opsmxadmin123 (Belongs to all groups) ID: user1 / Password: user1password (Belongs to \u201cdevelopers\u201d group) ID: user2 / Password: user2password (Belongs to \u201cqa\u201d group) ID: user3 / Password: user3password (Belongs to both developers and qa groups) Values.yaml: global.installOpenldap: true Files: charts/openldap/templates Note Default settings in \u201cstandard-gitops\u201d repo are for authentication enabled but authorization is disabled. If you want to enable, please do check \u2018fiat\u2019 param in the \u201coes-gate\u201d config as well. \u201cglobal.ldap.enabled=true\u201d is independent of openLDAP. That means, the users are free to use other LDAP.","title":"OpenLDAP"},{"location":"Helm%20Chart%20based%20installation/#open-policy-agent-opa","text":"OES supports enforcing \u201cpolicy\u201d. A policy is an execution condition, a simple policy might be \u201cdon\u2019t allow deployment on weekends\u201d. There are two kinds of policies: Static and Runtime. This is how it works in OES. Static Policy front50 has a web-hook configured that is called before a pipeline is saved. The configuration is in \u201c.hal/defaults/profile/front50-local.yml\u201d. You can see it in the standard-gitops repo \u201cdefault/profiles/front50-local.yml\u201d, policy.opa.enabled and URL that points to \u201cOES-Sapor\u201d. Note It is always possible to disable the policy enforcement using policy.opa,enabled: false. If OES is installed in a different namespace or a different cluster, this URL needs to be updated to route it correctly to OES-Sapor. OpsMx front50 image is required for this functionality, hence this feature doesn\u2019t work with Open Source Spinnaker Runtime Policy Runtime policy is enforced by adding a \u201cpolicy\u201d stage in the pipeline through the OES-UI Execution In both these cases, an API call comes to SAPOR which in turns makes a call the configured OPA server. For providing this functionality, an OPA server is required. An OPA server is installed by default in the chart, which installing OES. Values.yaml: opa.enabled: true (Enabled by default) Files: templates/deployments/opa-deployment.yaml and templates/configmaps/opa-persists,yaml Note : OPA server is required and expected by the install. If required, it can be disabled later. Customer\u2019s OPA server, if any, can be configured in addition to this OPA-server.","title":"Open Policy Agent (OPA)"},{"location":"Helm%20Chart%20based%20installation/#create-controller-secrets-agent-configuration","text":"OES supports Spinnaker deployment via an \u201cAgent\u201d that is installed in a remote cluster with no inbound network access (of course, outbound is required). Controller and Agent talk to each other and everyone through custom self-signed certificates that need to be made available to all parties. To this end, a custom job \u201ccreate-controller-secrets\u201d is executed at the start of the installation. It only needs to be executed once (unless the created secrets are deleted). It creates the following: ca-secret: This is the self-signed CA and its key. This is mounted as a volume in the controller so that it can generate all the required certificates. oes-control-secret: This contains the CA and x509 certs required for SAPOR to talk to the controller. From OES-UI, when we add an agent, SAPOR talks to the controller to generate the required configuration content. Jwt-secret: Used by the controller oes-cacerts: This contains the JAVA key-store \u201ccacerts\u201d that has the self-signed CA added to it. This is mounted on Igor (for remote jenkins), etc. It can be mounted in any of the pods that need to access any extra certificates. The \u201ccreate-controller-secrets\u201d custom job allows for the following (both being optional): Provide your own base \u201ccacerts\u201d: If a customer has 10-20 CAs that need to be added, we could use java \u2018key-tool\u2019 to add all of them and provide that \u201ccacerts\u201d as the base to which the controller CA is added. Provide your CAs: If a customer wants their own CA to be added, this can optionally be provided. It is added into the base \u201ccacerts\u201d that are already baked into the image. values.yaml: forwarder.enabled: true (If false, remove mounts in default/service-settings.) Files: templates/forwarder Note It is OK to rerun this job by deleting all the secrets created by it. This may be required, for example, to add another CA. However, ensure that SAPOR controller and any pods mounting \u201coes-cacerts\u201d are restarted. All agent manifests should be deleted, re-created via the OES-UI and re-applied in the remote clusters. Only to rename the \u201ccontroller-agent-grpc\u201d endpoint, rerunning this job is NOT required. Simply update the controller configMap and restart the controller. The controller creates its own certs based on the \u201cca-secret\u201d contents. As it recreates it every time on start-up, running this job is not required. Do download the agent manifests afresh.","title":"Create-controller-secrets (Agent Configuration)"},{"location":"Helm%20Chart%20based%20installation/#chart-custom-ca","text":"OES Helm chart fully supports the use of a custom CA (Certificate Authority). This is done in two parts: The \u201ccreate-controller-secrets\u201d job allows you to include a CA in \u201coes-cacerts\u201d secret. Ensure that custom CA is part of \u201coes-cacerts\u201d. This secret is mounted in all the pods, both in OES and Spinnaker. In OES it is mounted by specifying the flag in \u201c values.yaml \u201d and in Spinnaker is mounted by adding entries to \u201c .hal/default/service-settings/ .yml*\u201d files values.yaml: global.customCerts.enabled: true (Default is false) global.customCerts.secretName (DO NOT CHANGE) Files: standard-gitops repo, default/service-settings/*.yml. Note To test this, access the resources and look for SSL exceptions in pod-logs.","title":"Chart-Custom CA"},{"location":"Helm%20Chart%20based%20installation/#chart-airgapped-install","text":"OES Helm chart fully supports installing in an airgapped environment. This is done in the following way: Obtain all docker images required and upload to local image repository In \u201cvalues.yaml\u201d, update global.customImage.registry as appropriate Use the \u201copsmx/airgap-repo\u201d instead of the \u201cstandard-gitops\u201d repo. Note The repo contains \u201c.boms\u201d folder that may not be listed with ls command. Images repo locations need to be updated as appropriate In addition, OES uses \u201cplugin-framework\u201d for adding functionality to Spinnaker. Spinnaker natively supports PF4J that requires downloading files from an unauthenticated git repository. If an unauthenticated git repository is available within the airgapped environment: Update \u201c spinnaker.extensibility.repositories.url \u201d in the \u201coes-gate\u201d configmap to point to a repo that is reachable by Spinnaker. Copy the contents from the opsmx repo into the local repo. Update the same parameter in \u201c orca-local.yml \u201d (in .hal/defaults/profile)","title":"Chart-Airgapped Install"},{"location":"Helm%20Chart%20based%20installation/#halyard-gitops","text":"This section describes the basics of how the gitOps works and the various players in the process. There is a repo (github repo for this document, but could be S3, bitbucket, etc), typically copied from \u201c github.com/opsmx/standard-gitops repo \u201d This repo contains files that are used by Spinnaker Halyard. All the contents of \u201c /home/spinnaker/.hal \u201d inside the halyard pod are placed there by pulling them from the repo and editing them to replace certain values. OES updates the spinnaker configuration by writing to this repo. Spinnaker configuration is updated by restarting the halyard pod. This process is enabled by multiple \u201c init \u201d containers that run before the main halyard container. values.yaml: spinnaker.gitOpsHalyard.* Spinnaker.spinCli.* Files: charts/spinnaker/templates & charts/spinnaker/config","title":"Halyard GitOps"},{"location":"Helm%20Chart%20based%20installation/#container-create-halyard-local","text":"This is the first container that executes the \u201cinit.sh\u201d script that is located in the \"*-opsmx-spinnaker-halyard-init-script\u201d configMap. Note that the script gets modified based on the repo-type during the installation process. Here is a high-level description of the script: Clone the \u201cgit-repo\u201d Replace \u201cSPINNAKER_NAMESPACE\u201d string in \u201c.hal/config, default/profiles/fiat-local.yml\u201d, \u201corca-local.yml\u201d (custom jobs) Replace \u201cRELEASE_NAME\u201d string in \u201c.hal/config, redis.yml\u201d in \u201cdefault/service-settings\u201d Replaces \u201cGIT_TOKEN\u201d, \u201cGIT_USER\u201d and \u201cDYNAMIC_ACCNT_CONFIG\u201d in \u201cdefault/profiles/spinnakerconfig.yml\u201d","title":"Container: create-halyard-local"},{"location":"Helm%20Chart%20based%20installation/#container-halyardconfig-update","text":"As we use git-repo for halyard configuration, secrets used by halyard (for example, account passwords) could be exposed to anyone who has git-repo access. OES chart supports using Kubernetes secrets in halyard configuration. The procedure is as follows: Manually create a Kubernetes secret with a key and password in the spinnaker namespace. Create it as: K create secret generic --from-literal =MYSECRET In the \u201c git-repo \u201d, refer to it as encrypted:: in the files where it is used If need to encrypt a File, create the secret and refer to it as encryptedFile:: Create it as, k create secret generic SECRETNAME --from-file This init container runs the \u201crun.sh\u201d script in -opsmx-spinnaker-spin-secret-decoder configMap that searches and replaces all values as appropriate.","title":"Container: halyardconfig-update"},{"location":"Helm%20Chart%20based%20installation/#container-halyard-overrideurl","text":"OES requires 3 (max 5 including controller) end-points that need to be reachable from the web-browser. These are: oes-ui oes-gate Spin-deck spin-gate (only if NOT using the common-gate, usually not required) \"agent-grpc\" service of the controller (if configuring agent/controller) Routing Web-URLs to OES and Spinnaker pods requires multiple configurations depending on the following URLs type: Ingress: In this model there is one loadbalancer/IP that routes traffic to an ingress controller (e.g. nginx). The ingress controller looks at the URL string (example, spin.saas.opsmx.com or oes.saas.opsmx.com) and based on this string routes the traffic to the appropriate pod. Note that for this to work, DNS (example, www.godaddy.com) is a critical requirement as IP address needs to be translated to URLs. Load Balancers: Most cloud providers have automatic load balancer provisioning. This allows for any service to have an external IP and traffic is directly routed to the appropriate service or pod. In addition, we can still use the DNS to reach the LB. Node Port: In case load balancer is not available, Kubernetes allows IP address of any of the worker nodes to be used with a \u201cnode port\u201d (instead of the service-port) to route the traffic to pods HTTP or HTTPS If using HTTPS, additional complexity comes in the form TLS certificates and termination. Ingress: In most cases, ingress will allow for TLS termination. Coupled with cert-manager+ACME, automatic certificates can be generated. Default OES installation assumes \u201cnginx\u201d and \u201ccert-manager\u201d. If using custom-certificates, these need to be generated and provided to ingress controller for TLS termination. This is easily done by create the TLS secrets mentioned in the default ingress objects created (kubectl get ing) If using any other ingress (other than nginx), the ingress object configuration has to be changed accordingly. Load Balancers: Most cloud providers provide options for TLS termination at the Load Balancer. If this option is chosen (makes sense only if DNS is in place), the certificates need to be loaded to the cloud provider for TLS termination. Node Port: In this case, it is assumed that we are in development mode and HTTPS is not supported. values.yaml: global.spinDeck.host, oesUI.host, oesGate.host, spinGate.host, protocol k8sServiceType: ClusterIP or LoadBalancer This init container runs the \u201ccall_overrides.sh\u201d script in *-opsmx-spinnaker-halyard-overrideurl configMap. This is designed to support 3 situations: Gate and deck use ingress and URLs are provided and gitops is in use. In this case, the hal/config overrideUrls are edited to appropriate values. No URLs are provided, load-balancer IP is used for figuring out the URLs for gate and deck. No URLs are provided and there is no external IP for the load-balancer after waiting for 5 minutes. In this case, Node IP with node-ports is used for configuring the gate and deck URLs.","title":"Container: halyard-overrideurl"},{"location":"Helm%20Chart%20based%20installation/#container-halyard","text":"This is the main halyard container that runs the halyard executable. There is a postStart lifecycle hook that waits for the halyard process to be ready and then executes \u201c hal deploy apply \u201d. Note If you see any errors, check the logs of the \u201ccreate-halyard-local container\u201d. In most cases, it is unable to fetch the repo because the git-token may be incorrect or has expired. If the halyard pod stays hung in \u201cpodInitializing\u201d state for more than 5 minutes, it means that the halyard daemon process is unable to start. The issue here is most likely related to \u201chalyard-local.yml\u201d file in the \u201cstandard-gitops repo\u201d. Easiest way to debug is to remove the \u201cpoststart\u201d lifecycle hook and check the container logs, \u201cexec\u201d into the container and execute \u201chal-deploy-apply\u201d manually. If we see \u201cdecryption\u201d errors in \u201chal-deploy-apply\u201d, most likely the cause is the mismatch between SAPOR encryption and halyard decryption. SAPOR encrypt key can be found in bootstrap secret and oes-sapor-config CM. Halyard decrypt key is found in .hal/default/profiles/spinnakerconfig.yml","title":"Container: halyard"},{"location":"Helm%20Chart%20based%20installation/#install-using-hal","text":"This is the primary installer in the Spinnaker helm-chart. This has been modified to add a container. values.yaml: spinnaker.spinCli.* Files: charts/spinnaker/templates/hooks/install-using-hal.yaml & charts/spinnaker/templates/secrets/spin-config.yaml","title":"Install-using-hal"},{"location":"Helm%20Chart%20based%20installation/#sample-pipeline-install","text":"This creates the following applications in Spinnaker, \u201cOpsmx-gitops\u201d application in spinnaker is needed for \u201cRestart Spinnaker\u201d in OES UI to work. It also contains the \u201csyncToGit\u201d and \u201csyncToSpinnaker\u201d pipeline promotion pipelines for backing up Spinnaker applications. \u201csampleapp\u201d application contains a few sample pipelines to demonstrate spinnaker functionality and also act as a quick reference. This container (not an init container) executes the \u201cspin-pipeline-import.sh\u201d script that: Waits for all spinnaker services to be up. Clones the sample pipeline repo at \u201c https://github.com/OpsMx/sample-pipelines.git \u201d. Executes \u201cspin-cli\u201d commands to push sample pipelines into Spinnaker. For this it needs the gate-API url, username and password that is taken from a secret created from values.yaml, spinnaker.spinCli section. Note This step is mandatory. Opsmx-gitops application is needed for restart functionality to work. If sampleapp is not there in spinnaker after install, check the logs of this container.","title":"sample-pipeline-install"},{"location":"ISD%20-%20Commonly%20used%20Commands/","text":"ISD - Commonly used Commands Basic commands for OpsMx ISD This document contains a list of basic commands that can be useful when working with OpsMx ISD. Working with pods kubectl get pods -n <namespace> # to list down pods kubectl delete po <pod-id> -n <namespace> #for deleting the pods kubectl exec -it <pod id> -n <namespace> -- bash # for getting into the pod kubectl scale deploy <deployment-name> -n <name-space> --replicas=0 #for scaling down the pods kubectl scale deploy -n --replicas=1 #for scaling up the pods kubectl describe pod -n # to describe a pod kubectl logs -f -n #to get the running status of a pod kubectl logs -f -n > #to get the running status of a pod into a file kubectl apply -f <filename.yaml> -n #to create a service/secret/job Working with Secrets kubectl get secrets -n #to get all the secrets kubectl get secret -n -o yaml #to view a particular secret kubectl get secret -n -o yaml #to edit the secret echo -n <encode/decode-content> | base64 -d/-e -w0 #to encode/decode a secret Creating platform secrets kubectl -n get secrets oes-platform-config -o jsonpath=\u2018{.data.platform-local.yml}\u2019 | base64 -d > platform-local.yml If needed, edit the platform-local.yml file kubectl -n delete secret oes-platform-config kubectl -n create secret generic oes-platform-config --from-file platform-local.yml Creating gate secrets kubectl -n get secrets oes-gate-config -o jsonpath=\u2018{.data.gate.yml}\u2019 | base64 -d > gate.yml If needed, edit the gate.yml file kubectl -n delete secret oes-gate-config kubectl -n create secret generic oes-gate-config --from-file gate.yml Creating sapor secrets kubectl -n get secrets oes-sapor-config -o jsonpath='{.data.application.yml}' | base64 -d > application.yml If needed, edit the application.yml file kubectl -n delete secret oes-sapor-config kubectl -n create secret generic oes-sapor-config --from-file application.yml Working with deployments kubectl get deploy -n <namespace> # to get list of all the deployments kubectl get deploy <deployment-name> -n <namespace> -o yaml #to view a particular deployment kubectl edit deploy <deployment-name> -n <namespace> #to edit a deployment kubectl scale deploy <deployment-name> --replicas=0 -n <namespace> #to scale-down a deployment kubectl scale deploy <deployment-name> --replicas=1 -n <namespace> #to scale-up a deployment echo -n <encode/decode-content> | base64 -d/-e -w0 #to encode/decode a deployment Working with Configmaps kubectl get cm -n # to get the list of all configmaps kubectl get cm -n -o yaml # to get the details of the configmap kubectl edit cm -n # to edit the configmap Working with services kubectl get svc -n # to get the list of all services kubectl get svc -n -o yaml # to view a service kubectl edit svc -n # to edit a service Working with the jobs kubectl get jobs -n # to get the list of all jobs kubectl get job -n -o yaml # to view a job kubectl describe job -n -o yaml # to describe a job kubectl edit job -n # to edit a job kubectl delete job -n # to delete a job To check the ingress kubectl get ing -n # to get the ingress","title":"ISD   Commonly used Commands"},{"location":"ISD%20-%20Commonly%20used%20Commands/#isd-commonly-used-commands","text":"","title":"ISD - Commonly used Commands"},{"location":"ISD%20-%20Commonly%20used%20Commands/#basic-commands-for-opsmx-isd","text":"This document contains a list of basic commands that can be useful when working with OpsMx ISD. Working with pods kubectl get pods -n <namespace> # to list down pods kubectl delete po <pod-id> -n <namespace> #for deleting the pods kubectl exec -it <pod id> -n <namespace> -- bash # for getting into the pod kubectl scale deploy <deployment-name> -n <name-space> --replicas=0 #for scaling down the pods kubectl scale deploy -n --replicas=1 #for scaling up the pods kubectl describe pod -n # to describe a pod kubectl logs -f -n #to get the running status of a pod kubectl logs -f -n > #to get the running status of a pod into a file kubectl apply -f <filename.yaml> -n #to create a service/secret/job Working with Secrets kubectl get secrets -n #to get all the secrets kubectl get secret -n -o yaml #to view a particular secret kubectl get secret -n -o yaml #to edit the secret echo -n <encode/decode-content> | base64 -d/-e -w0 #to encode/decode a secret Creating platform secrets kubectl -n get secrets oes-platform-config -o jsonpath=\u2018{.data.platform-local.yml}\u2019 | base64 -d > platform-local.yml If needed, edit the platform-local.yml file kubectl -n delete secret oes-platform-config kubectl -n create secret generic oes-platform-config --from-file platform-local.yml Creating gate secrets kubectl -n get secrets oes-gate-config -o jsonpath=\u2018{.data.gate.yml}\u2019 | base64 -d > gate.yml If needed, edit the gate.yml file kubectl -n delete secret oes-gate-config kubectl -n create secret generic oes-gate-config --from-file gate.yml Creating sapor secrets kubectl -n get secrets oes-sapor-config -o jsonpath='{.data.application.yml}' | base64 -d > application.yml If needed, edit the application.yml file kubectl -n delete secret oes-sapor-config kubectl -n create secret generic oes-sapor-config --from-file application.yml Working with deployments kubectl get deploy -n <namespace> # to get list of all the deployments kubectl get deploy <deployment-name> -n <namespace> -o yaml #to view a particular deployment kubectl edit deploy <deployment-name> -n <namespace> #to edit a deployment kubectl scale deploy <deployment-name> --replicas=0 -n <namespace> #to scale-down a deployment kubectl scale deploy <deployment-name> --replicas=1 -n <namespace> #to scale-up a deployment echo -n <encode/decode-content> | base64 -d/-e -w0 #to encode/decode a deployment Working with Configmaps kubectl get cm -n # to get the list of all configmaps kubectl get cm -n -o yaml # to get the details of the configmap kubectl edit cm -n # to edit the configmap Working with services kubectl get svc -n # to get the list of all services kubectl get svc -n -o yaml # to view a service kubectl edit svc -n # to edit a service Working with the jobs kubectl get jobs -n # to get the list of all jobs kubectl get job -n -o yaml # to view a job kubectl describe job -n -o yaml # to describe a job kubectl edit job -n # to edit a job kubectl delete job -n # to delete a job To check the ingress kubectl get ing -n # to get the ingress","title":"Basic commands for OpsMx ISD"},{"location":"ISD%20Architecture/","text":"ISD Architecture Architecture The figure below depicts the component view of the ISD architecture. As mentioned earlier, it consists of two modules, Orchestration, and the Data & Intelligence module. ISD Services ISD consists of the following services. Autopilot = Verification service SAPOR = connect with Spinnaker and git/S3 Repo for updating dynamic accounts Visibility = implementation of approval service Dashboard = Collate data for graphical presentation of applications and pipelines OES-Gate = Authentication gateway Sapor-gate = OPTIONAL: spin-gate with basic-auth for Sapor communication Controller = OPTIONAL: remote deployments (Not shown in the Schematic below) OES-UI = Serves the UI elements (Not shown in the Schematic below) These services also use two databases: OES-db : Postgres DB customized for OES OES-redis : Used by OES-gate Apart from these, OES includes all the Spinnaker components, configured in HA mode. Spinnaker services functional roles are as follows: Deck (GUI) Gate (API) Clouddriver (Deployments) Orca (Orchestrator) Echo (Notifications) Front50 (DB Frontend) Redis (Execution cache) Key communication paths in the ISD: SAPOR Service communicates with the Spinnaker Gateway and makes API calls to retrieve data, update pipelines, etc. SAPOR can also be configured to use Sapor-gate which uses Basic Authentication. This is useful in cases where Spinnaker is configured with 2-factor authentication. Application is designed based on API-gateway architecture. All data from the web-browser goes through: OES-gate or Spin-gate Ingress ISD requires 5 ingress points: Spinnaker UI : spin-deck service on port 9000 Spinnaker Gate: spin-gate service on port 8084 OES UI: OES-UI service on port 8080 OES gate: OES-API service on port 8084 Controller: For an agent to contact the controller, we need an ingress/LB. Note that TLS + gRPC traffic needs to be routed to the controller, shown in red.","title":"ISD Architecture"},{"location":"ISD%20Architecture/#isd-architecture","text":"","title":"ISD Architecture"},{"location":"ISD%20Architecture/#architecture","text":"The figure below depicts the component view of the ISD architecture. As mentioned earlier, it consists of two modules, Orchestration, and the Data & Intelligence module. ISD Services ISD consists of the following services. Autopilot = Verification service SAPOR = connect with Spinnaker and git/S3 Repo for updating dynamic accounts Visibility = implementation of approval service Dashboard = Collate data for graphical presentation of applications and pipelines OES-Gate = Authentication gateway Sapor-gate = OPTIONAL: spin-gate with basic-auth for Sapor communication Controller = OPTIONAL: remote deployments (Not shown in the Schematic below) OES-UI = Serves the UI elements (Not shown in the Schematic below) These services also use two databases: OES-db : Postgres DB customized for OES OES-redis : Used by OES-gate Apart from these, OES includes all the Spinnaker components, configured in HA mode. Spinnaker services functional roles are as follows: Deck (GUI) Gate (API) Clouddriver (Deployments) Orca (Orchestrator) Echo (Notifications) Front50 (DB Frontend) Redis (Execution cache) Key communication paths in the ISD: SAPOR Service communicates with the Spinnaker Gateway and makes API calls to retrieve data, update pipelines, etc. SAPOR can also be configured to use Sapor-gate which uses Basic Authentication. This is useful in cases where Spinnaker is configured with 2-factor authentication. Application is designed based on API-gateway architecture. All data from the web-browser goes through: OES-gate or Spin-gate","title":"Architecture"},{"location":"ISD%20Architecture/#ingress","text":"ISD requires 5 ingress points: Spinnaker UI : spin-deck service on port 9000 Spinnaker Gate: spin-gate service on port 8084 OES UI: OES-UI service on port 8080 OES gate: OES-API service on port 8084 Controller: For an agent to contact the controller, we need an ingress/LB. Note that TLS + gRPC traffic needs to be routed to the controller, shown in red.","title":"Ingress"},{"location":"ISD%20Deployment%20Architecture/","text":"ISD Deployment Architecture Introduction ISD is an application layer built on top of Spinnaker that provides value-added services such as verification gates, approval gates, and Policy enforcement. ISD Components It consists of the following services: Autopilot = Verification service SAPOR = Connect with Spinnaker and git/S3 Repo for updating dynamic accounts Visibility = Implementation of approval service Dashboard = Collate data for graphical presentation of applications and pipelines oes-Gate = Authentication gateway Sapor-gate = OPTIONAL: spin-gate with basic-auth for Sapor communication Controller = OPTIONAL: remote deployments (Not shown in the Schematic below) oes-ui = Serves the UI elements (Not shown in the Schematic below) These services also use two databases: Oes-db : Postgres DB customized for oes oes-redis : Used by oes-gate Apart from these, OES includes all the Spinnaker components, configured in HA mode. Spinnaker services functional roles are as follows: Deck (GUI) Gate (API) Cloud driver (Deployments) Orca (Orchestrator) Echo (Notifications) Front50 (DB Frontend) Redis (Execution cache) The schematic is as follows: Key communication paths in the ISD: SAPOR Service communicates with the Spinnaker Gateway and makes API calls to retrieve data, update pipelines, etc. SAPOR can also be configured to use Sapor-gate which uses Basic Authentication. This is useful in cases where Spinnaker is configured with 2-factor authentication. Application is designed based on API-gateway architecture. All data from the web browser goes through: OES-gate Spin-gate Ingress ISD requires three to five ingress points: Spinnaker UI : spin-deck service on port 9000 Spinnaker Gate: spin-gate service on port 8084 OES UI: oes-ui service on port 8080 OES gate: oes-api service on port 8084 == this can be used as \u201ccommon gate: for OES and Spinnaker Controller: For agent to contact the controller, we need an ingress/LB. Note that TLS+gRPC traffic needs to be routed to the controller, shown in red. This is optional The schematic including ingress is as follows(Istio ingress is only an example): Controller Configuration The controller allows for deploying to remote clusters that may not have inbound network access. All communication between Spinnaker and the remote cluster is routed via a controller and an agent. The controller is automatically installed and configured for use in OES 3.5 and beyond. Overview Spinnaker is configured to use the controller as the \u201ctarget\u201d server for various functions. For example, for a remote kubernetes account, Spinnaker will get a kubeconfig file where the server address is that of the controller. Similarly, for Jenkins, AWS, and other remote servers, the server name is replaced with that of the controller. The controller forwards all the http traffic to the agent, which then re-transmits them to the real, target server (kube-API server, jenkins server, etc.). In the schematic above communication shown in red uses shared TLS certificates making the communication extremely secure. Self-signed certificates are generated by default and can be replaced post-installation. Dynamic account configuration must be used for the controller configuration to work from OES-UI. Key points: All communication with the controller is HTTPS or TLS Agent communication with the controller is TLS over gRPC The controller needs to be provided with a CA and Key as it generates the tls-certs for all other parties. As we use, by default, a self-signed CA, all other parties i.e. SAPOR and Spinnaker-services need to trust this CA. All this is handled by the helm-install process. What is happening behind the scenes: There is a job (\u201ccreate-secrets\u201d) that creates two secrets: ca-secret : This contains CA-cert and key. This is used by the controller for stamping out all other certificates oes-control-secret: This contains the TLS cert+key that is used by SAPOR to contact the controller [Note: oes-control-secret was called oes-command-secret before 3.7] Whenever a user turns the \u201cremote\u201d slider button in OES->settings->cloud-accounts->create account, SAPOR connects to the controller to check if it is reachable. On \u201csave\u201d, sapor makes API calls to the controller and creates: A kubeconfig file, that is updated in the git-repo for dynamic accounts and is eventually used by Spinnaker for deployment A manifest YAML file is available for download. The user is expected to download the YAML manifest and apply it in the remote cluster. While the schematic shows one controller and one agent, the system supports multiple agents in multiple clusters in HA mode i.e. there can be multiple controllers and agents. The controller is written in golang and has been open-sourced. Source code can be downloaded from: https://github.com/OpsMx/oes-birger Deployment and Upgrade ISD is provided in a helm package and is installed using the helm command. The helm install does the following: Processes values.yaml file and processes all the helm templates All kubernetes objects are applied in the given namespace Pipeline-gitops secrets and config maps are created in the \u201cdefault\u201d namespace. There are two jobs that have do additional functions: Create secrets for the controller CA configuration Automatically configure Github, Spinnaker, Autopilot, and OPA integrations based on the values provided in values.yaml The upgrade is done using helm as well. The upgrade ensures that the two Jobs executed during the installation process are not re-executed. GitOps Configuration GitOps is an operational paradigm that says that the target environment is in sync with a git repo. While we do not have full GitOps, the model being followed can be extended to GitOps in the future. Fundamentally, all the configuration information for Spinnaker is stored in a directory \u201c.hal\u201d inside the halyard-pod. The \u201cnormal\u201d spinnaker installation requires a persistent store (PV) to be mounted at this mount point (/home/spinnaker). In gitOps halyard, we have an init container in the statefulset that clones a git-repo (or Vault or S3) and processes the files before placing them in .hal directory. There is no persistent storage, thereby reducing the associated security risks. Any change required can be done in the git-repo. Once the halyard pod is restarted, the changes become effective. The schematic looks as follows: While the schematic shows three repositories, it is possible to use one repository for all three purposes.","title":"ISD Deployment Architecture"},{"location":"ISD%20Deployment%20Architecture/#isd-deployment-architecture","text":"","title":"ISD Deployment Architecture"},{"location":"ISD%20Deployment%20Architecture/#introduction","text":"ISD is an application layer built on top of Spinnaker that provides value-added services such as verification gates, approval gates, and Policy enforcement.","title":"Introduction"},{"location":"ISD%20Deployment%20Architecture/#isd-components","text":"It consists of the following services: Autopilot = Verification service SAPOR = Connect with Spinnaker and git/S3 Repo for updating dynamic accounts Visibility = Implementation of approval service Dashboard = Collate data for graphical presentation of applications and pipelines oes-Gate = Authentication gateway Sapor-gate = OPTIONAL: spin-gate with basic-auth for Sapor communication Controller = OPTIONAL: remote deployments (Not shown in the Schematic below) oes-ui = Serves the UI elements (Not shown in the Schematic below) These services also use two databases: Oes-db : Postgres DB customized for oes oes-redis : Used by oes-gate Apart from these, OES includes all the Spinnaker components, configured in HA mode. Spinnaker services functional roles are as follows: Deck (GUI) Gate (API) Cloud driver (Deployments) Orca (Orchestrator) Echo (Notifications) Front50 (DB Frontend) Redis (Execution cache) The schematic is as follows: Key communication paths in the ISD: SAPOR Service communicates with the Spinnaker Gateway and makes API calls to retrieve data, update pipelines, etc. SAPOR can also be configured to use Sapor-gate which uses Basic Authentication. This is useful in cases where Spinnaker is configured with 2-factor authentication. Application is designed based on API-gateway architecture. All data from the web browser goes through: OES-gate Spin-gate","title":"ISD Components"},{"location":"ISD%20Deployment%20Architecture/#ingress","text":"ISD requires three to five ingress points: Spinnaker UI : spin-deck service on port 9000 Spinnaker Gate: spin-gate service on port 8084 OES UI: oes-ui service on port 8080 OES gate: oes-api service on port 8084 == this can be used as \u201ccommon gate: for OES and Spinnaker Controller: For agent to contact the controller, we need an ingress/LB. Note that TLS+gRPC traffic needs to be routed to the controller, shown in red. This is optional The schematic including ingress is as follows(Istio ingress is only an example):","title":"Ingress"},{"location":"ISD%20Deployment%20Architecture/#controller-configuration","text":"The controller allows for deploying to remote clusters that may not have inbound network access. All communication between Spinnaker and the remote cluster is routed via a controller and an agent. The controller is automatically installed and configured for use in OES 3.5 and beyond.","title":"Controller Configuration"},{"location":"ISD%20Deployment%20Architecture/#overview","text":"Spinnaker is configured to use the controller as the \u201ctarget\u201d server for various functions. For example, for a remote kubernetes account, Spinnaker will get a kubeconfig file where the server address is that of the controller. Similarly, for Jenkins, AWS, and other remote servers, the server name is replaced with that of the controller. The controller forwards all the http traffic to the agent, which then re-transmits them to the real, target server (kube-API server, jenkins server, etc.). In the schematic above communication shown in red uses shared TLS certificates making the communication extremely secure. Self-signed certificates are generated by default and can be replaced post-installation. Dynamic account configuration must be used for the controller configuration to work from OES-UI. Key points: All communication with the controller is HTTPS or TLS Agent communication with the controller is TLS over gRPC The controller needs to be provided with a CA and Key as it generates the tls-certs for all other parties. As we use, by default, a self-signed CA, all other parties i.e. SAPOR and Spinnaker-services need to trust this CA. All this is handled by the helm-install process. What is happening behind the scenes: There is a job (\u201ccreate-secrets\u201d) that creates two secrets: ca-secret : This contains CA-cert and key. This is used by the controller for stamping out all other certificates oes-control-secret: This contains the TLS cert+key that is used by SAPOR to contact the controller [Note: oes-control-secret was called oes-command-secret before 3.7] Whenever a user turns the \u201cremote\u201d slider button in OES->settings->cloud-accounts->create account, SAPOR connects to the controller to check if it is reachable. On \u201csave\u201d, sapor makes API calls to the controller and creates: A kubeconfig file, that is updated in the git-repo for dynamic accounts and is eventually used by Spinnaker for deployment A manifest YAML file is available for download. The user is expected to download the YAML manifest and apply it in the remote cluster. While the schematic shows one controller and one agent, the system supports multiple agents in multiple clusters in HA mode i.e. there can be multiple controllers and agents. The controller is written in golang and has been open-sourced. Source code can be downloaded from: https://github.com/OpsMx/oes-birger","title":"Overview"},{"location":"ISD%20Deployment%20Architecture/#deployment-and-upgrade","text":"ISD is provided in a helm package and is installed using the helm command. The helm install does the following: Processes values.yaml file and processes all the helm templates All kubernetes objects are applied in the given namespace Pipeline-gitops secrets and config maps are created in the \u201cdefault\u201d namespace. There are two jobs that have do additional functions: Create secrets for the controller CA configuration Automatically configure Github, Spinnaker, Autopilot, and OPA integrations based on the values provided in values.yaml The upgrade is done using helm as well. The upgrade ensures that the two Jobs executed during the installation process are not re-executed.","title":"Deployment and Upgrade"},{"location":"ISD%20Deployment%20Architecture/#gitops-configuration","text":"GitOps is an operational paradigm that says that the target environment is in sync with a git repo. While we do not have full GitOps, the model being followed can be extended to GitOps in the future. Fundamentally, all the configuration information for Spinnaker is stored in a directory \u201c.hal\u201d inside the halyard-pod. The \u201cnormal\u201d spinnaker installation requires a persistent store (PV) to be mounted at this mount point (/home/spinnaker). In gitOps halyard, we have an init container in the statefulset that clones a git-repo (or Vault or S3) and processes the files before placing them in .hal directory. There is no persistent storage, thereby reducing the associated security risks. Any change required can be done in the git-repo. Once the halyard pod is restarted, the changes become effective. The schematic looks as follows: While the schematic shows three repositories, it is possible to use one repository for all three purposes.","title":"GitOps Configuration"},{"location":"ISD%20GitOps%20Installation/","text":"ISD GitOps Installation The document is primarily intended to be used for standard ISD GitOps installation. Infrastructure and Laptop requirements Before you start, it might be helpful to go through these documents: The infrastructure required for a non-prod installation can be found here The infrastructure required for a Production Setup can be found here Basic requirements of a laptop and Kubernetes cluster can be found here . If you need a different infrastructure, please contact OpsMx. Create your git-repo ISD stores all the configuration in a repo, typically a ' git repo ', though bitbucket, S3, and others are supported. Create an empty-repo (called the \"gitops-repo\" in the document), \"main\" branch should be the default and clone it locally. Clone https://github.com/OpsMx/standard-isd-gitops , selecting the appropriate branch: git clone https://github.com/OpsMx/standard-isd-gitops -b 4.0 Copy contents of the standard-isd-repo to the gitops-repo created above using: cp -r standard-isd-gitops/* gitops-repo # Replace \"gitops-repo\" with your repo-name and cd to the gitops-repo e.g. cd gitops-repo . Specify inputs Specify the inputs based on your environment and git-repo. The installation process requires inputs such as the application version, git-repo details, etc. In the gitops-repo cloned to disk and edit install/inputcm.yaml. This should be updated, at a minimum, with gitrepo and username. Update Values.yaml as required , specifically: At minimum the ISD URL and gitops-repo details in the spinnaker.gitopsHalyard section must be updated. Full values.yaml is available at the following link : https://github.com/OpsMx/enterprise-spinnaker/tree/v3.12/charts/oes Note We recommend that we start with the defaults, updating just the URL and gitopsHalyard details and gradually adding SSO, external DBs, etc. while updating the installed instance. Edit namespace in the install/services.yaml file, if changed from default (i.e. \"opsmx-isd\") Push all changes in the gitops-repo to git (E.g git add -A; git commit -m\"my changes\";git push ). Create namespace, a configmap for inputs and a service account as follows: kubectl create ns opsmx-isd kubectl -n opsmx-isd apply -f install/inputcm.yaml kubectl -n opsmx-isd apply -f install/serviceaccount.yaml # Edit namespace in the yaml if changed from the default and update the kubectl command. Create secrets ISD supports multiple secret managers for storing secrets such as DB passwords, SSO authentication details, and so on. Using Kubernetes secrets is the default. Create the following secrets. The default values are handled by the installer, except for gittoken. If you are using External SSO, DBs, etc. you might want to change them. Else, best to leave them at the defaults: kubectl -n opsmx-isd create secret generic gittoken --from-literal=gittoken=PUT_YOUR_GITTOKEN_HERE Optional In case we want to change these, please enter the correct values and create the secrets kubectl -n opsmx-isd create secret generic ldapconfigpassword --from-literal ldapconfigpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic ldappassword --from-literal ldappassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic miniopassword --from-literal miniopassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic redispassword --from-literal redispassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic saporpassword --from-literal saporpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic rabbitmqpassword --from-literal rabbitmqpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic keystorepassword --from-literal keystorepassword=PUT_YOUR_SECRET_HERE Start the installation The installation is done by a Kubernetes job that processes the secrets, generates YAMLs, stores them into the git-repo and creates the objects in Kubernetes. Installation of ISD by executing this command: kubectl -n opsmx-isd apply -f install/ISD-Install-Job.yaml Monitor the installation process Wait for all pods to stabilize (about 10-20 min, depending on your cluster load). The \"oes-config\" in Completed status indicates completion of the installation process. Check the status using the following comment: kubectl -n opsmx-isd get po -w Note: If the pod starting with isd-install-* errors out, please check the logs as follows, replacing the pod-name correctly: kubectl -n opsmx-isd logs isd-install-tjzlx -c get-secrets kubectl -n opsmx-isd logs isd-install-tjzlx -c git-clone kubectl -n opsmx-isd logs isd-install-tjzlx -c apply-yamls Note: It is normal for some pods, specifically the oes-ui pod to crash a few times before running. However, if the isd-spinnaker-halyard-0 pod crashes or errors out, please check the logs of the \"create-halyard-local\" init container using this command: kubectl -n opsmx-isd logs isd-spinnaker-halyard-0 -c create-halyard-local Check the installation Access ISD using the URL specified in the values.yaml in step 5 in a browser such as Chrome. Login to the ISD instance with user/password as admin and opsmxadmin123, if using the defaults for build-in LDAP. Note If you are facing any Issues during installation, refer to the Troubleshooting page.","title":"ISD GitOps Installation"},{"location":"ISD%20GitOps%20Installation/#isd-gitops-installation","text":"The document is primarily intended to be used for standard ISD GitOps installation.","title":"ISD GitOps Installation"},{"location":"ISD%20GitOps%20Installation/#infrastructure-and-laptop-requirements","text":"Before you start, it might be helpful to go through these documents: The infrastructure required for a non-prod installation can be found here The infrastructure required for a Production Setup can be found here Basic requirements of a laptop and Kubernetes cluster can be found here . If you need a different infrastructure, please contact OpsMx.","title":"Infrastructure and Laptop requirements"},{"location":"ISD%20GitOps%20Installation/#create-your-git-repo","text":"ISD stores all the configuration in a repo, typically a ' git repo ', though bitbucket, S3, and others are supported. Create an empty-repo (called the \"gitops-repo\" in the document), \"main\" branch should be the default and clone it locally. Clone https://github.com/OpsMx/standard-isd-gitops , selecting the appropriate branch: git clone https://github.com/OpsMx/standard-isd-gitops -b 4.0 Copy contents of the standard-isd-repo to the gitops-repo created above using: cp -r standard-isd-gitops/* gitops-repo # Replace \"gitops-repo\" with your repo-name and cd to the gitops-repo e.g. cd gitops-repo .","title":"Create your git-repo"},{"location":"ISD%20GitOps%20Installation/#specify-inputs","text":"Specify the inputs based on your environment and git-repo. The installation process requires inputs such as the application version, git-repo details, etc. In the gitops-repo cloned to disk and edit install/inputcm.yaml. This should be updated, at a minimum, with gitrepo and username. Update Values.yaml as required , specifically: At minimum the ISD URL and gitops-repo details in the spinnaker.gitopsHalyard section must be updated. Full values.yaml is available at the following link : https://github.com/OpsMx/enterprise-spinnaker/tree/v3.12/charts/oes Note We recommend that we start with the defaults, updating just the URL and gitopsHalyard details and gradually adding SSO, external DBs, etc. while updating the installed instance. Edit namespace in the install/services.yaml file, if changed from default (i.e. \"opsmx-isd\") Push all changes in the gitops-repo to git (E.g git add -A; git commit -m\"my changes\";git push ). Create namespace, a configmap for inputs and a service account as follows: kubectl create ns opsmx-isd kubectl -n opsmx-isd apply -f install/inputcm.yaml kubectl -n opsmx-isd apply -f install/serviceaccount.yaml # Edit namespace in the yaml if changed from the default and update the kubectl command.","title":"Specify inputs"},{"location":"ISD%20GitOps%20Installation/#create-secrets","text":"ISD supports multiple secret managers for storing secrets such as DB passwords, SSO authentication details, and so on. Using Kubernetes secrets is the default. Create the following secrets. The default values are handled by the installer, except for gittoken. If you are using External SSO, DBs, etc. you might want to change them. Else, best to leave them at the defaults: kubectl -n opsmx-isd create secret generic gittoken --from-literal=gittoken=PUT_YOUR_GITTOKEN_HERE Optional In case we want to change these, please enter the correct values and create the secrets kubectl -n opsmx-isd create secret generic ldapconfigpassword --from-literal ldapconfigpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic ldappassword --from-literal ldappassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic miniopassword --from-literal miniopassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic redispassword --from-literal redispassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic saporpassword --from-literal saporpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic rabbitmqpassword --from-literal rabbitmqpassword=PUT_YOUR_SECRET_HERE kubectl -n opsmx-isd create secret generic keystorepassword --from-literal keystorepassword=PUT_YOUR_SECRET_HERE","title":"Create secrets"},{"location":"ISD%20GitOps%20Installation/#start-the-installation","text":"The installation is done by a Kubernetes job that processes the secrets, generates YAMLs, stores them into the git-repo and creates the objects in Kubernetes. Installation of ISD by executing this command: kubectl -n opsmx-isd apply -f install/ISD-Install-Job.yaml","title":"Start the installation"},{"location":"ISD%20GitOps%20Installation/#monitor-the-installation-process","text":"Wait for all pods to stabilize (about 10-20 min, depending on your cluster load). The \"oes-config\" in Completed status indicates completion of the installation process. Check the status using the following comment: kubectl -n opsmx-isd get po -w Note: If the pod starting with isd-install-* errors out, please check the logs as follows, replacing the pod-name correctly: kubectl -n opsmx-isd logs isd-install-tjzlx -c get-secrets kubectl -n opsmx-isd logs isd-install-tjzlx -c git-clone kubectl -n opsmx-isd logs isd-install-tjzlx -c apply-yamls Note: It is normal for some pods, specifically the oes-ui pod to crash a few times before running. However, if the isd-spinnaker-halyard-0 pod crashes or errors out, please check the logs of the \"create-halyard-local\" init container using this command: kubectl -n opsmx-isd logs isd-spinnaker-halyard-0 -c create-halyard-local","title":"Monitor the installation process"},{"location":"ISD%20GitOps%20Installation/#check-the-installation","text":"Access ISD using the URL specified in the values.yaml in step 5 in a browser such as Chrome. Login to the ISD instance with user/password as admin and opsmxadmin123, if using the defaults for build-in LDAP. Note If you are facing any Issues during installation, refer to the Troubleshooting page.","title":"Check the installation"},{"location":"ISD%20Installation%20Configuration/","text":"ISD Installation Configuration ISD Installation Configuration In order to configure ISD, first you have to download the values.yaml file. This file specifies the values for the parameters which are provided while installing the chart. To download the file execute the following command: wget https://raw.githubusercontent.com/opsmx/enterprise-spinnaker/master/charts/oes/values.yaml Once you run the above command, the values.yaml file is downloaded in your local machine. Open the values.yaml file in an editor of your choice. The file will look like as shown below: ##################################################### ## OpsMx Enterprise for Spinnaker configuration ##################################################### # Default values for OES chart. ## This is a YAML-formatted file. ## Declare variables to be passed into your templates. ## Name of the secret for pulling image from docker registry. ## Change it only if you want to create a secret with ## different name. ## imagePullSecret: opsmxdev-secret ## Docker registry credentials to create imagePullSecret ## imageCredentials: registry: https://index.docker.io/v1/ username: username # Docker hub username password: password # Docker hub password email: info@opsmx.com # email corresponding to docker hub ID rbac: create: true ## Option to skip installation of spinnaker, if it already exists ## or if OES is to be connected to existing spinnaker ## installSpinnaker: false ## Installation mode ## Available installation modes OES-AP, OES, AP ## installationMode: OES-AP ## Set to true to expose spinnaker and deck services as LoadBalancers ## createIngress: false ## OES UI & Gate service type ## k8sServiceType: LoadBalancer Note The above file is just a sample of the original file and does not consist all the parameters. In the above file, you can edit or customize the parameters as per your requirement. For example - Change the username, password or email under the imageCredentials section as shown below: Similarly you can change the other parameters also. The following table lists the configurable parameters of the ISD chart and their default values: Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } Parameter Description Default imagePullSecret Name of the image pull secret to fetch oes docker images from private registry opsmxdev-secret imageCredentials.registry The registry where OES docker images are available https://index.docker.io/v1/ imageCredentials.username Username of docker account to access docker registry dockerID imageCredentials.password Password of docker account dockerPassword imageCredentials.email Email associated with docker account info@opsmx.com rbac.create Enable or disable rbac true installSpinnaker If true, install Spinnaker along with OES Extensions true installationMode The installation mode. Available installation modes are OES-AP (both OES 3.0 and Autopilot), OES (Only OES 3.0) and AP (Only Autopilot) and None (Skip OES installation) OES-AP createIngress If true, exposes Spinnaker deck & gate services over Ingress false oesUI.protocol Change this to https if TLS is enabled for ingress endpoint http oesUI.host Host using which UI needs to be accessed oes.domain.com k8sServiceType Service Type of oes-ui, oes-gate, spin-deck-ui, spin-gate LoadBalancer installRedis If false, OES will uninstall its own Redis for caching false redis.url Set custom URL if installRedis is set to false redis://{{ .Release.Name }}-redis-master:6379 db.enabled Set it to false if OpsMx DB is already installed on cluster or if any external database is to be used. true db.url URL of the external DB if not using OpsMx DB. jdbc:postgresql://oes-db:5432/opsmx db.storageMountSize Storage to be allocated to OpsMx DB 8Gi autopilot.config.buildAnalysis.enabled Set it to false to disable build analysis false autopilot.config.ssl.enabled Set it to true to enable SSL false autopilot.config.ssl.keystore SSL keystore value keystore.p12 autopilot.config.ssl.keyStorePassword SSL keystore password dummypwd autopilot.config.ssl.keyStoreType SSL keystore type PKCS12 autopilot.config.ssl.keyAlias SSL key alias tomcat dashboard.spinnakerLink Specify if dashboard needs to be configured with a different spinnaker {{ .Values.spinnaker.ingress.protocol }}://{{ .Values.spinnaker.ingress.host }} gate.config.oesUIcors Regex of OES-UI URL to prevent cross origin attacks `^https?://(?:localhost gate.config.fileBasedAuthentication Set it to true to disable LDAP authentication and enable file based authentication false platform.config.adminGroups Admin groups available admin, Administrators platform.config.userSource Source of Users for authorization ldap platform.config.supportedFeatures List of features to be supported by OES [deployment-verification, services, releases, policies] sapor.config.spinnaker.authnEnabled Set it to true if authentication is enabled in Spinnaker false sapor.config.spinnaker.spinGateURL URL of Spinnaker Gate http://spin-gate.oes-spin:8084 sapor.config.spinnaker.spinExternalGateURL Set the external IP address of spin-gate, this is used to redirect to the spinnaker pipelines from OES-UI http://spin-gate.oes-spin:8084 sapor.config.spinnaker.ldap.ldapEnabled Is LDAP authn enabled for spinnaker true sapor.config.spinnaker.ldap.ldapUsername Spinnaker username admin sapor.config.spinnaker.ldap.ldapPassword Spinnaker password opsmxadmin123 sapor.config.spinnaker.x509.enabled Is x509 cert authn enabled for spinnaker false sapor.config.spinnaker.x509.client.password Password of x509 client certificate changeit sapor.config.kubernetes.agent.enabled Option to enable oes kubernetes agent true sapor.config.caCerts.override If default java certs are to be overwritten, create custom config map 'oes-sapor-cacerts.yaml' under templates and set this option to true false ui.config.setApplicationRefreshInterval Interval at which UI refreshes application dashboard 16000 visibility.config.configuredConnectors Integrations options JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS visibility.config.logLevel Default Log Level ERROR autoConfiguration.enabled Option enables OES to be configured automatically. Load Balancer IPs will be automatically replaced in the configuration files of oes-gate, oes-ui & sapor. Set it to false if OES is being installed on restricted environment. true autoConfiguration.initContainer.externalIpCheckDelay Expected delay in assigning load balancer IPs to oes-ui & oes-gate in secs 180 opa.enabled Enable OPA with OES true installOpenLdap If true, installs Open LDAP server false openldap.adminPassword Password to be set for admin user of LDAP opsmxadmin123 ldap.enabled Set it to true if LDAP is to be enabled for OES true ldap.url URL of LDAP server ldap://{{ .Release.Name }}-openldap:389 spinnaker.enableHA Enable HA for orca & echo true spinnaker.enableCentralMonitoring Enable monitoring for Spinnaker false spinnaker.gitops.Halyard.enabled Enable gitops style Halyard and account config false spinnaker.gitopsHalyard.mTLS.enabled Enable mTLS for Spinnaker Services and SSL for Deck and Gate false spinnaker.gitopsHalyard.mTLS.deckIngressHost Ingress host for deck spindeck.{{ .Release.Name }}.domain.com spinnaker.gitopsHalyard.mTLS.gateIngressHost Ingress host for gate spingate.{{ .Release.Name }}.domain.com spinnaker.gitopsHalyard.repo-type Repo type; git, s3, vault git spinnaker.gitopsHalyard.secretName Secret in which git credentials shall be specified, sample secret found under templates/secrets/ opsmx-gitops-auth spinnaker.gitopsHalyard.spinnakerLBCheckDelay Timeout while fetching LB IPs of spin-deck and spin-gate to configure in hal config in seconds 180 spinnaker.gitopsHalyard.gatex509.enabled Flag to enable x509 authentication for gate and use it for webhooks false spinnaker.gitopsHalyard.gatex509.host Separate host for using x509 authentication spingate-x509.domain.com spinnaker.gitopsHalyard.pipelinePromotion.enabled To Enable pipeline promotion from one environment to another false After you have changed the above mentioned properties as per your requirement, install the OES package with the customized values.yaml file to apply the changes. To do so, execute the following command: helm install my-release opsmx/oes -f values.yaml","title":"ISD Installation Configuration"},{"location":"ISD%20Installation%20Configuration/#isd-installation-configuration","text":"","title":"ISD Installation Configuration"},{"location":"ISD%20Installation%20Configuration/#isd-installation-configuration_1","text":"In order to configure ISD, first you have to download the values.yaml file. This file specifies the values for the parameters which are provided while installing the chart. To download the file execute the following command: wget https://raw.githubusercontent.com/opsmx/enterprise-spinnaker/master/charts/oes/values.yaml Once you run the above command, the values.yaml file is downloaded in your local machine. Open the values.yaml file in an editor of your choice. The file will look like as shown below: ##################################################### ## OpsMx Enterprise for Spinnaker configuration ##################################################### # Default values for OES chart. ## This is a YAML-formatted file. ## Declare variables to be passed into your templates. ## Name of the secret for pulling image from docker registry. ## Change it only if you want to create a secret with ## different name. ## imagePullSecret: opsmxdev-secret ## Docker registry credentials to create imagePullSecret ## imageCredentials: registry: https://index.docker.io/v1/ username: username # Docker hub username password: password # Docker hub password email: info@opsmx.com # email corresponding to docker hub ID rbac: create: true ## Option to skip installation of spinnaker, if it already exists ## or if OES is to be connected to existing spinnaker ## installSpinnaker: false ## Installation mode ## Available installation modes OES-AP, OES, AP ## installationMode: OES-AP ## Set to true to expose spinnaker and deck services as LoadBalancers ## createIngress: false ## OES UI & Gate service type ## k8sServiceType: LoadBalancer Note The above file is just a sample of the original file and does not consist all the parameters. In the above file, you can edit or customize the parameters as per your requirement. For example - Change the username, password or email under the imageCredentials section as shown below: Similarly you can change the other parameters also. The following table lists the configurable parameters of the ISD chart and their default values: Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } Parameter Description Default imagePullSecret Name of the image pull secret to fetch oes docker images from private registry opsmxdev-secret imageCredentials.registry The registry where OES docker images are available https://index.docker.io/v1/ imageCredentials.username Username of docker account to access docker registry dockerID imageCredentials.password Password of docker account dockerPassword imageCredentials.email Email associated with docker account info@opsmx.com rbac.create Enable or disable rbac true installSpinnaker If true, install Spinnaker along with OES Extensions true installationMode The installation mode. Available installation modes are OES-AP (both OES 3.0 and Autopilot), OES (Only OES 3.0) and AP (Only Autopilot) and None (Skip OES installation) OES-AP createIngress If true, exposes Spinnaker deck & gate services over Ingress false oesUI.protocol Change this to https if TLS is enabled for ingress endpoint http oesUI.host Host using which UI needs to be accessed oes.domain.com k8sServiceType Service Type of oes-ui, oes-gate, spin-deck-ui, spin-gate LoadBalancer installRedis If false, OES will uninstall its own Redis for caching false redis.url Set custom URL if installRedis is set to false redis://{{ .Release.Name }}-redis-master:6379 db.enabled Set it to false if OpsMx DB is already installed on cluster or if any external database is to be used. true db.url URL of the external DB if not using OpsMx DB. jdbc:postgresql://oes-db:5432/opsmx db.storageMountSize Storage to be allocated to OpsMx DB 8Gi autopilot.config.buildAnalysis.enabled Set it to false to disable build analysis false autopilot.config.ssl.enabled Set it to true to enable SSL false autopilot.config.ssl.keystore SSL keystore value keystore.p12 autopilot.config.ssl.keyStorePassword SSL keystore password dummypwd autopilot.config.ssl.keyStoreType SSL keystore type PKCS12 autopilot.config.ssl.keyAlias SSL key alias tomcat dashboard.spinnakerLink Specify if dashboard needs to be configured with a different spinnaker {{ .Values.spinnaker.ingress.protocol }}://{{ .Values.spinnaker.ingress.host }} gate.config.oesUIcors Regex of OES-UI URL to prevent cross origin attacks `^https?://(?:localhost gate.config.fileBasedAuthentication Set it to true to disable LDAP authentication and enable file based authentication false platform.config.adminGroups Admin groups available admin, Administrators platform.config.userSource Source of Users for authorization ldap platform.config.supportedFeatures List of features to be supported by OES [deployment-verification, services, releases, policies] sapor.config.spinnaker.authnEnabled Set it to true if authentication is enabled in Spinnaker false sapor.config.spinnaker.spinGateURL URL of Spinnaker Gate http://spin-gate.oes-spin:8084 sapor.config.spinnaker.spinExternalGateURL Set the external IP address of spin-gate, this is used to redirect to the spinnaker pipelines from OES-UI http://spin-gate.oes-spin:8084 sapor.config.spinnaker.ldap.ldapEnabled Is LDAP authn enabled for spinnaker true sapor.config.spinnaker.ldap.ldapUsername Spinnaker username admin sapor.config.spinnaker.ldap.ldapPassword Spinnaker password opsmxadmin123 sapor.config.spinnaker.x509.enabled Is x509 cert authn enabled for spinnaker false sapor.config.spinnaker.x509.client.password Password of x509 client certificate changeit sapor.config.kubernetes.agent.enabled Option to enable oes kubernetes agent true sapor.config.caCerts.override If default java certs are to be overwritten, create custom config map 'oes-sapor-cacerts.yaml' under templates and set this option to true false ui.config.setApplicationRefreshInterval Interval at which UI refreshes application dashboard 16000 visibility.config.configuredConnectors Integrations options JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS visibility.config.logLevel Default Log Level ERROR autoConfiguration.enabled Option enables OES to be configured automatically. Load Balancer IPs will be automatically replaced in the configuration files of oes-gate, oes-ui & sapor. Set it to false if OES is being installed on restricted environment. true autoConfiguration.initContainer.externalIpCheckDelay Expected delay in assigning load balancer IPs to oes-ui & oes-gate in secs 180 opa.enabled Enable OPA with OES true installOpenLdap If true, installs Open LDAP server false openldap.adminPassword Password to be set for admin user of LDAP opsmxadmin123 ldap.enabled Set it to true if LDAP is to be enabled for OES true ldap.url URL of LDAP server ldap://{{ .Release.Name }}-openldap:389 spinnaker.enableHA Enable HA for orca & echo true spinnaker.enableCentralMonitoring Enable monitoring for Spinnaker false spinnaker.gitops.Halyard.enabled Enable gitops style Halyard and account config false spinnaker.gitopsHalyard.mTLS.enabled Enable mTLS for Spinnaker Services and SSL for Deck and Gate false spinnaker.gitopsHalyard.mTLS.deckIngressHost Ingress host for deck spindeck.{{ .Release.Name }}.domain.com spinnaker.gitopsHalyard.mTLS.gateIngressHost Ingress host for gate spingate.{{ .Release.Name }}.domain.com spinnaker.gitopsHalyard.repo-type Repo type; git, s3, vault git spinnaker.gitopsHalyard.secretName Secret in which git credentials shall be specified, sample secret found under templates/secrets/ opsmx-gitops-auth spinnaker.gitopsHalyard.spinnakerLBCheckDelay Timeout while fetching LB IPs of spin-deck and spin-gate to configure in hal config in seconds 180 spinnaker.gitopsHalyard.gatex509.enabled Flag to enable x509 authentication for gate and use it for webhooks false spinnaker.gitopsHalyard.gatex509.host Separate host for using x509 authentication spingate-x509.domain.com spinnaker.gitopsHalyard.pipelinePromotion.enabled To Enable pipeline promotion from one environment to another false After you have changed the above mentioned properties as per your requirement, install the OES package with the customized values.yaml file to apply the changes. To do so, execute the following command: helm install my-release opsmx/oes -f values.yaml","title":"ISD Installation Configuration"},{"location":"ISD%20Installation%20Guide/","text":"ISD Installation Guide Installing ISD on a kubernetes cluster This document provides the step-by-step instructions for installing ISD on a kubernetes cluster. Some basic knowledge of command-line interface is required. Before you start, it might be helpful to go through these documents: Routing Web URLs to ISD services - Refer here ISD On-Prem POV Infrastructure requirements - Refer here ISD - Commonly used Commands - Refer here ISD Service Catalogue - Refer here Pre-requisites A laptop/machine being used to install that has the required software mentioned here A kubeconfig file to access the kubernetes cluster A working \u201ckubectl\u201d command. Execute the command below: kubectl get no # to see the nodes kubectl get ns # to see the namespaces These commands should show some output. If required, rename the kubeconfig file as \" config \" and copy to .kube folder in your machine A github repo, and a \u201cpersonal access token\u201d. Instructions for creating these can be found here. NGINX Ingress Controller and cert-manager(if using https) in the cluster. If not already installed, install by using the instructions here Access to a DNS server. If you do not have access to a DNS server, you can add the host-names to \u201chosts\u201d file on your machine by following the instructions here Pre-installation steps Decide on the host names that will be used to access ISD Clone the standard-git-ops repository and copy the contents to your github repository Select a \u201cvalues.yaml\u201d file from the SAMPLES/values-yamls folder in your github repository, and edit the contents Prepare helm for installation Install ISD using the helm command Login to the ISD instance created Installation steps Setup URLs Host names that will be used to access ISD: Three host-names are required as mentioned below: oes.< subdomain>.company.com spin.< subdomain>.company.com oes-gate.< subdomain>.company.com For Example: oes.isd-from-opsmx.opsmx.com Run the following command to get the IP address of the ingress controller kubectl get ingress -n ingress-nginx If you have access to a DNS server, add the three host names from step 1 to the DNS server pointing them to the IP Address in step 2 above. If you do not have access to a DNS server, follow the instructions here to add them locally to your laptop. Prepare gitops repo Prepare your gitops repository as follows: Create a working directory in your local system mkdir opsmx-isd #create a working directory for your installation Clone standard-gitops-repo repository from appropriate branch git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.10 3. Clone your gitops repo using the following command: git clone https://github.com/<your-id>/<gitops-repo> For Example: git clone https://github.com/ravigorremuchu/oes-repo.git 4. Copy files from standard-gitops-repo to your gitops repo cp -R ./standard-gitops-repo/config ./<gitops-repo>/config cp -R ./standard-gitops-repo/halyard.yaml ./<oes-repo>/halyard.yaml cp -R ./standard-gitops-repo/default ./<oes-repo>/default cp -R ./standard-gitops-repo/SAMPLES ./<oes-repo>/SAMPLES 5. Push the changes back to the githup repo cd <oes-repo> git add -A git commit -m \u201cOpsmx standard gitops repo\u201d git push Prepare values file cd ./<gitops-repo>/SAMPLES/values-yamls and select a template values file. Start with \u201c easy-values.yaml \u201d for a very simply insecure installation. Edit the value.yaml file selected as follows: For spinDeck, spinGate, oesUI and oesGate: change the hostnames decided in step 1, which will be used for accessing the OES/Spinnaker For Example: host: spin.oes.opsmx.net host: oes.oes.opsmx.net host: oes-gate-ldap.oes.opsmx.net Go to gitopsHalyard section and update gitops repo information: repo: type: git baseUrlHostName: github.com organization: <org> # e.g \u201csrini\u201d in https://github.com/srini/isd-repo repository: <your cloned repo name> #Eg: isd-repo dynamicAccRepository: <your cloned repo name> #Eg: isd-repo username: your-git-id # https://github.com/srini/isd-repo token: your-git-token # Access token corresponding to above login-id Install ISD Add helm repo and create namespace helm repo list helm repo add opsmx https://helmcharts.opsmx.com/ helm repo update kubectl create namespace opsmx-isd #[create a namespace] Navigate to the directory where values.yaml is saved/modified and begin the installation. This may take up to 30 min depending on the network speed. helm upgrade \u2013install isd opsmx/oes -f easy-values.yaml -n opsmx-isd --timeout 30m Keep monitoring the pods being created using kubectl get po -n opsmx-isd -w Once all the pods show 1/1 or 2/2 or \u201c0/1 completed\u201d status, open your browser and navigate to \u201coes..company.com\u201d, the host name selected in step 1 Login with user name \u2018admin\u2019 and password as \u201copsmxadmin123\u201d Click on \u201c set-up \u201d on the bottom right corner, and proceed to \u201ccloud accounts\u201d Create a kubernetes account, and name it as \u201c default \u201d Common Issues during helm installation Most common issues during installation are related to incorrect values in *-values.yaml. Should you realize that there is a mistake, it is easy to correct it. Update the easy-values.yaml (or which ever file name you are using) Wait for the helm install to error out, it is best to not break the process Simply re-execute the \u201chelm upgrade \u2013install \u2026\u201d command given: helm upgrade \u2013install isd opsmx/oes -f easy-values.yaml -n opsmx-isd --timeout 30m Should this not work, please follow the instructions for \u201cCleaning up\u201d below and start-over. Cleaning up Use the following commands to delete the entire installation from kubernetes Option 1 Issue this command, replace -n option with the namespace helm uninstall isd -n opsmx-isd Option 2 Issue these commands, replace -n option with the namespace kubectl -n opsmx-isd delete deploy --all kubectl -n opsmx-isd delete sts --all kubectl -n opsmx-isd delete svc --all kubectl -n opsmx-isd delete ing --all kubectl -n opsmx-isd delete cm --all kubectl -n opsmx-isd delete secrets --all kubectl -n opsmx-isd delete role --all kubectl -n opsmx-isd delete rolebinding --all kubectl delete ns opsmx-isd","title":"ISD Installation Guide"},{"location":"ISD%20Installation%20Guide/#isd-installation-guide","text":"","title":"ISD Installation Guide"},{"location":"ISD%20Installation%20Guide/#installing-isd-on-a-kubernetes-cluster","text":"This document provides the step-by-step instructions for installing ISD on a kubernetes cluster. Some basic knowledge of command-line interface is required. Before you start, it might be helpful to go through these documents: Routing Web URLs to ISD services - Refer here ISD On-Prem POV Infrastructure requirements - Refer here ISD - Commonly used Commands - Refer here ISD Service Catalogue - Refer here","title":"Installing ISD on a kubernetes cluster"},{"location":"ISD%20Installation%20Guide/#pre-requisites","text":"A laptop/machine being used to install that has the required software mentioned here A kubeconfig file to access the kubernetes cluster A working \u201ckubectl\u201d command. Execute the command below: kubectl get no # to see the nodes kubectl get ns # to see the namespaces These commands should show some output. If required, rename the kubeconfig file as \" config \" and copy to .kube folder in your machine A github repo, and a \u201cpersonal access token\u201d. Instructions for creating these can be found here. NGINX Ingress Controller and cert-manager(if using https) in the cluster. If not already installed, install by using the instructions here Access to a DNS server. If you do not have access to a DNS server, you can add the host-names to \u201chosts\u201d file on your machine by following the instructions here","title":"Pre-requisites"},{"location":"ISD%20Installation%20Guide/#pre-installation-steps","text":"Decide on the host names that will be used to access ISD Clone the standard-git-ops repository and copy the contents to your github repository Select a \u201cvalues.yaml\u201d file from the SAMPLES/values-yamls folder in your github repository, and edit the contents Prepare helm for installation Install ISD using the helm command Login to the ISD instance created","title":"Pre-installation steps"},{"location":"ISD%20Installation%20Guide/#installation-steps","text":"Setup URLs Host names that will be used to access ISD: Three host-names are required as mentioned below: oes.< subdomain>.company.com spin.< subdomain>.company.com oes-gate.< subdomain>.company.com For Example: oes.isd-from-opsmx.opsmx.com Run the following command to get the IP address of the ingress controller kubectl get ingress -n ingress-nginx If you have access to a DNS server, add the three host names from step 1 to the DNS server pointing them to the IP Address in step 2 above. If you do not have access to a DNS server, follow the instructions here to add them locally to your laptop. Prepare gitops repo Prepare your gitops repository as follows: Create a working directory in your local system mkdir opsmx-isd #create a working directory for your installation Clone standard-gitops-repo repository from appropriate branch git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.10 3. Clone your gitops repo using the following command: git clone https://github.com/<your-id>/<gitops-repo> For Example: git clone https://github.com/ravigorremuchu/oes-repo.git 4. Copy files from standard-gitops-repo to your gitops repo cp -R ./standard-gitops-repo/config ./<gitops-repo>/config cp -R ./standard-gitops-repo/halyard.yaml ./<oes-repo>/halyard.yaml cp -R ./standard-gitops-repo/default ./<oes-repo>/default cp -R ./standard-gitops-repo/SAMPLES ./<oes-repo>/SAMPLES 5. Push the changes back to the githup repo cd <oes-repo> git add -A git commit -m \u201cOpsmx standard gitops repo\u201d git push Prepare values file cd ./<gitops-repo>/SAMPLES/values-yamls and select a template values file. Start with \u201c easy-values.yaml \u201d for a very simply insecure installation. Edit the value.yaml file selected as follows: For spinDeck, spinGate, oesUI and oesGate: change the hostnames decided in step 1, which will be used for accessing the OES/Spinnaker For Example: host: spin.oes.opsmx.net host: oes.oes.opsmx.net host: oes-gate-ldap.oes.opsmx.net Go to gitopsHalyard section and update gitops repo information: repo: type: git baseUrlHostName: github.com organization: <org> # e.g \u201csrini\u201d in https://github.com/srini/isd-repo repository: <your cloned repo name> #Eg: isd-repo dynamicAccRepository: <your cloned repo name> #Eg: isd-repo username: your-git-id # https://github.com/srini/isd-repo token: your-git-token # Access token corresponding to above login-id Install ISD Add helm repo and create namespace helm repo list helm repo add opsmx https://helmcharts.opsmx.com/ helm repo update kubectl create namespace opsmx-isd #[create a namespace] Navigate to the directory where values.yaml is saved/modified and begin the installation. This may take up to 30 min depending on the network speed. helm upgrade \u2013install isd opsmx/oes -f easy-values.yaml -n opsmx-isd --timeout 30m Keep monitoring the pods being created using kubectl get po -n opsmx-isd -w Once all the pods show 1/1 or 2/2 or \u201c0/1 completed\u201d status, open your browser and navigate to \u201coes..company.com\u201d, the host name selected in step 1 Login with user name \u2018admin\u2019 and password as \u201copsmxadmin123\u201d Click on \u201c set-up \u201d on the bottom right corner, and proceed to \u201ccloud accounts\u201d Create a kubernetes account, and name it as \u201c default \u201d Common Issues during helm installation Most common issues during installation are related to incorrect values in *-values.yaml. Should you realize that there is a mistake, it is easy to correct it. Update the easy-values.yaml (or which ever file name you are using) Wait for the helm install to error out, it is best to not break the process Simply re-execute the \u201chelm upgrade \u2013install \u2026\u201d command given: helm upgrade \u2013install isd opsmx/oes -f easy-values.yaml -n opsmx-isd --timeout 30m Should this not work, please follow the instructions for \u201cCleaning up\u201d below and start-over. Cleaning up Use the following commands to delete the entire installation from kubernetes Option 1 Issue this command, replace -n option with the namespace helm uninstall isd -n opsmx-isd Option 2 Issue these commands, replace -n option with the namespace kubectl -n opsmx-isd delete deploy --all kubectl -n opsmx-isd delete sts --all kubectl -n opsmx-isd delete svc --all kubectl -n opsmx-isd delete ing --all kubectl -n opsmx-isd delete cm --all kubectl -n opsmx-isd delete secrets --all kubectl -n opsmx-isd delete role --all kubectl -n opsmx-isd delete rolebinding --all kubectl delete ns opsmx-isd","title":"Installation steps"},{"location":"ISD%20Installation%20on%20OpenShift/","text":"ISD Installation on OpenShift Installing ISD on OpenShift platform Refer this detailed instructions for installing ISD on OpenShift platform. Begin your installation: Click Download OES-3.9.1 and README.md. The YAML file for the OES installation and its README will download to your computer. Pre-requisites Download and extract the OES Package \u201ctar -xvf OES-.tar.gz\u201d. Provide the user's quay credentials to get access to the images. Ensure to have a service account that allows the OES Installation process. Installation Steps Navigate to the Directory. cd OES-/charts/oes Edit the values.yaml and update the \"imageCredentials\" as below. registry: https://quay.io/ username: # Quay username password: # Quay password email: emailaddress@domain.com # email corresponding to quay registry ID Enable True for the below if needed. CertManager Ingress OpenLDAP If you are using an existing extern Openshift Route/Ingress, ensure to update the URLs in the below fields. So that all the spinnaker and OES configurations will be done during the installation. Update the GitOps Halyard Section with BitBucket/S3 where ever Halyard is placed. Update the Pipeline Promotion with BitBucket/S3 credentials according to your requirement. Spinnaker Deck URL configuration; url overwhich spinnaker deck will be accessed Spinnaker Gate URL configuration; url overwhich spinnaker gate will be accessed OES-UI url configuration OES-Gate url configuration Update the LDAP details, if you are using a different LDAP. Execute a helm install command to start the installation. cd OES-/charts/oes/ helm install oes . --namespace --timeout 20m E.g. helm install oes . --namespace oes --timeout 20m After completion of installation, below containers will be up and running. Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } NAME READY STATUS RESTARTS AGE oes-autopilot-787685b89f-tkkjg 1/1 Running 3 6h1m oes-dashboard-5d4bbb6fcf-x8f7q 1/1 Running 0 4h13m oes-db-0 1/1 Running 0 5h46m oes-gate-7b54554c5d-g7qs2 1/1 Running 0 5h27m oes-install-using-hal-nkzkj 0/1 Completed 0 5h46m oes-minio-b56cd74df-srrhd 1/1 Running 0 10h oes-platform-6f55f98c96-72dxd 1/1 Running 0 5h27m oes-redis-master-0 1/1 Running 0 10h oes-sapor-8cf5c9556-d9mpk 1/1 Running 0 4h15m oes-spinnaker-halyard-0 1/1 Running 0 10h oes-ui-6fc95cdf94-mj8fc 1/1 Running 0 114m oes-visibility-889f6fcdb-vcwx7 1/1 Running 4 6h1m opa-67c945d7b7-p9mjw 1/1 Running 0 7h5m spin-clouddriver-caching-6bf67f45b8-wwtcj 1/1 Running 0 5h37m spin-clouddriver-ro-75f8d6bbbd-58fnn 1/1 Running 0 5h37m spin-clouddriver-ro-deck-6b499cd544-69nbt 1/1 Running 0 5h37m spin-clouddriver-rw-6f8ff48976-8c27m 1/1 Running 0 5h37m spin-deck-7f74cd96d5-wcc5n 1/1 Running 0 5h37m spin-echo-scheduler-5fdd9fb7b-m7ztn 1/1 Running 0 5h37m spin-echo-worker-5bf4b855fd-qzpp8 1/1 Running 0 5h37m spin-fiat-59578d97f9-8mhvg 1/1 Running 0 5h37m spin-front50-58c69476b8-pp9g4 1/1 Running 0 5h37m spin-gate-6c6cdfc649-7lgvw 1/1 Running 0 5h37m spin-igor-85d986c45d-dphn5 1/1 Running 0 5h37m spin-orca-7f666f4676-sgbzf 1/1 Running 0 5h37m spin-rosco-69fcc9cd7c-ppjnx 1/1 Running 0 5h37m If you are not using any Ingress, create routes for the below services. Oes-ui Oes-gate Spin-deck-lb Spin-gate-lb After the routes are created, update the URLs in the values.yaml in the ingress section and do a \u201chelm upgrade\u201d. This will update all the override URLs in the spinnaker and other OES configurations. Spinnaker Deck URL configuration; url overwhich spinnaker deck will be accessed Spinnaker Gate URL configuration; url overwhich spinnaker gate will be accessed OES-UI url configuration OES-Gate url configuration Enter the below command to execute a \"helm upgrade\" helm upgrade oes . --namespace oes --timeout 20m","title":"ISD Installation on OpenShift"},{"location":"ISD%20Installation%20on%20OpenShift/#isd-installation-on-openshift","text":"","title":"ISD Installation on OpenShift"},{"location":"ISD%20Installation%20on%20OpenShift/#installing-isd-on-openshift-platform","text":"Refer this detailed instructions for installing ISD on OpenShift platform.","title":"Installing ISD on OpenShift platform"},{"location":"ISD%20Installation%20on%20OpenShift/#begin-your-installation","text":"Click Download OES-3.9.1 and README.md. The YAML file for the OES installation and its README will download to your computer.","title":"Begin your installation:"},{"location":"ISD%20Installation%20on%20OpenShift/#pre-requisites","text":"Download and extract the OES Package \u201ctar -xvf OES-.tar.gz\u201d. Provide the user's quay credentials to get access to the images. Ensure to have a service account that allows the OES Installation process.","title":"Pre-requisites"},{"location":"ISD%20Installation%20on%20OpenShift/#installation-steps","text":"Navigate to the Directory. cd OES-/charts/oes Edit the values.yaml and update the \"imageCredentials\" as below. registry: https://quay.io/ username: # Quay username password: # Quay password email: emailaddress@domain.com # email corresponding to quay registry ID Enable True for the below if needed. CertManager Ingress OpenLDAP If you are using an existing extern Openshift Route/Ingress, ensure to update the URLs in the below fields. So that all the spinnaker and OES configurations will be done during the installation. Update the GitOps Halyard Section with BitBucket/S3 where ever Halyard is placed. Update the Pipeline Promotion with BitBucket/S3 credentials according to your requirement. Spinnaker Deck URL configuration; url overwhich spinnaker deck will be accessed Spinnaker Gate URL configuration; url overwhich spinnaker gate will be accessed OES-UI url configuration OES-Gate url configuration Update the LDAP details, if you are using a different LDAP. Execute a helm install command to start the installation. cd OES-/charts/oes/ helm install oes . --namespace --timeout 20m E.g. helm install oes . --namespace oes --timeout 20m After completion of installation, below containers will be up and running. Title of the document table, th, td { padding: 2px; border: 1px solid black; border-collapse: collapse; } NAME READY STATUS RESTARTS AGE oes-autopilot-787685b89f-tkkjg 1/1 Running 3 6h1m oes-dashboard-5d4bbb6fcf-x8f7q 1/1 Running 0 4h13m oes-db-0 1/1 Running 0 5h46m oes-gate-7b54554c5d-g7qs2 1/1 Running 0 5h27m oes-install-using-hal-nkzkj 0/1 Completed 0 5h46m oes-minio-b56cd74df-srrhd 1/1 Running 0 10h oes-platform-6f55f98c96-72dxd 1/1 Running 0 5h27m oes-redis-master-0 1/1 Running 0 10h oes-sapor-8cf5c9556-d9mpk 1/1 Running 0 4h15m oes-spinnaker-halyard-0 1/1 Running 0 10h oes-ui-6fc95cdf94-mj8fc 1/1 Running 0 114m oes-visibility-889f6fcdb-vcwx7 1/1 Running 4 6h1m opa-67c945d7b7-p9mjw 1/1 Running 0 7h5m spin-clouddriver-caching-6bf67f45b8-wwtcj 1/1 Running 0 5h37m spin-clouddriver-ro-75f8d6bbbd-58fnn 1/1 Running 0 5h37m spin-clouddriver-ro-deck-6b499cd544-69nbt 1/1 Running 0 5h37m spin-clouddriver-rw-6f8ff48976-8c27m 1/1 Running 0 5h37m spin-deck-7f74cd96d5-wcc5n 1/1 Running 0 5h37m spin-echo-scheduler-5fdd9fb7b-m7ztn 1/1 Running 0 5h37m spin-echo-worker-5bf4b855fd-qzpp8 1/1 Running 0 5h37m spin-fiat-59578d97f9-8mhvg 1/1 Running 0 5h37m spin-front50-58c69476b8-pp9g4 1/1 Running 0 5h37m spin-gate-6c6cdfc649-7lgvw 1/1 Running 0 5h37m spin-igor-85d986c45d-dphn5 1/1 Running 0 5h37m spin-orca-7f666f4676-sgbzf 1/1 Running 0 5h37m spin-rosco-69fcc9cd7c-ppjnx 1/1 Running 0 5h37m If you are not using any Ingress, create routes for the below services. Oes-ui Oes-gate Spin-deck-lb Spin-gate-lb After the routes are created, update the URLs in the values.yaml in the ingress section and do a \u201chelm upgrade\u201d. This will update all the override URLs in the spinnaker and other OES configurations. Spinnaker Deck URL configuration; url overwhich spinnaker deck will be accessed Spinnaker Gate URL configuration; url overwhich spinnaker gate will be accessed OES-UI url configuration OES-Gate url configuration Enter the below command to execute a \"helm upgrade\" helm upgrade oes . --namespace oes --timeout 20m","title":"Installation Steps"},{"location":"ISD%20On-Prem%20POV%20Infrastructure%20requirements/","text":"ISD On-Prem POV Infrastructure requirements ISD On-Prem POV Infrastructure requirements These requirements for setting up a Proof of Value are not sufficient for a production ready environment. Each customer\u2019s environment is unique and an installation often involves tailoring ISD to each customer\u2019s unique environment and constraints. By communicating key constraints of your environment upfront, An OpsMx Engineer can help you install ISD quickly and efficiently. Note We understand that not every user may be able to answer all of these questions and, while we highly recommend contacting your infrastructure team(s), we also understand that not every user has that option. If this is the case, feel free to contact us using https://www.opsmx.com/contact/ and we will be happy to help you find the answers. Requirements Kubernetes Cluster : Minimum of 24 CPU and 96 GB of RAM available. Each node should have a minimum of 32 GB. Typically 3 Nodes of 8 CPU/32 GB RAM should be enough. Automatic PVC provisioning is assumed Automatic LoadBalancer provisioning is assumed Most cloud-based k8s have these features. If you are using a non-standard k8s that requires manual provisioning, please let an OpsMx Engineer know. Access : Admin access to at least one namespace is required. Network : Full internet access, without http proxy will result in a simple installation process. Internet access via http-proxy, or a full air-gapped (no internet) connection is possible. Note that a gRPCconnections are made to google servers even if using proxy-servers. Please let us know upfront if we know of any restrictions in internet access. Security : It is possible that security restrictions can interfere with the process of serving web-pages from inside a kubernetes cluster. Please let us know if you know of cloudflare or similar software that intercepts all traffic to internal web-sites. Repository : ISD requires a repository for storing its configuration. In other words, users will need a github, gitlab or bitbucket repository. Alternatively, users can use AWS S3 bucket or install gitea, a small, open source, local github. Custom CA certificates : ISD integrates with multiple other applications in the environment. If custom CA certificates are in use in your environment, please inform an OpsMx engineer. It is required that ISD \u2018trusts\u2019 your environment. SSO or single-sign-on : We recommend that initial installation and configuration be done with our install-time provided open-LDAP that provides an admin user, user1, user2 and user3 for testing RBAC (Role based Access control). Should you require that we integrate with your SSO as part of POV, please ensure that we have support of your infrastructure team that handles the SSO i.e. AD, Okta or any other. As SSO configuration requires multiple decisions and is dependent on the decisions made before, an element of trial-and-error is involved to \u201cget it just right\u201d. Secrets : During installation, we support the use of k8s secrets. Should you need any other secret manager \u201cduring installation\u201dremember to ask an OpsMx engineer for help. Note At no point do we request you to give your account credentials OR store it in a repo that is accessible to OpsMx employees. Should that be requested, please report to the OpsMx security officer. We support multiple secret managers \u201cduring use\u201d (as against during installation). If ISTIO or any other service mesh is in use, this may require additional considerations. Please contact an OpsMx Engineer for assistance. Installation Process Requirements for Machines/Laptops The machine/laptop used for installation has these requirements: We should have internet access and should be able to access github.com, docker.io and quay.io and we need the following tools and services: curl kubectl (kubernetes command line interface) helm (package manager from https://www.hashicorp.com/) git Github user ID and login in github.com choco package manager (only if using Windows Laptop)","title":"ISD On Prem POV Infrastructure requirements"},{"location":"ISD%20On-Prem%20POV%20Infrastructure%20requirements/#isd-on-prem-pov-infrastructure-requirements","text":"","title":"ISD On-Prem POV Infrastructure requirements"},{"location":"ISD%20On-Prem%20POV%20Infrastructure%20requirements/#isd-on-prem-pov-infrastructure-requirements_1","text":"These requirements for setting up a Proof of Value are not sufficient for a production ready environment. Each customer\u2019s environment is unique and an installation often involves tailoring ISD to each customer\u2019s unique environment and constraints. By communicating key constraints of your environment upfront, An OpsMx Engineer can help you install ISD quickly and efficiently. Note We understand that not every user may be able to answer all of these questions and, while we highly recommend contacting your infrastructure team(s), we also understand that not every user has that option. If this is the case, feel free to contact us using https://www.opsmx.com/contact/ and we will be happy to help you find the answers.","title":"ISD On-Prem POV Infrastructure requirements"},{"location":"ISD%20On-Prem%20POV%20Infrastructure%20requirements/#requirements","text":"Kubernetes Cluster : Minimum of 24 CPU and 96 GB of RAM available. Each node should have a minimum of 32 GB. Typically 3 Nodes of 8 CPU/32 GB RAM should be enough. Automatic PVC provisioning is assumed Automatic LoadBalancer provisioning is assumed Most cloud-based k8s have these features. If you are using a non-standard k8s that requires manual provisioning, please let an OpsMx Engineer know. Access : Admin access to at least one namespace is required. Network : Full internet access, without http proxy will result in a simple installation process. Internet access via http-proxy, or a full air-gapped (no internet) connection is possible. Note that a gRPCconnections are made to google servers even if using proxy-servers. Please let us know upfront if we know of any restrictions in internet access. Security : It is possible that security restrictions can interfere with the process of serving web-pages from inside a kubernetes cluster. Please let us know if you know of cloudflare or similar software that intercepts all traffic to internal web-sites. Repository : ISD requires a repository for storing its configuration. In other words, users will need a github, gitlab or bitbucket repository. Alternatively, users can use AWS S3 bucket or install gitea, a small, open source, local github. Custom CA certificates : ISD integrates with multiple other applications in the environment. If custom CA certificates are in use in your environment, please inform an OpsMx engineer. It is required that ISD \u2018trusts\u2019 your environment. SSO or single-sign-on : We recommend that initial installation and configuration be done with our install-time provided open-LDAP that provides an admin user, user1, user2 and user3 for testing RBAC (Role based Access control). Should you require that we integrate with your SSO as part of POV, please ensure that we have support of your infrastructure team that handles the SSO i.e. AD, Okta or any other. As SSO configuration requires multiple decisions and is dependent on the decisions made before, an element of trial-and-error is involved to \u201cget it just right\u201d. Secrets : During installation, we support the use of k8s secrets. Should you need any other secret manager \u201cduring installation\u201dremember to ask an OpsMx engineer for help. Note At no point do we request you to give your account credentials OR store it in a repo that is accessible to OpsMx employees. Should that be requested, please report to the OpsMx security officer. We support multiple secret managers \u201cduring use\u201d (as against during installation). If ISTIO or any other service mesh is in use, this may require additional considerations. Please contact an OpsMx Engineer for assistance.","title":"Requirements"},{"location":"ISD%20On-Prem%20POV%20Infrastructure%20requirements/#installation-process-requirements-for-machineslaptops","text":"The machine/laptop used for installation has these requirements: We should have internet access and should be able to access github.com, docker.io and quay.io and we need the following tools and services: curl kubectl (kubernetes command line interface) helm (package manager from https://www.hashicorp.com/) git Github user ID and login in github.com choco package manager (only if using Windows Laptop)","title":"Installation Process Requirements for Machines/Laptops"},{"location":"ISD%20Quick%20Installation/","text":"ISD Quick Installation To experience ISD quickly, you can install it and deploy your applications. The instructions below are intended to get you started quickly and try out ISD functionality. Note The instructions below are not suitable for production or any other environment where security is a concern. The page helps you to install ISD quickly with the following five simple steps. Pre-requisites You should have access to a Kubernetes cluster with at least 2 nodes Each node should have a minimum of 32 GB RAM and kubectl set-up. Execute the following commands (copy-paste in a terminal window): kubectl create namespace opsmx-isd kubectl -n opsmx-isd apply -f https://raw.githubusercontent.com/OpsMx/isd-quick-install/main/isd312/isd-gitea-quick.yaml kubectl -n opsmx-isd get po kubectl -n opsmx-isd port-forward svc/oes-ui 8080 Now open your browser and navigate to http://localhost:8080 and login using the administrator's username and password. After login to ISD, please go to \" Setup \"--> \" Integrations \" --> and click \" Sync CD Accounts \" to complete the post-installation setup.","title":"ISD Quick Installation"},{"location":"ISD%20Quick%20Installation/#isd-quick-installation","text":"To experience ISD quickly, you can install it and deploy your applications. The instructions below are intended to get you started quickly and try out ISD functionality. Note The instructions below are not suitable for production or any other environment where security is a concern. The page helps you to install ISD quickly with the following five simple steps.","title":"ISD Quick Installation"},{"location":"ISD%20Quick%20Installation/#pre-requisites","text":"You should have access to a Kubernetes cluster with at least 2 nodes Each node should have a minimum of 32 GB RAM and kubectl set-up. Execute the following commands (copy-paste in a terminal window): kubectl create namespace opsmx-isd kubectl -n opsmx-isd apply -f https://raw.githubusercontent.com/OpsMx/isd-quick-install/main/isd312/isd-gitea-quick.yaml kubectl -n opsmx-isd get po kubectl -n opsmx-isd port-forward svc/oes-ui 8080 Now open your browser and navigate to http://localhost:8080 and login using the administrator's username and password. After login to ISD, please go to \" Setup \"--> \" Integrations \" --> and click \" Sync CD Accounts \" to complete the post-installation setup.","title":"Pre-requisites"},{"location":"ISD%20Service%20Catalogue/","text":"ISD Service Catalogue Spinnaker is composed of a number of independent microservices List of Spinnaker Services: spinnaker-halyard : is Spinnaker\u2019s configuration service spin-deck : is the browser-based UI spin-gate : is the API gateway spin-orca : the orchestration engine for executing pipelines. It handles all ad-hoc operations and pipelines spin-clouddriver : responsible for all mutating calls to the cloud providers, docker and git-repos spin-front50 : is used to persist the metadata of applications, pipelines, projects spin-rosco : The bakery that produces immutable VM images (or image templates) for various clouds. spin-igor : is used to trigger pipelines spin-echo : is Spinnaker\u2019s eventing bus for sending notifications Fiat : is Spinnaker\u2019s authorization service. If RBAC is enabled, other services call Fiat to check if an operation is permitted or not List of Autopilot Services: Agent-grpc : Used by agents to connect to the controller, used to communicate with controller Oes-db : Postgres database used to store the ISD data Oes-autopilot : For analysis of logs/metrics Oes-dashboard : Used to display the dashboard in ISD UI Oes-gate : is the API gateway of ISD Oes-platform: Used for saving data integrators, cloud provider accounts etc. Oes-sapor : Used for connecting to spinnaker and OPA Oes-ui : Main UI of ISD Oes-visibility : Used for approval/visibility gate Oes310-minio : Used by spinnaker and data science for storing data. Oes310-openldap : Used for open-ldap authentication Oes310-redis-headless : Not used Oes310-redis-master : Used for caching purposes (gate, orca, clouddriver among others) Oes310-spinnaker-halyard : Used to connect to spinnaker (apply config changes etc) Opa : Is the policy engine Opsmx-controller-controller1 : Primary service to support agent communication with the rest of the services opsmx-controller-controller1-interproc : Not currently used Sapor-gate : Used by oes-sapor to connect to a spinnaker services when 2FA or SAML is used. Oes-audit-client : Used to retrieve the audit data to display in the UI. Available in ISD 3.10 Oes-audit-service : Used to save the audit data. Available in ISD 3.10 Oes-datascience : Artificial Intelligence/Machine Learning Engine of logs & metrics. Available in ISD 3.10 Rabbitmq-service : Tuning service used in oes data science for asynchronous operations/analysis. Available in ISD 3.10 List of Jobs Create-controller-secret : This job creates ca-secret, oes-cacerts, jwt-secret and command-secret. These secrets and certs are used for Secure communication between agent and controller. Oes-config : This job attempts automatic configuration of Autopilot-Spinnaker communications at install time. If it fails, this needs to be done manually. oes310-create-sample-app : Used to create sample applications from a git-repo in the spinnaker at the install time. If this fails, one can manually do it by following the instructions given here . Oes310-install-using-hal : This is part of the Spinnaker installation.","title":"ISD Service Catalogue"},{"location":"ISD%20Service%20Catalogue/#isd-service-catalogue","text":"","title":"ISD Service Catalogue"},{"location":"ISD%20Service%20Catalogue/#spinnaker-is-composed-of-a-number-of-independent-microservices","text":"","title":"Spinnaker is composed of a number of independent microservices"},{"location":"ISD%20Service%20Catalogue/#list-of-spinnaker-services","text":"spinnaker-halyard : is Spinnaker\u2019s configuration service spin-deck : is the browser-based UI spin-gate : is the API gateway spin-orca : the orchestration engine for executing pipelines. It handles all ad-hoc operations and pipelines spin-clouddriver : responsible for all mutating calls to the cloud providers, docker and git-repos spin-front50 : is used to persist the metadata of applications, pipelines, projects spin-rosco : The bakery that produces immutable VM images (or image templates) for various clouds. spin-igor : is used to trigger pipelines spin-echo : is Spinnaker\u2019s eventing bus for sending notifications Fiat : is Spinnaker\u2019s authorization service. If RBAC is enabled, other services call Fiat to check if an operation is permitted or not","title":"List of Spinnaker Services:"},{"location":"ISD%20Service%20Catalogue/#list-of-autopilot-services","text":"Agent-grpc : Used by agents to connect to the controller, used to communicate with controller Oes-db : Postgres database used to store the ISD data Oes-autopilot : For analysis of logs/metrics Oes-dashboard : Used to display the dashboard in ISD UI Oes-gate : is the API gateway of ISD Oes-platform: Used for saving data integrators, cloud provider accounts etc. Oes-sapor : Used for connecting to spinnaker and OPA Oes-ui : Main UI of ISD Oes-visibility : Used for approval/visibility gate Oes310-minio : Used by spinnaker and data science for storing data. Oes310-openldap : Used for open-ldap authentication Oes310-redis-headless : Not used Oes310-redis-master : Used for caching purposes (gate, orca, clouddriver among others) Oes310-spinnaker-halyard : Used to connect to spinnaker (apply config changes etc) Opa : Is the policy engine Opsmx-controller-controller1 : Primary service to support agent communication with the rest of the services opsmx-controller-controller1-interproc : Not currently used Sapor-gate : Used by oes-sapor to connect to a spinnaker services when 2FA or SAML is used. Oes-audit-client : Used to retrieve the audit data to display in the UI. Available in ISD 3.10 Oes-audit-service : Used to save the audit data. Available in ISD 3.10 Oes-datascience : Artificial Intelligence/Machine Learning Engine of logs & metrics. Available in ISD 3.10 Rabbitmq-service : Tuning service used in oes data science for asynchronous operations/analysis. Available in ISD 3.10","title":"List of Autopilot Services:"},{"location":"ISD%20Service%20Catalogue/#list-of-jobs","text":"Create-controller-secret : This job creates ca-secret, oes-cacerts, jwt-secret and command-secret. These secrets and certs are used for Secure communication between agent and controller. Oes-config : This job attempts automatic configuration of Autopilot-Spinnaker communications at install time. If it fails, this needs to be done manually. oes310-create-sample-app : Used to create sample applications from a git-repo in the spinnaker at the install time. If this fails, one can manually do it by following the instructions given here . Oes310-install-using-hal : This is part of the Spinnaker installation.","title":"List of Jobs"},{"location":"ISD_Installation_Guide_old/","text":"ISD Installation Guide Introduction This document provides the step-by-step instructions for installing ISD on a kubernetes cluster. Some basic knowledge of command-line interface is required. Before you start, it might be helpful to go through these documents: Routing Web URLs to ISD services - Refer here ISD On-Prem POV Infrastructure requirements - Refer here ISD - Commonly used Commands - Refer here ISD Service Catalogue - Refer here Pre-requisites A laptop/machine being used to install that has the required software mentioned here A kubeconfig file to access the kubernetes cluster A working \u201ckubectl\u201d command. Execute the command below: kubectl get no to see the nodes kubectl get ns to see the namespaces These commands should show some output. If required, rename the kubeconfig file as \"config\" and copy to .kube folder in your machine A github repo, and a \u201cpersonal access token\u201d. Instructions for creating these can be found here. NGINX Ingress Controller and cert-manager(if using https) in the cluster. Installation steps Setup URLs Host names that will be used to access ISD: Three host-names are required as mentioned below: oes. .company.com spin. .company.com oes-gate. .company.com Run the following command to get the IP address of the ingress controller kubectl get ingress -n ingress-nginx Prepare gitops repo Prepare your gitops repository as follows: 1.Create a working directory in your local system ``` mkdir opsmx - isd # create a working directory for your installation ``` 2.Clone standard-gitops-repo repository from appropriate branch `git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.10` 3.Clone your gitops repo using the following command: git clone https://github.com/<your-id>/<gitops-repo> For Example: git clone https://github.com/ravigorremuchu/oes-repo.git 4.Copy files from standard-gitops-repo to your gitops repo cp -R ./standard-gitops-repo/config ./<gitops-repo>/config cp -R ./standard-gitops-repo/halyard.yaml ./<oes-repo>/halyard.yaml cp -R ./standard-gitops-repo/default ./<oes-repo>/default cp -R ./standard-gitops-repo/SAMPLES ./<oes-repo>/SAMPLES 5.Push the changes back to the githup repo cd <oes-repo> git add -A git commit -m \u201cOpsmx standard gitops repo\u201d git push","title":"ISD Installation Guide old"},{"location":"ISD_Installation_Guide_old/#isd-installation-guide","text":"","title":"ISD Installation Guide"},{"location":"ISD_Installation_Guide_old/#introduction","text":"This document provides the step-by-step instructions for installing ISD on a kubernetes cluster. Some basic knowledge of command-line interface is required. Before you start, it might be helpful to go through these documents: Routing Web URLs to ISD services - Refer here ISD On-Prem POV Infrastructure requirements - Refer here ISD - Commonly used Commands - Refer here ISD Service Catalogue - Refer here","title":"Introduction"},{"location":"ISD_Installation_Guide_old/#pre-requisites","text":"A laptop/machine being used to install that has the required software mentioned here A kubeconfig file to access the kubernetes cluster A working \u201ckubectl\u201d command. Execute the command below: kubectl get no to see the nodes kubectl get ns to see the namespaces These commands should show some output. If required, rename the kubeconfig file as \"config\" and copy to .kube folder in your machine A github repo, and a \u201cpersonal access token\u201d. Instructions for creating these can be found here. NGINX Ingress Controller and cert-manager(if using https) in the cluster.","title":"Pre-requisites"},{"location":"ISD_Installation_Guide_old/#installation-steps","text":"","title":"Installation steps"},{"location":"ISD_Installation_Guide_old/#setup-urls","text":"Host names that will be used to access ISD: Three host-names are required as mentioned below: oes. .company.com spin. .company.com oes-gate. .company.com Run the following command to get the IP address of the ingress controller kubectl get ingress -n ingress-nginx","title":"Setup URLs"},{"location":"ISD_Installation_Guide_old/#prepare-gitops-repo","text":"Prepare your gitops repository as follows: 1.Create a working directory in your local system ``` mkdir opsmx - isd # create a working directory for your installation ``` 2.Clone standard-gitops-repo repository from appropriate branch `git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.10` 3.Clone your gitops repo using the following command: git clone https://github.com/<your-id>/<gitops-repo> For Example: git clone https://github.com/ravigorremuchu/oes-repo.git 4.Copy files from standard-gitops-repo to your gitops repo cp -R ./standard-gitops-repo/config ./<gitops-repo>/config cp -R ./standard-gitops-repo/halyard.yaml ./<oes-repo>/halyard.yaml cp -R ./standard-gitops-repo/default ./<oes-repo>/default cp -R ./standard-gitops-repo/SAMPLES ./<oes-repo>/SAMPLES 5.Push the changes back to the githup repo cd <oes-repo> git add -A git commit -m \u201cOpsmx standard gitops repo\u201d git push","title":"Prepare gitops repo"},{"location":"Installation/","text":"Installation ISD installation in a Kubernetes Cluster This page describes the steps to install ISD in a Kubernetes Cluster. Assumptions Ability to install application on a Kubernetes Cluster Internet access from the Kubernetes node Access to Quay and Docker repositories is available Pre-requisites Hardware requirements: You should have access to a Kubernetes cluster with at least 2 nodes Each node having a minimum of 8 CPU & 32 GB RAM Other Pre-requisites You should have internet access and should be able to access github.com, docker.io and quay.io. You should have the following tools installed. Choco package manager Curl kubectl-cli kubectl-helm git login to \"www.github.com\" If you are using Windows machine Execute the following command in Powershell (running in administrator mode) Set-ExecutionPolicy Bypass -Scope Process -Force; `iex ((New-Object System.Net.WebClient).DownloadString('http://chocolatey.org/install.psl')) Execute the following command: Install 'Curl' using the following command $choco install curl Install 'Kubernetes' using the following command $choco install kubernetes-cli Install 'Helm' using the following command $choco install kubernetes-helm Install 'git' using the following command $choco install git If you are using Linux machine Install-using-native-package-management, following the instructions provided here, https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ Install helm using the following command & instructions provided here, https://helm.sh/docs/intro/install/ and follow the instruction provided below Install 'git' using the following command $choco install git Pre-installation steps Ensure that the kubeconfig file is named as \"config\" and is copied to .kube folder in your machine You should have the NGINX Ingress Controller already available in the cluster; if not, install the same using the following instructions. $kubectl create ns ingress-nginx Note: It is the controller for service-to-cloud $helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx Note: Use \"$helm repo\" list to check ingress-nginx is added or not $helm repo update $helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx Note: Installs nginx control in our namespace $kubectl get svc -n ingress-nginx Note: This command is used to check whether it is installed correctly or not Check whether 'cert-manager' already installed in the cluster or not by running $kubectl get pods --namespace cert-manager If not installed, use the following commands to install the 'cert-manager' $kubectl create namespace cert-manager $helm repo add jetstack https://charts.jetstack.io $helm repo update $helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager Note: This command installs cert-manager. Installation Steps Create a working directory in your local system $mkdir <working-dir> Note: Create a working directory for your installation Clone 'standard-gitops-repo' repository from appropriate branch $git clone https://github.com/OpsMx/standard-gitops-repo.git -b <branch-id> Login to GitHub (github.com) with your own credentials. If you don\u2019t have an account, create an account in github. Create a new private repository with just README file. Make sure it is marked private. Rename main branch as master branch. Go to settings/branches to rename the branch. Get a git user token. Save this token to be updated in \"values.yaml\" later. Note: If the token contains \u2018/\u2019 or \u2018\\\u2019, please generate another token as these special characters create some issues during installation. Clone the newly created repo using the following commands $git clone htts://github.com/<your-id>/<oes-repo Example: git clone https://github.com/ravigorremuchu/oes-repo.git Copy files (config, halyard and default) from standard-gitops-repo to the newly cloned repo directory $cp -R .\\standard-gitops-repo\\config .\\oes-repo\\config Note: Copy config file from standard-gitops-repo $cp -R .\\standard-gitops-repo\\halyard.yaml .\\oes-repo\\halyard.yaml Note: Copy halyard.yaml from standard-gitops-repo $cp -R .\\standard-gitops-repo\\default .\\oes-repo\\default Note: Copy config file from standard-gitops-repo Go to your new git directory and execute the following commands: $git add -A $git commit -m \"some message\u201d $git push To copy sample pipelines (go to your working dir and execute the following commands): $git clone https://github.com/OpsMx/sample-pipelines.git Note: For getting pipelines sync with git $cp -R .\\sample-pipelines\\pipeline-jsonfile\\ .\\<oes-repo>\\pipeline-jsonfile\\ Note: Copy pipeline-jsonfile directory into your git dir Go to your git directory: $git add .\\pipeline-jsonfile\\ $git commit -m \"pipeline promotion files\" $git push Get \"values.yaml\" file from the Enterprise Spinnaker repo in the Git (https://github.com/OpsMx/enterprise-spinnaker/), from the appropriate branch and charts/oes directory and copy to your working directory. Modify \"values.yaml\" Under Image credentials make sure you have the right parameters defined: imageCredentials: registry: https://quay.io/ username: Password: For spinDeck, spinGate, oesUI and oesGate: change the URLs to be used for accessing the OES/Spinnaker Eg: host: spin.oes.opsmx.net host: spin-gate.oes.opsmx.net host: oes.oes.opsmx.net host: oes-gate-ldap.oes.opsmx.net Set \"OpenLdap\" to \"true\" & \"installOpenLdap: true\" Go to gitopsHalyard section and make the following changes repo: type: git baseUrlHostName: github.com organization: your-git-org projectName: \" \" <<Should be empty>> repository: <your cloned repo name> <<Example: oes-repo>> dynamicAccRepository: <your cloned repo name> <<Example: oes-repo>> username: your-git-id token: your-git-token <<Access token corresponding to above login-id>> At pipeline promotion section, make this change: pipelinePromotion: <<GitHub only not supported on S3 or Stash>> enabled: true Check if helm chart for opsmx is existing or not $helm repo list Check if https://helmcharts.opsmx.com/ is existing. If existing, don't need to add the helm chart. Otherwise, add using $helm repo add opsmx https://helmcharts.opsmx.com/ $helm repo update $kubectl create namespace <oes-ns> Note: Create a namespace Go to the directory where \"values.yaml\" is saved/modified and begin the installation using the following command. Note that this will install with the latest helm version. $helm install oes39 opsmx/oes -f values.yaml -n <oes-ns> --timeout 30m Note: \"oes39\" is the release name, \"oes-ns\" is the namespace. If you need to use any specific version of helm, use the following command: $helm install oes39 opsmx/oes -f values.yaml -n oes-ns --timeout 30m --version <helm-ver> Keep monitoring the pods being created using $kubectl get po -n <oes-ns> Note: -w for looping $kubectl get sts -n <oes-ns> Check whether all the pods are up and running Run the following command to get the URLs $kubectl get ingress -n <oes-ns> Send the URLs and the external address to the DNS administrator to be added to the DNS server.","title":"Installation"},{"location":"Installation/#installation","text":"","title":"Installation"},{"location":"Installation/#isd-installation-in-a-kubernetes-cluster","text":"This page describes the steps to install ISD in a Kubernetes Cluster.","title":"ISD installation in a Kubernetes Cluster"},{"location":"Installation/#assumptions","text":"Ability to install application on a Kubernetes Cluster Internet access from the Kubernetes node Access to Quay and Docker repositories is available","title":"Assumptions"},{"location":"Installation/#pre-requisites","text":"Hardware requirements: You should have access to a Kubernetes cluster with at least 2 nodes Each node having a minimum of 8 CPU & 32 GB RAM Other Pre-requisites You should have internet access and should be able to access github.com, docker.io and quay.io. You should have the following tools installed. Choco package manager Curl kubectl-cli kubectl-helm git login to \"www.github.com\" If you are using Windows machine Execute the following command in Powershell (running in administrator mode) Set-ExecutionPolicy Bypass -Scope Process -Force; `iex ((New-Object System.Net.WebClient).DownloadString('http://chocolatey.org/install.psl')) Execute the following command: Install 'Curl' using the following command $choco install curl Install 'Kubernetes' using the following command $choco install kubernetes-cli Install 'Helm' using the following command $choco install kubernetes-helm Install 'git' using the following command $choco install git If you are using Linux machine Install-using-native-package-management, following the instructions provided here, https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ Install helm using the following command & instructions provided here, https://helm.sh/docs/intro/install/ and follow the instruction provided below Install 'git' using the following command $choco install git","title":"Pre-requisites"},{"location":"Installation/#pre-installation-steps","text":"Ensure that the kubeconfig file is named as \"config\" and is copied to .kube folder in your machine You should have the NGINX Ingress Controller already available in the cluster; if not, install the same using the following instructions. $kubectl create ns ingress-nginx Note: It is the controller for service-to-cloud $helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx Note: Use \"$helm repo\" list to check ingress-nginx is added or not $helm repo update $helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx Note: Installs nginx control in our namespace $kubectl get svc -n ingress-nginx Note: This command is used to check whether it is installed correctly or not Check whether 'cert-manager' already installed in the cluster or not by running $kubectl get pods --namespace cert-manager If not installed, use the following commands to install the 'cert-manager' $kubectl create namespace cert-manager $helm repo add jetstack https://charts.jetstack.io $helm repo update $helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager Note: This command installs cert-manager.","title":"Pre-installation steps"},{"location":"Installation/#installation-steps","text":"Create a working directory in your local system $mkdir <working-dir> Note: Create a working directory for your installation Clone 'standard-gitops-repo' repository from appropriate branch $git clone https://github.com/OpsMx/standard-gitops-repo.git -b <branch-id> Login to GitHub (github.com) with your own credentials. If you don\u2019t have an account, create an account in github. Create a new private repository with just README file. Make sure it is marked private. Rename main branch as master branch. Go to settings/branches to rename the branch. Get a git user token. Save this token to be updated in \"values.yaml\" later. Note: If the token contains \u2018/\u2019 or \u2018\\\u2019, please generate another token as these special characters create some issues during installation. Clone the newly created repo using the following commands $git clone htts://github.com/<your-id>/<oes-repo Example: git clone https://github.com/ravigorremuchu/oes-repo.git Copy files (config, halyard and default) from standard-gitops-repo to the newly cloned repo directory $cp -R .\\standard-gitops-repo\\config .\\oes-repo\\config Note: Copy config file from standard-gitops-repo $cp -R .\\standard-gitops-repo\\halyard.yaml .\\oes-repo\\halyard.yaml Note: Copy halyard.yaml from standard-gitops-repo $cp -R .\\standard-gitops-repo\\default .\\oes-repo\\default Note: Copy config file from standard-gitops-repo Go to your new git directory and execute the following commands: $git add -A $git commit -m \"some message\u201d $git push To copy sample pipelines (go to your working dir and execute the following commands): $git clone https://github.com/OpsMx/sample-pipelines.git Note: For getting pipelines sync with git $cp -R .\\sample-pipelines\\pipeline-jsonfile\\ .\\<oes-repo>\\pipeline-jsonfile\\ Note: Copy pipeline-jsonfile directory into your git dir Go to your git directory: $git add .\\pipeline-jsonfile\\ $git commit -m \"pipeline promotion files\" $git push Get \"values.yaml\" file from the Enterprise Spinnaker repo in the Git (https://github.com/OpsMx/enterprise-spinnaker/), from the appropriate branch and charts/oes directory and copy to your working directory. Modify \"values.yaml\" Under Image credentials make sure you have the right parameters defined: imageCredentials: registry: https://quay.io/ username: Password: For spinDeck, spinGate, oesUI and oesGate: change the URLs to be used for accessing the OES/Spinnaker Eg: host: spin.oes.opsmx.net host: spin-gate.oes.opsmx.net host: oes.oes.opsmx.net host: oes-gate-ldap.oes.opsmx.net Set \"OpenLdap\" to \"true\" & \"installOpenLdap: true\" Go to gitopsHalyard section and make the following changes repo: type: git baseUrlHostName: github.com organization: your-git-org projectName: \" \" <<Should be empty>> repository: <your cloned repo name> <<Example: oes-repo>> dynamicAccRepository: <your cloned repo name> <<Example: oes-repo>> username: your-git-id token: your-git-token <<Access token corresponding to above login-id>> At pipeline promotion section, make this change: pipelinePromotion: <<GitHub only not supported on S3 or Stash>> enabled: true Check if helm chart for opsmx is existing or not $helm repo list Check if https://helmcharts.opsmx.com/ is existing. If existing, don't need to add the helm chart. Otherwise, add using $helm repo add opsmx https://helmcharts.opsmx.com/ $helm repo update $kubectl create namespace <oes-ns> Note: Create a namespace Go to the directory where \"values.yaml\" is saved/modified and begin the installation using the following command. Note that this will install with the latest helm version. $helm install oes39 opsmx/oes -f values.yaml -n <oes-ns> --timeout 30m Note: \"oes39\" is the release name, \"oes-ns\" is the namespace. If you need to use any specific version of helm, use the following command: $helm install oes39 opsmx/oes -f values.yaml -n oes-ns --timeout 30m --version <helm-ver> Keep monitoring the pods being created using $kubectl get po -n <oes-ns> Note: -w for looping $kubectl get sts -n <oes-ns> Check whether all the pods are up and running Run the following command to get the URLs $kubectl get ingress -n <oes-ns> Send the URLs and the external address to the DNS administrator to be added to the DNS server.","title":"Installation Steps"},{"location":"Installing%20Autopilot_old/","text":"Installing Autopilot If you are already using Open Source Spinnaker, then Autopilot can get seamlessly integrated with your Open Source Spinnaker and you get the all the benefits of Autopilot product. The following section defines the procedure for installing Autopilot as a standalone module to work with Open Source Spinnaker. Prerequisites Have access to public repositories in docker.io and quay.io Have the following tools installed - wget, kubectl, helm Have access to a Kubernetes cluster with at least 2 nodes, each node having 8 CPU and 32 GB RAM Have the NGINX Ingress Controller installed in the cluster. If it is not already installed, then you can install the same using the following instructions 4.1. kubectl create ns ingress-nginx 4.2. helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx 4.3. helm repo update 4.4. helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx 4.5. kubectl get svc -n ingress-nginx Have \u201ccert-manager\u201d already available in the cluster. If it is not already available, then you can install it using the following instructions 5.1. kubectl create namespace cert-manager 5.2. helm repo add jetstack https://charts.jetstack.io 5.3. helm repo update 5.4. helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager In the Kubernetes cluster, have 3 Persistent Volumes of size 10GB each Two DNS records pointing to the IP of the Ingress Controller for the following: \u201cAutopilot UI\u201d, Eg. autopilot.opsmx.net \u201cAutopilot Gate\u201d, Eg. autopilot-gate.opsmx.net","title":"Installing Autopilot old"},{"location":"Installing%20Autopilot_old/#installing-autopilot","text":"If you are already using Open Source Spinnaker, then Autopilot can get seamlessly integrated with your Open Source Spinnaker and you get the all the benefits of Autopilot product. The following section defines the procedure for installing Autopilot as a standalone module to work with Open Source Spinnaker.","title":"Installing Autopilot"},{"location":"Installing%20Autopilot_old/#prerequisites","text":"Have access to public repositories in docker.io and quay.io Have the following tools installed - wget, kubectl, helm Have access to a Kubernetes cluster with at least 2 nodes, each node having 8 CPU and 32 GB RAM Have the NGINX Ingress Controller installed in the cluster. If it is not already installed, then you can install the same using the following instructions 4.1. kubectl create ns ingress-nginx 4.2. helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx 4.3. helm repo update 4.4. helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx 4.5. kubectl get svc -n ingress-nginx Have \u201ccert-manager\u201d already available in the cluster. If it is not already available, then you can install it using the following instructions 5.1. kubectl create namespace cert-manager 5.2. helm repo add jetstack https://charts.jetstack.io 5.3. helm repo update 5.4. helm install cert-manager jetstack/cert-manager --set installCRDs=true -n cert-manager In the Kubernetes cluster, have 3 Persistent Volumes of size 10GB each Two DNS records pointing to the IP of the Ingress Controller for the following: \u201cAutopilot UI\u201d, Eg. autopilot.opsmx.net \u201cAutopilot Gate\u201d, Eg. autopilot-gate.opsmx.net","title":"Prerequisites"},{"location":"Multi-cloud%20Deployments/","text":"Multi-cloud Deployments OES allows you to achieve repeatable multi-cloud deployments without scripting and reduce failure rates through built-in safe deployment strategies that work across public, private and container environments. With OES you can continuously deploy both microservices and traditional monolith applications. Multi-cloud Deployment: Automatically deploy applications on bare metal, container, VM, or serverless platforms with no scripting via our cloud platform integrations and templates. OES helps you to deploy to Private cloud (OpenStack, OpenShift, Kubernetes, Mesos, Docker, vSphere) and public cloud (AWS, GCP, Azure, Oracle). Built-in Safe Strategies: You can safely and consistently deploy with built-in, ready-to-use deployment strategies such as Blue-Green, A/B, Canary, and Rolling Update. OES treats Kubernetes as first-class citizens and supports Kubernetes resources and operators for custom strategies. 1-Click Rollback: Just rollback with one click and quickly mitigate deployment risks, avoiding unforeseen application performance or quality degradation. OES maintains deployment versions so that you can roll back to any previous working version with just one click. Policy Driven Deployments: Achieve policy enforcement at every stage of deployment. Easily navigate changing policies using fine-grain controls at both creation and run-time of deployment pipelines with declarative specifications. Real-time visibility and insights: Gain deep end-to-end visibility into all the stages of deployment. Quickly understand the reason behind deployment failures and resolve the errors and issues to improve your delivery process.","title":"Multi cloud Deployments"},{"location":"Multi-cloud%20Deployments/#multi-cloud-deployments","text":"OES allows you to achieve repeatable multi-cloud deployments without scripting and reduce failure rates through built-in safe deployment strategies that work across public, private and container environments. With OES you can continuously deploy both microservices and traditional monolith applications. Multi-cloud Deployment: Automatically deploy applications on bare metal, container, VM, or serverless platforms with no scripting via our cloud platform integrations and templates. OES helps you to deploy to Private cloud (OpenStack, OpenShift, Kubernetes, Mesos, Docker, vSphere) and public cloud (AWS, GCP, Azure, Oracle). Built-in Safe Strategies: You can safely and consistently deploy with built-in, ready-to-use deployment strategies such as Blue-Green, A/B, Canary, and Rolling Update. OES treats Kubernetes as first-class citizens and supports Kubernetes resources and operators for custom strategies. 1-Click Rollback: Just rollback with one click and quickly mitigate deployment risks, avoiding unforeseen application performance or quality degradation. OES maintains deployment versions so that you can roll back to any previous working version with just one click. Policy Driven Deployments: Achieve policy enforcement at every stage of deployment. Easily navigate changing policies using fine-grain controls at both creation and run-time of deployment pipelines with declarative specifications. Real-time visibility and insights: Gain deep end-to-end visibility into all the stages of deployment. Quickly understand the reason behind deployment failures and resolve the errors and issues to improve your delivery process.","title":"Multi-cloud Deployments"},{"location":"OES%20Concepts/","text":"OES Concepts Overview OES, as it is designed to work with Spinnaker, will naturally have a lot of overlap with Spinnaker concepts. We are going to outline the core features of OES (and of Spinnaker below) OES has two basic features: Application management Application deployment Application Deployment Spinnaker's application deployment feature is responsible for the continuous delivery workflow. Some of the basic concepts of application deployment are: Pipeline Stage Deployment Strategies Let\u2019s discuss and learn how these concepts work. Pipeline The main deployment management constructor of Spinnaker is the pipeline. A pipeline defines a flow of actions in a particular sequence; for the code traversal, from commit all the way until it is deployed in the target deployment environment. A pipeline comprises a series of actions known as stages. You can add/modify stages to a pipeline as you define it, allowing you to pass parameters from one stage to the next along the pipeline. The image below shows an example pipeline. Stage In Spinnaker, an automatically created building block for the pipeline is known as a stage. A stage in a pipeline is used to define a specific and finite activity. Herein, You can specify an action to be performed on a specific pipeline here. You can have as many stages as you wish in a pipeline based on what actions you want to perform; for example, a stage for code build, a stage for static code analysis, a stage for code deploy, etc. Spinnaker can integrate with a large number of third third-party tools for performing the actions specified in a pipeline. For example, you can integrate Spinnaker with Jenkins, SonarQube, Terraform, Vault, test automation tools, etc. Deployment Strategies Spinnaker manages cloud-native deployment strategies as exclusive constructs, handling primary arrangements such as disabling old server groups, enabling new server groups, and verifying health checks. Spinnaker backs the red/black (also known as blue/green) strategy, with rolling red/black and canary strategies in active development. This enables the user to define the custom deployment strategy based on their organization requirements. Spinnaker supports: Blue/green (AKA Red/Black) Rolling Red/black Highlander Dark Rollout Blue/Green (AKA Red/Black): Blue/Green strategy, AKA Red/black strategy consists of creating new server groups and once the new server groups become healthy, removing the old server groups from the load balancer. Highlander: The highlander strategy consists of creating new server groups and once the new server groups become healthy the old server groups are deleted. Dark rollout (None): Dark roll outs involve doing nothing about the old server groups. Both old and new server groups stay on the load balancer. Refer to the figure below for a better understanding:","title":"OES Concepts"},{"location":"OES%20Concepts/#oes-concepts","text":"","title":"OES Concepts"},{"location":"OES%20Concepts/#overview","text":"OES, as it is designed to work with Spinnaker, will naturally have a lot of overlap with Spinnaker concepts. We are going to outline the core features of OES (and of Spinnaker below) OES has two basic features: Application management Application deployment","title":"Overview"},{"location":"OES%20Concepts/#application-deployment","text":"Spinnaker's application deployment feature is responsible for the continuous delivery workflow. Some of the basic concepts of application deployment are: Pipeline Stage Deployment Strategies Let\u2019s discuss and learn how these concepts work.","title":"Application Deployment"},{"location":"OES%20Concepts/#pipeline","text":"The main deployment management constructor of Spinnaker is the pipeline. A pipeline defines a flow of actions in a particular sequence; for the code traversal, from commit all the way until it is deployed in the target deployment environment. A pipeline comprises a series of actions known as stages. You can add/modify stages to a pipeline as you define it, allowing you to pass parameters from one stage to the next along the pipeline. The image below shows an example pipeline.","title":"Pipeline"},{"location":"OES%20Concepts/#stage","text":"In Spinnaker, an automatically created building block for the pipeline is known as a stage. A stage in a pipeline is used to define a specific and finite activity. Herein, You can specify an action to be performed on a specific pipeline here. You can have as many stages as you wish in a pipeline based on what actions you want to perform; for example, a stage for code build, a stage for static code analysis, a stage for code deploy, etc. Spinnaker can integrate with a large number of third third-party tools for performing the actions specified in a pipeline. For example, you can integrate Spinnaker with Jenkins, SonarQube, Terraform, Vault, test automation tools, etc.","title":"Stage"},{"location":"OES%20Concepts/#deployment-strategies","text":"Spinnaker manages cloud-native deployment strategies as exclusive constructs, handling primary arrangements such as disabling old server groups, enabling new server groups, and verifying health checks. Spinnaker backs the red/black (also known as blue/green) strategy, with rolling red/black and canary strategies in active development. This enables the user to define the custom deployment strategy based on their organization requirements.","title":"Deployment Strategies"},{"location":"OES%20Concepts/#spinnaker-supports","text":"Blue/green (AKA Red/Black) Rolling Red/black Highlander Dark Rollout Blue/Green (AKA Red/Black): Blue/Green strategy, AKA Red/black strategy consists of creating new server groups and once the new server groups become healthy, removing the old server groups from the load balancer. Highlander: The highlander strategy consists of creating new server groups and once the new server groups become healthy the old server groups are deleted. Dark rollout (None): Dark roll outs involve doing nothing about the old server groups. Both old and new server groups stay on the load balancer. Refer to the figure below for a better understanding:","title":"Spinnaker supports:"},{"location":"OES%20Features/","text":"OES Features OES has a wide range of tools and conveniences that allow developers, Managers and SRE\u2019s to develop, build and deploy software faster, better with less friction. Below you can find the eight key features of OES: Automated Workflows: Replace manual scripts with automated workflows to simplify CI/CD process. Setup entire CI/CD workflow in minutes, empowering developers to deploy applications through easy to create pipelines without scripts by allowing for pipelines to be stored as JSON files. Multi-cloud Deployment: Automatically deploy applications on bare metal, Kubernetes, VMs, or public cloud platforms at scale. Native support for deploying applications to major cloud providers such as Amazon, Google, and Microsoft. Self-Deployment Strategies: Deploy applications quickly and safely through out-of-box support for deployment strategies, roll back/canary, blue/green, progressive roll-out strategies to minimize risk during deployment. Scalable and Extensible platform: Ensure smooth and painless enterprise-scale adoption with pre-built integrations and open-source community based support. Easy lifecycle management: Enable reliable and efficient operation wrt to maintenance and frequent upgrades of Spinnaker. Self-Service: Onboard your Kubernetes or public-cloud account into Spinnaker dynamically using simple steps in the OES UI. Enterprise Security: Ensure built-in protection across multiple teams, point tools, and infrastructure with hardened Spinnaker. GitOps style delivery: Manage complex applications and infrastructure running on Kubernetes using fast and secure applications deployment workflows triggered by Git events.","title":"OES Features"},{"location":"OES%20Features/#oes-features","text":"OES has a wide range of tools and conveniences that allow developers, Managers and SRE\u2019s to develop, build and deploy software faster, better with less friction. Below you can find the eight key features of OES: Automated Workflows: Replace manual scripts with automated workflows to simplify CI/CD process. Setup entire CI/CD workflow in minutes, empowering developers to deploy applications through easy to create pipelines without scripts by allowing for pipelines to be stored as JSON files. Multi-cloud Deployment: Automatically deploy applications on bare metal, Kubernetes, VMs, or public cloud platforms at scale. Native support for deploying applications to major cloud providers such as Amazon, Google, and Microsoft. Self-Deployment Strategies: Deploy applications quickly and safely through out-of-box support for deployment strategies, roll back/canary, blue/green, progressive roll-out strategies to minimize risk during deployment. Scalable and Extensible platform: Ensure smooth and painless enterprise-scale adoption with pre-built integrations and open-source community based support. Easy lifecycle management: Enable reliable and efficient operation wrt to maintenance and frequent upgrades of Spinnaker. Self-Service: Onboard your Kubernetes or public-cloud account into Spinnaker dynamically using simple steps in the OES UI. Enterprise Security: Ensure built-in protection across multiple teams, point tools, and infrastructure with hardened Spinnaker. GitOps style delivery: Manage complex applications and infrastructure running on Kubernetes using fast and secure applications deployment workflows triggered by Git events.","title":"OES Features"},{"location":"Observability/","text":"Observability The application observability dashboard is a crucial challenge for DevOps engineers, SRE, DevSecOps, and engineering managers. The dashboard provides in-depth information about the application and services managed by the platform. Users can observe details about current deployment across all environments (Dev, QA, Staging, and Productions) and past deployments. This feature allows users to collaborate more and make better decisions using real-time visibility and deep insights across the software deployments and delivery. It supports real-time observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved. Overview \u200b\u200bFollowing are the key benefits of the observability feature: Identify and remove bottlenecks in all your pipelines through customizable Application and Delivery dashboards. Improve security by rapidly tracing the use of any artifact that has vulnerabilities or other issues. Share best practices and identify problem areas across your entire software delivery environment. Enable developers to monitor applications during and after deployment to production, with the ability to detect issues and request for rollback quickly to avoid disruptions. Get a high-level view of thousands of pipelines through a single-dashboard to ensure that it is operational feasible and receive diagnosis based on historical information.","title":"Observability"},{"location":"Observability/#observability","text":"The application observability dashboard is a crucial challenge for DevOps engineers, SRE, DevSecOps, and engineering managers. The dashboard provides in-depth information about the application and services managed by the platform. Users can observe details about current deployment across all environments (Dev, QA, Staging, and Productions) and past deployments. This feature allows users to collaborate more and make better decisions using real-time visibility and deep insights across the software deployments and delivery. It supports real-time observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved.","title":"Observability"},{"location":"Observability/#overview","text":"\u200b\u200bFollowing are the key benefits of the observability feature: Identify and remove bottlenecks in all your pipelines through customizable Application and Delivery dashboards. Improve security by rapidly tracing the use of any artifact that has vulnerabilities or other issues. Share best practices and identify problem areas across your entire software delivery environment. Enable developers to monitor applications during and after deployment to production, with the ability to detect issues and request for rollback quickly to avoid disruptions. Get a high-level view of thousands of pipelines through a single-dashboard to ensure that it is operational feasible and receive diagnosis based on historical information.","title":"Overview"},{"location":"Observability_old/","text":"Observability The application observability dashboard is a crucial challenge for DevOps engineers, SRE, DevSecOps, and engineering managers. The dashboard provides in-depth information about the application and services managed by the platform. Users can observe details about current deployment across all environments (Dev, QA, Staging, and Productions) and past deployments. This feature allows users to collaborate more and make better decisions using real-time visibility and deep insights across the software deployments and delivery. It supports real-time observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved. Following are the key benefits of the observability feature: Identify and remove bottlenecks in all your pipelines through customizable Application and Delivery dashboards. Improve security by rapidly tracing the use of any artifact that has vulnerabilities or other issues. Share best practices and identify problem areas across your entire software delivery environment. Enable developers to monitor applications during and after deployment to production, with the ability to detect issues and request for rollback quickly to avoid disruptions. Get a high-level view of thousands of pipelines through a single-dashboard to ensure that it is operational feasible and receive diagnosis based on historical information.","title":"Observability old"},{"location":"Observability_old/#observability","text":"The application observability dashboard is a crucial challenge for DevOps engineers, SRE, DevSecOps, and engineering managers. The dashboard provides in-depth information about the application and services managed by the platform. Users can observe details about current deployment across all environments (Dev, QA, Staging, and Productions) and past deployments. This feature allows users to collaborate more and make better decisions using real-time visibility and deep insights across the software deployments and delivery. It supports real-time observability with respect to deployments and pipeline execution and traceability for all software delivery events, including what is getting delivered, who approved the release, and when it was approved. Following are the key benefits of the observability feature: Identify and remove bottlenecks in all your pipelines through customizable Application and Delivery dashboards. Improve security by rapidly tracing the use of any artifact that has vulnerabilities or other issues. Share best practices and identify problem areas across your entire software delivery environment. Enable developers to monitor applications during and after deployment to production, with the ability to detect issues and request for rollback quickly to avoid disruptions. Get a high-level view of thousands of pipelines through a single-dashboard to ensure that it is operational feasible and receive diagnosis based on historical information.","title":"Observability"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/","text":"OpsMx Intelligent Software Delivery Platform OpsMx\u2019s ISD is designed to help release software faster, with fewer errors and with minimal human intervention to create a better end customer experience and free up time and Manpower for businesses to scale and Innovate. ISD allows you to: Build Flexible deployment pipelines for multiple cloud environments Using ISD\u2019s Orchestration Module, OpsMx builds off of Spinnaker, the premier open source multi cloud deployment solution, by providing users with extra layers of data and information to make better decisions. For example, Spinnaker does not have clear distinctions between the application and the various services and microservices that make up that application. ISD however allows users to easily see the various services and microservices that make up each application and the pipelines that make up each individual service and microservice. This allows you to easier see dependencies between service pipelines and as a result help you optimize your workflow. Whether used as an On-prem or a Managed SaaS solution, the orchestration module offers a host of other features like: Self Service onboarding: ISD allows users to serve themselves whether it is adding a new tool, cluster or pipeline, ISD allows users to serve themselves. Pipelines as code: While Spinnaker gives users visual representations of your pipelines so that you can see how your deployment stages might playout, ISD allows you to maintain your pipelines as JSON files which allows you to easily store them as, modify them and repurpose them using any Git-based repository, saving your team time and your business money. Infrastructure as code: As customers demand more from their CI/CD tools, the infrastructure has to be able to scale to meet those requirements. ISD allows you to use tools like Terraform to have your infrastructure like Servers available as code. This allows you to easily scale your application and, as a result, your business without having to worry as much about infrastructure costs. Increase compliance and communication across your development and operations teams: Using our Pluggable data layer, ISD supports over 40+ integrations with various tools that cover each and every stage of software development and operation no matter your team size or work flow. It supports communication with tools like Slack, the Google communication suite, git based repositories like github and Bit-Bucket, automation tools like Jenkins, ticketing systems like Jira and so many others. By galvanizing these tools through one cohesive UI, ISD improves visibility for the entire team and allows each individual member to know the health of their application. In addition to this, ISD offers a scalable policy enforcement system by using the Open Policy engine allowing for greater enforcement of organizational policies at larger scales. Automate key stages of pipelines: Integrating tools is just the beginning. Using OpsMx\u2019s Data and Intelligence module, you can use artificial intelligence to make optimal decisions without relying on human intervention. For example if you are performing a log analysis, comparing the old version of the software and new versions of a software, the artificial intelligence will automatically calculate the risk of the deployment and decide whether to deploy or not all without needing a human to intervene in the process. Make more informed decisions: As the saying goes, \u201cWhat gets measured gets managed.\u201d ISD provides users key insights into their application health including data such as the fastest pipeline, the slowest pipeline, any errors encountered. This enables a more centralized and detailed view of your application health. In addition to this, when manual decisions are required ISD automatically gathers information from relevant sources so that the user making the decision does not need to look for that information and can make a faster decision. Whether you use Argo or another CD platform, the Data and Intelligence module AKA, Autopilot, is available stand alone.","title":"OpsMx Intelligent Software Delivery Platform"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/#opsmx-intelligent-software-delivery-platform","text":"OpsMx\u2019s ISD is designed to help release software faster, with fewer errors and with minimal human intervention to create a better end customer experience and free up time and Manpower for businesses to scale and Innovate. ISD allows you to:","title":"OpsMx Intelligent Software Delivery Platform"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/#build-flexible-deployment-pipelines-for-multiple-cloud-environments","text":"Using ISD\u2019s Orchestration Module, OpsMx builds off of Spinnaker, the premier open source multi cloud deployment solution, by providing users with extra layers of data and information to make better decisions. For example, Spinnaker does not have clear distinctions between the application and the various services and microservices that make up that application. ISD however allows users to easily see the various services and microservices that make up each application and the pipelines that make up each individual service and microservice. This allows you to easier see dependencies between service pipelines and as a result help you optimize your workflow. Whether used as an On-prem or a Managed SaaS solution, the orchestration module offers a host of other features like: Self Service onboarding: ISD allows users to serve themselves whether it is adding a new tool, cluster or pipeline, ISD allows users to serve themselves. Pipelines as code: While Spinnaker gives users visual representations of your pipelines so that you can see how your deployment stages might playout, ISD allows you to maintain your pipelines as JSON files which allows you to easily store them as, modify them and repurpose them using any Git-based repository, saving your team time and your business money. Infrastructure as code: As customers demand more from their CI/CD tools, the infrastructure has to be able to scale to meet those requirements. ISD allows you to use tools like Terraform to have your infrastructure like Servers available as code. This allows you to easily scale your application and, as a result, your business without having to worry as much about infrastructure costs.","title":"Build Flexible deployment pipelines for multiple cloud environments"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/#increase-compliance-and-communication-across-your-development-and-operations-teams","text":"Using our Pluggable data layer, ISD supports over 40+ integrations with various tools that cover each and every stage of software development and operation no matter your team size or work flow. It supports communication with tools like Slack, the Google communication suite, git based repositories like github and Bit-Bucket, automation tools like Jenkins, ticketing systems like Jira and so many others. By galvanizing these tools through one cohesive UI, ISD improves visibility for the entire team and allows each individual member to know the health of their application. In addition to this, ISD offers a scalable policy enforcement system by using the Open Policy engine allowing for greater enforcement of organizational policies at larger scales.","title":"Increase compliance and communication across your development and operations teams:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/#automate-key-stages-of-pipelines","text":"Integrating tools is just the beginning. Using OpsMx\u2019s Data and Intelligence module, you can use artificial intelligence to make optimal decisions without relying on human intervention. For example if you are performing a log analysis, comparing the old version of the software and new versions of a software, the artificial intelligence will automatically calculate the risk of the deployment and decide whether to deploy or not all without needing a human to intervene in the process.","title":"Automate key stages of pipelines:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform/#make-more-informed-decisions","text":"As the saying goes, \u201cWhat gets measured gets managed.\u201d ISD provides users key insights into their application health including data such as the fastest pipeline, the slowest pipeline, any errors encountered. This enables a more centralized and detailed view of your application health. In addition to this, when manual decisions are required ISD automatically gathers information from relevant sources so that the user making the decision does not need to look for that information and can make a faster decision. Whether you use Argo or another CD platform, the Data and Intelligence module AKA, Autopilot, is available stand alone.","title":"Make more informed decisions:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/","text":"OpsMx Intelligent Software Delivery Platform OpsMx ISD OpsMx\u2019s ISD is designed to help release software faster, with fewer errors and with minimal human intervention to create a better end customer experience and free up time and Manpower for businesses to scale and Innovate. ISD allows you to do the following: Build Flexible deployment pipelines for multiple cloud environments Increase compliance and communication across your development and operations teams Automate key stages of pipelines Make more informed decisions Build Flexible deployment pipelines for multiple cloud environments: Using ISD\u2019s Orchestration Module, OpsMx builds off of Spinnaker, the premier open source multi cloud deployment solution, by providing users with extra layers of data and information to make better decisions. For example, Spinnaker does not have clear distinctions between the application and the various services and microservices that make up that application. ISD however allows users to easily see the various services and microservices that make up each application and the pipelines that make up each individual service and microservice. This allows you to easier see dependencies between service pipelines and as a result help you optimize your workflow. Whether used as an On-prem or a Managed SaaS solution, the orchestration module offers a host of other features like: Self Service onboarding: ISD allows users to serve themselves whether it is adding a new tool, cluster or pipeline, ISD allows users to serve themselves. Pipelines as code: While Spinnaker gives users visual representations of your pipelines so that you can see how your deployment stages might playout, ISD allows you to maintain your pipelines as JSON files which allows you to easily store them as, modify them and repurpose them using any Git-based repository, saving your team time and your business money. Infrastructure as code: As customers demand more from their CI/CD tools, the infrastructure has to be able to scale to meet those requirements. ISD allows you to use tools like Terraform to have your infrastructure like Servers available as code. This allows you to easily scale your application and, as a result, your business without having to worry as much about infrastructure costs. Increase compliance and communication across your development and operations teams: Using our Pluggable data layer, ISD supports over 40+ integrations with various tools that cover each and every stage of software development and operation no matter your team size or work flow. It supports communication with tools like Slack, the Google communication suite, git based repositories like github and Bit-Bucket, automation tools like Jenkins, ticketing systems like Jira and so many others. By galvanizing these tools through one cohesive UI, ISD improves visibility for the entire team and allows each individual member to know the health of their application. In addition to this, ISD offers a scalable policy enforcement system by using the Open Policy engine allowing for greater enforcement of organizational policies at larger scales. Automate key stages of pipelines: Integrating tools is just the beginning. Using OpsMx\u2019s Data and Intelligence module, you can use artificial intelligence to make optimal decisions without relying on human intervention. For example if you are performing a log analysis, comparing the old version of the software and new versions of a software, the artificial intelligence will automatically calculate the risk of the deployment and decide whether to deploy or not all without needing a human to intervene in the process. Make more informed decisions: As the saying goes, \u201cWhat gets measured gets managed.\u201d ISD provides users key insights into their application health including data such as the fastest pipeline, the slowest pipeline, any errors encountered. This enables a more centralized and detailed view of your application health. In addition to this, when manual decisions are required ISD automatically gathers information from relevant sources so that the user making the decision does not need to look for that information and can make a faster decision. Whether you use Argo or another CD platform, the Data and Intelligence module AKA, Autopilot, is available stand alone.","title":"OpsMx Intelligent Software Delivery Platform old"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#opsmx-intelligent-software-delivery-platform","text":"","title":"OpsMx Intelligent Software Delivery Platform"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#opsmx-isd","text":"OpsMx\u2019s ISD is designed to help release software faster, with fewer errors and with minimal human intervention to create a better end customer experience and free up time and Manpower for businesses to scale and Innovate. ISD allows you to do the following: Build Flexible deployment pipelines for multiple cloud environments Increase compliance and communication across your development and operations teams Automate key stages of pipelines Make more informed decisions","title":"OpsMx ISD"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#build-flexible-deployment-pipelines-for-multiple-cloud-environments","text":"Using ISD\u2019s Orchestration Module, OpsMx builds off of Spinnaker, the premier open source multi cloud deployment solution, by providing users with extra layers of data and information to make better decisions. For example, Spinnaker does not have clear distinctions between the application and the various services and microservices that make up that application. ISD however allows users to easily see the various services and microservices that make up each application and the pipelines that make up each individual service and microservice. This allows you to easier see dependencies between service pipelines and as a result help you optimize your workflow. Whether used as an On-prem or a Managed SaaS solution, the orchestration module offers a host of other features like: Self Service onboarding: ISD allows users to serve themselves whether it is adding a new tool, cluster or pipeline, ISD allows users to serve themselves. Pipelines as code: While Spinnaker gives users visual representations of your pipelines so that you can see how your deployment stages might playout, ISD allows you to maintain your pipelines as JSON files which allows you to easily store them as, modify them and repurpose them using any Git-based repository, saving your team time and your business money. Infrastructure as code: As customers demand more from their CI/CD tools, the infrastructure has to be able to scale to meet those requirements. ISD allows you to use tools like Terraform to have your infrastructure like Servers available as code. This allows you to easily scale your application and, as a result, your business without having to worry as much about infrastructure costs.","title":"Build Flexible deployment pipelines for multiple cloud environments:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#increase-compliance-and-communication-across-your-development-and-operations-teams","text":"Using our Pluggable data layer, ISD supports over 40+ integrations with various tools that cover each and every stage of software development and operation no matter your team size or work flow. It supports communication with tools like Slack, the Google communication suite, git based repositories like github and Bit-Bucket, automation tools like Jenkins, ticketing systems like Jira and so many others. By galvanizing these tools through one cohesive UI, ISD improves visibility for the entire team and allows each individual member to know the health of their application. In addition to this, ISD offers a scalable policy enforcement system by using the Open Policy engine allowing for greater enforcement of organizational policies at larger scales.","title":"Increase compliance and communication across your development and operations teams:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#automate-key-stages-of-pipelines","text":"Integrating tools is just the beginning. Using OpsMx\u2019s Data and Intelligence module, you can use artificial intelligence to make optimal decisions without relying on human intervention. For example if you are performing a log analysis, comparing the old version of the software and new versions of a software, the artificial intelligence will automatically calculate the risk of the deployment and decide whether to deploy or not all without needing a human to intervene in the process.","title":"Automate key stages of pipelines:"},{"location":"OpsMx%20Intelligent%20Software%20Delivery%20Platform_old/#make-more-informed-decisions","text":"As the saying goes, \u201cWhat gets measured gets managed.\u201d ISD provides users key insights into their application health including data such as the fastest pipeline, the slowest pipeline, any errors encountered. This enables a more centralized and detailed view of your application health. In addition to this, when manual decisions are required ISD automatically gathers information from relevant sources so that the user making the decision does not need to look for that information and can make a faster decision. Whether you use Argo or another CD platform, the Data and Intelligence module AKA, Autopilot, is available stand alone.","title":"Make more informed decisions:"},{"location":"Orchestration%20Module%20-%20OpsMx%20Enterprise%20for%20Spinnaker%20%28OES%29/","text":"Orchestration Module - OpsMx Enterprise for Spinnaker (OES) OpsMx Enterprise for Spinnaker is the orchestration module of ISD and the module that provides an extra layer of abstraction and information so that your development team can use Spinnaker more efficiently and as a result, minimize the friction that would normally occur during a development cycle. OpsMx Enterprise for Spinnaker is Scalable & Extensible: Spinnaker is scalable, extensible & battle tested with release workflow orchestration, multi-cloud deployments and automated roll-backs. Simple & Secure: Enterprise extensions increase simplicity, security & scale. Intelligent: OpsMx Autopilot automated release verification, continuous governance and policy, real time approvals and enterprise wide traceability and insights. The key benefits you would see as a result are: 1. Faster deployments: An enterprise-ready distribution and expert onboarding services speeds up the development process radically allowing you to get your application to deployment sooner. Reduced cost and increase ROI: OES with included onboard and support services lowers TCO compared to a DIY (do-it-yourself) approach. Reduced errors & outages: Expert configuration, support and application of pre-built best practices and deployment strategies reduce outages from failed deployments. Better security & compliance: OES provides a hardened Spinnaker with pre-configured security best practices & fast fixes of security vulnerabilities, resulting in reduced misconfiguration errors and faster issue resolution. Reduced Business Risk: Access to OpsMx experts, pre-configured best practices, and 24*7 support helps mitigate operational and risks commonly associated with open source. No Vendor Lock-in: OES is pluggable on top of open source Spinnaker, so you\u2019re never locked into a vendor\u2019s proprietary distribution.","title":"Orchestration Module   OpsMx Enterprise for Spinnaker (OES)"},{"location":"Orchestration%20Module%20-%20OpsMx%20Enterprise%20for%20Spinnaker%20%28OES%29/#orchestration-module-opsmx-enterprise-for-spinnaker-oes","text":"OpsMx Enterprise for Spinnaker is the orchestration module of ISD and the module that provides an extra layer of abstraction and information so that your development team can use Spinnaker more efficiently and as a result, minimize the friction that would normally occur during a development cycle. OpsMx Enterprise for Spinnaker is Scalable & Extensible: Spinnaker is scalable, extensible & battle tested with release workflow orchestration, multi-cloud deployments and automated roll-backs. Simple & Secure: Enterprise extensions increase simplicity, security & scale. Intelligent: OpsMx Autopilot automated release verification, continuous governance and policy, real time approvals and enterprise wide traceability and insights. The key benefits you would see as a result are: 1. Faster deployments: An enterprise-ready distribution and expert onboarding services speeds up the development process radically allowing you to get your application to deployment sooner. Reduced cost and increase ROI: OES with included onboard and support services lowers TCO compared to a DIY (do-it-yourself) approach. Reduced errors & outages: Expert configuration, support and application of pre-built best practices and deployment strategies reduce outages from failed deployments. Better security & compliance: OES provides a hardened Spinnaker with pre-configured security best practices & fast fixes of security vulnerabilities, resulting in reduced misconfiguration errors and faster issue resolution. Reduced Business Risk: Access to OpsMx experts, pre-configured best practices, and 24*7 support helps mitigate operational and risks commonly associated with open source. No Vendor Lock-in: OES is pluggable on top of open source Spinnaker, so you\u2019re never locked into a vendor\u2019s proprietary distribution.","title":"Orchestration Module - OpsMx Enterprise for Spinnaker (OES)"},{"location":"Overview/","text":"Overview A quick history: As customers are growing to demand faster, higher quality services, modern businesses are growing to adopt cloud native architecture, modernized continuous delivery and infrastructure automation for their services. By breaking up otherwise large and monolithic applications into smaller, containerized, microservices, organizations can release a higher volume of smaller changes thereby rapidly increasing the quality and scalability of their applications to serve more customers with a better application overall. However, creating a system for secure and continuous application delivery that scales for multiple cloud environments is a daunting task even for organizations that can afford to hire the best engineers on the market. Oftentimes those teams will be stretched thin as organizations scale their cloud development infrastructure. As Organizations add more code bases and services, the risk and complexity of this task will only increase. Overview To tackle this problem, OpsMx has created the intelligent software delivery system (ISD). The goal is simple: eliminate human intervention from the software delivery process. And get your application released faster, safer and more secure than before. The ISD is highly scalable and leverages Spinnaker for multi-cloud orchestration. Its modular architecture gives you the choice of full-stack deployment automation with Spinnaker or extending your current CD platform with ISD\u2019s Intelligence and Data module. ISD consists of the following two modules: OpsMx Enterprise for Spinnaker (OES): OES is the C module that simplifies the difficulty of orchestrating the end-to-end process workflow from code-checking to safe multi-cloud deployments. OpsMx Autopilot: OpsMx Autopilot is the Data & Intelligence module that provides insightful data-driven risk verification, policy enforcement, and approvals to ensure quality, risk-free and compliant software in production. Key Benefits Accelerate the velocity of software delivery by replacing manual scripts with automated workflows that scale across multi-cloud environments. Release software safely and reliably by deploying applications quickly and safely using Canary or Blue-Green. Make data-driven decisions across all stages of a deployment pipeline. Minimize risk of production failures by automatically determining the risk of every software before moving it to production. Ensure security and compliance by mitigating risk and vulnerabilities through policy enforced pipelines. Remove maintenance and operations burden with the OpsMx ISD which is also available in SaaS option. ISD consists of the following two modules. Hyper link_internal Hyper link_internal","title":"Overview"},{"location":"Overview/#overview","text":"","title":"Overview"},{"location":"Overview/#a-quick-history","text":"As customers are growing to demand faster, higher quality services, modern businesses are growing to adopt cloud native architecture, modernized continuous delivery and infrastructure automation for their services. By breaking up otherwise large and monolithic applications into smaller, containerized, microservices, organizations can release a higher volume of smaller changes thereby rapidly increasing the quality and scalability of their applications to serve more customers with a better application overall. However, creating a system for secure and continuous application delivery that scales for multiple cloud environments is a daunting task even for organizations that can afford to hire the best engineers on the market. Oftentimes those teams will be stretched thin as organizations scale their cloud development infrastructure. As Organizations add more code bases and services, the risk and complexity of this task will only increase.","title":"A quick history:"},{"location":"Overview/#overview_1","text":"To tackle this problem, OpsMx has created the intelligent software delivery system (ISD). The goal is simple: eliminate human intervention from the software delivery process. And get your application released faster, safer and more secure than before. The ISD is highly scalable and leverages Spinnaker for multi-cloud orchestration. Its modular architecture gives you the choice of full-stack deployment automation with Spinnaker or extending your current CD platform with ISD\u2019s Intelligence and Data module.","title":"Overview"},{"location":"Overview/#isd-consists-of-the-following-two-modules","text":"","title":"ISD consists of the following two modules:"},{"location":"Overview/#opsmx-enterprise-for-spinnaker-oes","text":"OES is the C module that simplifies the difficulty of orchestrating the end-to-end process workflow from code-checking to safe multi-cloud deployments.","title":"OpsMx Enterprise for Spinnaker (OES):"},{"location":"Overview/#opsmx-autopilot","text":"OpsMx Autopilot is the Data & Intelligence module that provides insightful data-driven risk verification, policy enforcement, and approvals to ensure quality, risk-free and compliant software in production.","title":"OpsMx Autopilot:"},{"location":"Overview/#key-benefits","text":"Accelerate the velocity of software delivery by replacing manual scripts with automated workflows that scale across multi-cloud environments. Release software safely and reliably by deploying applications quickly and safely using Canary or Blue-Green. Make data-driven decisions across all stages of a deployment pipeline. Minimize risk of production failures by automatically determining the risk of every software before moving it to production. Ensure security and compliance by mitigating risk and vulnerabilities through policy enforced pipelines. Remove maintenance and operations burden with the OpsMx ISD which is also available in SaaS option. ISD consists of the following two modules. Hyper link_internal Hyper link_internal","title":"Key Benefits"},{"location":"Promethues%20and%20Kubernetes/","text":"Promethues and Kubernetes How to do Automated Canary Analysis for Kubernetes and Prometheus Spinnaker automated canary analysis tool ( Kayenta ) has been available starting with version 1.7. In this blog we will cover how to setup Kayenta for a Kubernetes provider with Prometheus being used for monitoring. Background: Canary deployments has been one of the best practices in the software delivery for some time now. The reason for doing Canary deployment is to reduce the risk of introducing new update with issues to 100 % of the customers like American Airline did and resulted in all their airplanes grounded for 6 hours . Automated canary analysis is way to use automation to detecting issues with the new software using the metrics generated by the new application and comparing to the current production version. Netflix and Google has teamed up to release an open source version of this analysis tool called Kayenta and make it available as part of the Spinnaker project. Note that the Kayenta architecture is designed in a modular fashion allowing for use of 3rd party or custom judges created by the users. For more information about Kayenta architecture, watch the recent meetup from the architect of Kayenta Steps to Enable Kayenta for Kubernetes and Prometheus Kayenta supports the following monitoring services - Stackdriver, Prometheus and DataDog. You can deploy Kayenta to Kubernetes running on AWS. In our case, we have Spinnaker instance deploying to Kubernetes running on AWS. Prometheus is the monitoring service used for service level metrics monitoring (Tomcat service). Let\u2019s begin Step 1: Enable Canary Ensure that you are running 1.7 or later version of the Spinnaker software. You can use the following command to ve rify your spinnaker version. hal config version If you are running prior version, make sure you upgrade the version to the latest version and try again. You can use the following command. hal config version edit --version 1.7.6 Then use the below command to enable Canary analysis option for all applications. You can turn off canary availability option for individual applications as desired. hal config canary enable Step 2: Enable Storage for Canary Canary needs a storage account to store the canary data such as canary configurations and time series data retrieved from metric stores. If you need help configuring a storage account, check documentation . Enable the default storage account with the following command. hal config canary edit --default-storage-account ACCOUNTName --bucket StorageBucketName --root-folder RootFolderlName For example: hal config canary edit --default-storage-account aws-s3-kayenta --bucket kayentasetup --root-folder kayenta Step 3: Enable Prometheus Monitoring Service Integration Next, we have to enable for Kayenta to able to read Prometheus metric store. Authentication for prometheus is not enabled in the given example. However, it can be setup easily if authentication at Prometheus is enabled. Use the following command to enable Prometheus metric store hal config canary prometheus enable hal config canary prometheus account add ACCOUNTName --base-url ENDPointOfPrometheus For example: hal config canary prometheus account add prometheus-account --base-url http://a23f9cc3537ee12345678910-655574421.us-east-2.elb.amazonaws.com:9090 hal config canary edit --default-metric-account ACCOUNTName For example: hal config canary edit --default-metric-account prometheus-account Step 4: Create Canary Config Add canary config in the form of metric template of your monitoring data store (Prometheus) Click on canary config page under delivery tab on application tab as shown below. (Image-1) Image-1 After that, click on \u2018 Add Configuration \u2019, \u2018Add configuration name and description\u2019. Click on \u2018 Add Metric \u2019, which will result in a pop-up as shown below. Image-2 Add Name and Metric name: We need to add a filter template in the case of kubernete cluster because pod names are saved in the format - container_label_{your pod name} in the Prometheus server. So for the filter template, be sure to attach the \u201ccontainer_label_\u201d string before your pod name which you will give in the canary analysis stage in pipeline and spinnaker will use internally to query metric data from the Prometheus server. Label Bindings are another way to filter metrics for aggregation. Internally, if the query to Prometheus results in more than one metric (due to multiple tags/dimensions that match metric name) then they are averaged to form one series of data. Labels allow filtering to support only the required tags to be used in generating metric time series. This is also a simple way to utilize labels assigned to Kubernetes pods to select in metric time series query. In summary, before adding anything in this pop up template, Add template in filter templates button (image-1) and then come to this pop up, configure metric and attached filter template. Direction: Customize for change in higher or lower values. For example, measuring throughput, higher is acceptable, however, for latency lower is acceptable Filter templates allow customization of metrics to use in canary analysis. Some implicit binding variables available in filter templates are scope, project, location, and resource Type. Filter templates allow literal bindings along with variable bindings. For example, in Prometheus metrics, if only cpu idle time is of interest then a literal filter can be set to filter only idle time and not utilization. Another example is when the canary comparison is using a single pod and not the entire server group then the filter can be specified as shown in image-3. Click on Add template under filter template section on canary configuration. Image-3 ${scope} will fill with baseline and canary version dynamically i.e. pod name of your Kubernetes cluster. Now you are done with the canary configuration. Image-4 Image-5 Image-6 Step 5: Run the pipeline / Get scores and Review the scores Over \u2018Canary reports\u2019 tab, under the \u2018delivery tab\u2019 on application page one can see the reports of metrics which we configured in the canary config. Image-7 Image-8","title":"Promethues and Kubernetes"},{"location":"Promethues%20and%20Kubernetes/#promethues-and-kubernetes","text":"","title":"Promethues and Kubernetes"},{"location":"Promethues%20and%20Kubernetes/#how-to-do-automated-canary-analysis-for-kubernetes-and-prometheus","text":"Spinnaker automated canary analysis tool ( Kayenta ) has been available starting with version 1.7. In this blog we will cover how to setup Kayenta for a Kubernetes provider with Prometheus being used for monitoring.","title":"How to do Automated Canary Analysis for Kubernetes and Prometheus"},{"location":"Promethues%20and%20Kubernetes/#background","text":"Canary deployments has been one of the best practices in the software delivery for some time now. The reason for doing Canary deployment is to reduce the risk of introducing new update with issues to 100 % of the customers like American Airline did and resulted in all their airplanes grounded for 6 hours . Automated canary analysis is way to use automation to detecting issues with the new software using the metrics generated by the new application and comparing to the current production version. Netflix and Google has teamed up to release an open source version of this analysis tool called Kayenta and make it available as part of the Spinnaker project. Note that the Kayenta architecture is designed in a modular fashion allowing for use of 3rd party or custom judges created by the users. For more information about Kayenta architecture, watch the recent meetup from the architect of Kayenta","title":"Background:"},{"location":"Promethues%20and%20Kubernetes/#steps-to-enable-kayenta-for-kubernetes-and-prometheus","text":"Kayenta supports the following monitoring services - Stackdriver, Prometheus and DataDog. You can deploy Kayenta to Kubernetes running on AWS. In our case, we have Spinnaker instance deploying to Kubernetes running on AWS. Prometheus is the monitoring service used for service level metrics monitoring (Tomcat service). Let\u2019s begin","title":"Steps to Enable Kayenta for Kubernetes and Prometheus"},{"location":"Promethues%20and%20Kubernetes/#step-1-enable-canary","text":"Ensure that you are running 1.7 or later version of the Spinnaker software. You can use the following command to ve rify your spinnaker version. hal config version If you are running prior version, make sure you upgrade the version to the latest version and try again. You can use the following command. hal config version edit --version 1.7.6 Then use the below command to enable Canary analysis option for all applications. You can turn off canary availability option for individual applications as desired. hal config canary enable","title":"Step 1: Enable Canary"},{"location":"Promethues%20and%20Kubernetes/#step-2-enable-storage-for-canary","text":"Canary needs a storage account to store the canary data such as canary configurations and time series data retrieved from metric stores. If you need help configuring a storage account, check documentation . Enable the default storage account with the following command. hal config canary edit --default-storage-account ACCOUNTName --bucket StorageBucketName --root-folder RootFolderlName For example: hal config canary edit --default-storage-account aws-s3-kayenta --bucket kayentasetup --root-folder kayenta","title":"Step 2: Enable Storage for Canary"},{"location":"Promethues%20and%20Kubernetes/#step-3-enable-prometheus-monitoring-service-integration","text":"Next, we have to enable for Kayenta to able to read Prometheus metric store. Authentication for prometheus is not enabled in the given example. However, it can be setup easily if authentication at Prometheus is enabled. Use the following command to enable Prometheus metric store hal config canary prometheus enable hal config canary prometheus account add ACCOUNTName --base-url ENDPointOfPrometheus For example: hal config canary prometheus account add prometheus-account --base-url http://a23f9cc3537ee12345678910-655574421.us-east-2.elb.amazonaws.com:9090 hal config canary edit --default-metric-account ACCOUNTName For example: hal config canary edit --default-metric-account prometheus-account","title":"Step 3: Enable Prometheus Monitoring Service Integration"},{"location":"Promethues%20and%20Kubernetes/#step-4-create-canary-config","text":"Add canary config in the form of metric template of your monitoring data store (Prometheus) Click on canary config page under delivery tab on application tab as shown below. (Image-1) Image-1 After that, click on \u2018 Add Configuration \u2019, \u2018Add configuration name and description\u2019. Click on \u2018 Add Metric \u2019, which will result in a pop-up as shown below. Image-2 Add Name and Metric name: We need to add a filter template in the case of kubernete cluster because pod names are saved in the format - container_label_{your pod name} in the Prometheus server. So for the filter template, be sure to attach the \u201ccontainer_label_\u201d string before your pod name which you will give in the canary analysis stage in pipeline and spinnaker will use internally to query metric data from the Prometheus server. Label Bindings are another way to filter metrics for aggregation. Internally, if the query to Prometheus results in more than one metric (due to multiple tags/dimensions that match metric name) then they are averaged to form one series of data. Labels allow filtering to support only the required tags to be used in generating metric time series. This is also a simple way to utilize labels assigned to Kubernetes pods to select in metric time series query. In summary, before adding anything in this pop up template, Add template in filter templates button (image-1) and then come to this pop up, configure metric and attached filter template. Direction: Customize for change in higher or lower values. For example, measuring throughput, higher is acceptable, however, for latency lower is acceptable Filter templates allow customization of metrics to use in canary analysis. Some implicit binding variables available in filter templates are scope, project, location, and resource Type. Filter templates allow literal bindings along with variable bindings. For example, in Prometheus metrics, if only cpu idle time is of interest then a literal filter can be set to filter only idle time and not utilization. Another example is when the canary comparison is using a single pod and not the entire server group then the filter can be specified as shown in image-3. Click on Add template under filter template section on canary configuration. Image-3 ${scope} will fill with baseline and canary version dynamically i.e. pod name of your Kubernetes cluster. Now you are done with the canary configuration. Image-4 Image-5 Image-6","title":"Step 4: Create Canary Config"},{"location":"Promethues%20and%20Kubernetes/#step-5-run-the-pipeline-get-scores-and-review-the-scores","text":"Over \u2018Canary reports\u2019 tab, under the \u2018delivery tab\u2019 on application page one can see the reports of metrics which we configured in the canary config. Image-7 Image-8","title":"Step 5: Run the pipeline / Get scores and Review the scores"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/","text":"Routing Web URLs to ISD services Routing Web URLs to ISD services Intelligent Software Deliver (ISD) is a web-application used for state-of-the-art DevOps Delivery. It is accessed using a web browser such as Chrome, Safari, etc. and it allows you to build, deploy and manage web applications to multiple cloud providers. This document describes various options for routing the web traffic from the browser to the ISD services. Summary of terminologies URL: This is a string we type in the browser to access any web-application via a network connected laptop/computer. It consists of 3 main components: http/https (secure http), host-name and path. For example, https://opsmx.com/contac consists of the host \u201copsmx.com\u201d (\u201cwhere to go\u201d), and \u201c/contact\u201d (where specifically in the site). DNS: Domain Name service/server, that translates the \u201chost name\u201d component of the URL into an \u201cIP\u201d address, a 4-byte number, as all network devices understand only an IP address. Load Balancer: This is the entry point of all network traffic into the Cloud/On-prem system. Kubernetes cluster: This is an isolated environment for running various services (typically microservices) that together make an application. ISD is an application consisting of 10-20 micro-services depending on the configuration. Kubernetes service: Kubernetes(AKA Kubernetes) has defined \u201cservice\u201d as an object that is a fixed end-point for network traffic. The service forwards the traffic to the appropriate micro-services. Ingress: It is a k8s object that specifically defines \u201chow\u201d traffic is to be routed based on the URL typed by the user, such as the hostname and path components of the URL. Ingress Controller: This is the application that honors the \u201cIngress\u201d objects created in the cluster i.e it actually handles the network traffic routing based on the directions given in the Ingress Object. Generally, only one Ingress Controller is required for one Kubernetes cluster. NodePort: This is a network port that allows external traffic into the kubernetes cluster. This is generally not required unless we have on-prem hardware.(The Nodeport allows external traffic into the Kubernetes cluster. This is generally not needed unless we are installing ISD on-prem). TLS Termination: When using a httpS (secure) protocol, all network traffic is encrypted and decrypted using \u201ccertificates\u201d. Backend services do NOT use httpS. They use the less secure \u201chttp\u201d as all the traffic is with-in the cluster and the cluster network is assumed to be trusted. Hence, the incoming traffic from the browser (httpS) needs to be decrypted and forwarded to backend services as http. Similarly, reverse traffic (response) needs to be encrypted before sending to the browser. This process is called TLS termination. ISD Routing Options Considerations ISD requires 3 end-points, i.e URLs that can reach the application services. Which of the 2 options are used in an installation depends on the following: TLS Certificates: httpS configuration requires generating TLS certificates that contain the \u201chost name\u201d component of the URL. Depending on your organisations\u2019 security policy, these certificates may need to be generated in a certain way and TLS termination to be done in a certain way. Options are: Install cert-manager, a free application that dynamically generates certificates as required. Default ISD installation assumes cert-manager to be installed in the cluster. Note that, for this to work, ISD needs to be reachable from the internet i.e. if you have a private corporate network, this may not be an option. Generate certificates using your companies infrastructure team\u2019s process, if available. For POV/Trial only, use http installation, (not httpS). Note that this might not be allowed by your company policy and may result in other security issues. Use self-signed certificates. For this to work, your laptop should have permissions to add a \u201cCertificate Authority\u201d or CA, and is generally allowed in most companies except large corporations that issue company-imaged laptops to employees. DNS: The URL typed into the browser needs to be translated into an IP address.In other words, users must have a DNS server like godaddy, AWS, route53 or cloudfare. During a POV/Trial only, In the event no DNS service is available, users can manually add host-entries in the laptop(s) that are being used to access the application. However, this is a last resort option. Ingress Controller: ISD default installation uses an Nginx ingress controller, which is very popular and scalable. We at OpsMx recommend this approach. Note that installing an Nginx Ingress controller requires one LoadBalancer to route the network traffic from the user to the k8s cluster, which is automatically created in most clouds. Cloud-provided ingressions may also be used. LoadBalancer(LB): Most people with AWS/GCP/Azure are experienced in routing traffic from LBs to k8s backend services.This may be the only option depending on the environment used and comfort level of the team-members. TLS Termination: Depending on the model used, TLS can be terminated either at the Loadbalancer(s) or at the Nginx Ingress controller. The default installation assumes TLS termination at the Nginx Ingress controller.","title":"Routing Web URLs to ISD services"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/#routing-web-urls-to-isd-services","text":"","title":"Routing Web URLs to ISD services"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/#routing-web-urls-to-isd-services_1","text":"Intelligent Software Deliver (ISD) is a web-application used for state-of-the-art DevOps Delivery. It is accessed using a web browser such as Chrome, Safari, etc. and it allows you to build, deploy and manage web applications to multiple cloud providers. This document describes various options for routing the web traffic from the browser to the ISD services.","title":"Routing Web URLs to ISD services"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/#summary-of-terminologies","text":"URL: This is a string we type in the browser to access any web-application via a network connected laptop/computer. It consists of 3 main components: http/https (secure http), host-name and path. For example, https://opsmx.com/contac consists of the host \u201copsmx.com\u201d (\u201cwhere to go\u201d), and \u201c/contact\u201d (where specifically in the site). DNS: Domain Name service/server, that translates the \u201chost name\u201d component of the URL into an \u201cIP\u201d address, a 4-byte number, as all network devices understand only an IP address. Load Balancer: This is the entry point of all network traffic into the Cloud/On-prem system. Kubernetes cluster: This is an isolated environment for running various services (typically microservices) that together make an application. ISD is an application consisting of 10-20 micro-services depending on the configuration. Kubernetes service: Kubernetes(AKA Kubernetes) has defined \u201cservice\u201d as an object that is a fixed end-point for network traffic. The service forwards the traffic to the appropriate micro-services. Ingress: It is a k8s object that specifically defines \u201chow\u201d traffic is to be routed based on the URL typed by the user, such as the hostname and path components of the URL. Ingress Controller: This is the application that honors the \u201cIngress\u201d objects created in the cluster i.e it actually handles the network traffic routing based on the directions given in the Ingress Object. Generally, only one Ingress Controller is required for one Kubernetes cluster. NodePort: This is a network port that allows external traffic into the kubernetes cluster. This is generally not required unless we have on-prem hardware.(The Nodeport allows external traffic into the Kubernetes cluster. This is generally not needed unless we are installing ISD on-prem). TLS Termination: When using a httpS (secure) protocol, all network traffic is encrypted and decrypted using \u201ccertificates\u201d. Backend services do NOT use httpS. They use the less secure \u201chttp\u201d as all the traffic is with-in the cluster and the cluster network is assumed to be trusted. Hence, the incoming traffic from the browser (httpS) needs to be decrypted and forwarded to backend services as http. Similarly, reverse traffic (response) needs to be encrypted before sending to the browser. This process is called TLS termination.","title":"Summary of terminologies"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/#isd-routing-options","text":"","title":"ISD Routing Options"},{"location":"Routing%20Web%20URLs%20to%20ISD%20services/#considerations","text":"ISD requires 3 end-points, i.e URLs that can reach the application services. Which of the 2 options are used in an installation depends on the following: TLS Certificates: httpS configuration requires generating TLS certificates that contain the \u201chost name\u201d component of the URL. Depending on your organisations\u2019 security policy, these certificates may need to be generated in a certain way and TLS termination to be done in a certain way. Options are: Install cert-manager, a free application that dynamically generates certificates as required. Default ISD installation assumes cert-manager to be installed in the cluster. Note that, for this to work, ISD needs to be reachable from the internet i.e. if you have a private corporate network, this may not be an option. Generate certificates using your companies infrastructure team\u2019s process, if available. For POV/Trial only, use http installation, (not httpS). Note that this might not be allowed by your company policy and may result in other security issues. Use self-signed certificates. For this to work, your laptop should have permissions to add a \u201cCertificate Authority\u201d or CA, and is generally allowed in most companies except large corporations that issue company-imaged laptops to employees. DNS: The URL typed into the browser needs to be translated into an IP address.In other words, users must have a DNS server like godaddy, AWS, route53 or cloudfare. During a POV/Trial only, In the event no DNS service is available, users can manually add host-entries in the laptop(s) that are being used to access the application. However, this is a last resort option. Ingress Controller: ISD default installation uses an Nginx ingress controller, which is very popular and scalable. We at OpsMx recommend this approach. Note that installing an Nginx Ingress controller requires one LoadBalancer to route the network traffic from the user to the k8s cluster, which is automatically created in most clouds. Cloud-provided ingressions may also be used. LoadBalancer(LB): Most people with AWS/GCP/Azure are experienced in routing traffic from LBs to k8s backend services.This may be the only option depending on the environment used and comfort level of the team-members. TLS Termination: Depending on the model used, TLS can be terminated either at the Loadbalancer(s) or at the Nginx Ingress controller. The default installation assumes TLS termination at the Nginx Ingress controller.","title":"Considerations"},{"location":"SaaS%20Trial%20Usage%20Instruction%20Video/","text":"SaaS Trial Usage Instruction Video Instruction Video Here's a short video that provides quick step-by-step instructions to experience the OpsMx ISD SaaS Trial:","title":"SaaS Trial Usage Instruction Video"},{"location":"SaaS%20Trial%20Usage%20Instruction%20Video/#saas-trial-usage-instruction-video","text":"","title":"SaaS Trial Usage Instruction Video"},{"location":"SaaS%20Trial%20Usage%20Instruction%20Video/#instruction-video","text":"Here's a short video that provides quick step-by-step instructions to experience the OpsMx ISD SaaS Trial:","title":"Instruction Video"},{"location":"Safe-Deployment%20strategies/","text":"Safe-Deployment strategies OES allows you to safely and consistently deploy applications in Kubernetes with built-in, ready-to-use deployment strategies such as Blue-Green, Canary, A/B, and Rolling Update. OES treats Kubernetes as first-class citizens and supports Kubernetes resources and operators for custom strategies. Canary and Blue-Green Deployment: Avoid production downtime and mitigate risk of introducing new software by using in-built strategies like Canary and Blue-Green deployments. OES has native istio support, which makes traffic splitting between various kubernetes pods such as baseline and canary. Custom Stages for Verification: OES allows DevOps managers to create custom stages in the deployment pipeline for verifying performance and quality of new software release in the production. Rollback: In case of any regression, OES can notify stakeholders like SRE who can automatically rollback to the previous version with a single click to avoid degradation of customer experience. Approvals Gates: DevOps managers can use the manual judgement stage in the pipeline where release managers can go through aggregated information to approve or reject deployment pipeline progression.","title":"Safe Deployment strategies"},{"location":"Safe-Deployment%20strategies/#safe-deployment-strategies","text":"OES allows you to safely and consistently deploy applications in Kubernetes with built-in, ready-to-use deployment strategies such as Blue-Green, Canary, A/B, and Rolling Update. OES treats Kubernetes as first-class citizens and supports Kubernetes resources and operators for custom strategies. Canary and Blue-Green Deployment: Avoid production downtime and mitigate risk of introducing new software by using in-built strategies like Canary and Blue-Green deployments. OES has native istio support, which makes traffic splitting between various kubernetes pods such as baseline and canary. Custom Stages for Verification: OES allows DevOps managers to create custom stages in the deployment pipeline for verifying performance and quality of new software release in the production. Rollback: In case of any regression, OES can notify stakeholders like SRE who can automatically rollback to the previous version with a single click to avoid degradation of customer experience. Approvals Gates: DevOps managers can use the manual judgement stage in the pipeline where release managers can go through aggregated information to approve or reject deployment pipeline progression.","title":"Safe-Deployment strategies"},{"location":"Scalable%20%26%20Extensible/","text":"Scalable & Extensible With OES, you can scale your software delivery as needed, deploying a nearly unlimited number of changes to multiple targets per day. OES is highly scalable for increasing deployment workloads, and extensible to integrate with multiple SDLC tool chains. OES allows you to have: Custom Stage for parallel deployment: OES allows you to easily-to-define custom stages that can take any number of targets and can invoke preconfigured delivery pipelines simultaneously for each of the targets. Each delivery pipeline will deploy to its own target environment or instance independently to save time. DevOps managers can take action such as rollback or roll forward to continue or stop the number of parallel pipeline executions at once. Nested Pipelines: DevOps managers now have the ability to create child pipelines for repeated activities in SDLC and invoke parent pipelines. This improves the re-usability of pipelines among various teams in your IT organization. Infrastructure Creation: OES allows you to use Spinnaker pipelines to create and tear down infrastructure in the runtime using provisioning tools like Terraform. Integrations: DevOps engineers can focus on deployment and delivery of applications instead of developing custom integration scripts. And since OES is based on Spinnaker it is easy to customize and extend any capability as per your organization's requirements. Modular Based: OES is modular and can act as a central CD tool for many enterprises because it uses an API-based architecture. Developers across the team can easily integrate external services with Spinnaker services.","title":"Scalable & Extensible"},{"location":"Scalable%20%26%20Extensible/#scalable-extensible","text":"With OES, you can scale your software delivery as needed, deploying a nearly unlimited number of changes to multiple targets per day. OES is highly scalable for increasing deployment workloads, and extensible to integrate with multiple SDLC tool chains. OES allows you to have: Custom Stage for parallel deployment: OES allows you to easily-to-define custom stages that can take any number of targets and can invoke preconfigured delivery pipelines simultaneously for each of the targets. Each delivery pipeline will deploy to its own target environment or instance independently to save time. DevOps managers can take action such as rollback or roll forward to continue or stop the number of parallel pipeline executions at once. Nested Pipelines: DevOps managers now have the ability to create child pipelines for repeated activities in SDLC and invoke parent pipelines. This improves the re-usability of pipelines among various teams in your IT organization. Infrastructure Creation: OES allows you to use Spinnaker pipelines to create and tear down infrastructure in the runtime using provisioning tools like Terraform. Integrations: DevOps engineers can focus on deployment and delivery of applications instead of developing custom integration scripts. And since OES is based on Spinnaker it is easy to customize and extend any capability as per your organization's requirements. Modular Based: OES is modular and can act as a central CD tool for many enterprises because it uses an API-based architecture. Developers across the team can easily integrate external services with Spinnaker services.","title":"Scalable &amp; Extensible"},{"location":"Trial%20User%20Guide/","text":"Trial User Guide Login ISD Instance This is your ISD Trial Instance's login page. Enter the User ID and Password that you received via email. Note If you have any issues, please contact us at opsmxsaashelp@opsmx.io. After you log in you will see the Application Dashboard (refer to the screenshot below). ISD SaaS Trial Workflow Application Dashboard We have created a sample application for you since this is a Trial version. It comes with a pre-configured pipeline that allows you to deploy a sample image directly into a target Kubernetes cluster. To do so, follow the steps below: After your successful login, the Application Dashboard appears and it gives you high-level overviews of your applications, pipelines along with the following important operational information: Total Applications - The number of applications which you have access to Deployments - The total number of deployments, from all the applications which you have access to Pipeline Failures - Any pipeline failures, in any of the applications which you have access to Pending Approvals - Any approvals which are pending for your action Policy Violations - Any policy violations, in any of the applications which you have access to Verification Failures - Any failures in the verification process within the applications which you have access to As seen in the above image, the total application count is 1. This means, you have access to only one application is the sample application we created for you in this ISD instance. To get a detailed view of your application, click on your application name. It will redirect you to the \" Pipeline Builder \" page and it displays the pipeline(s) and the gate(s) within your application. By default, your application comes with one pipeline called \" K8sdeploydemo \" and two gates, one is an \" Approval \u201d gate and the other is a \u201c Policy \u201d gate. To know more about Application Dashboard, refer here , and to know more about Gates, refer here . Application Deployment To trigger the deployment of a particular pipeline of your application, click the \u201c Start New Deployment \u201d button. In the \" Start New Deployment \" window, update the following parameters using the drop-down options. Application - This drop down lists all the applications you have access to. Select the application for which you are triggering the execution of the pipeline. Service/Pipeline - This drop down lists the pipeline for that application selected above. Select the pipeline which you intend to execute. Trigger - Will be updated automatically Type - Select the type as Tag or Digest Tags - Select the tags as v1 or v2 or v3 Note: For the sample application that comes bundled with this trial instance of ISD, since you have access to one application and the drop-down menu only displays that application. If you want to be notified by email when the pipeline execution is completed, select the check box \"Notify me when the pipeline completes\" and enter your email address. And then click the \u201c Run \u201d button to start your deployment. To know more about Deployment, refer here . After clicking on the \u201cRun\u201d button, It immediately triggers the execution of the pipeline and starts deploying the sample ImageID into the sample Kubernetes cluster. Both the sample image & the Kubernetes cluster comes bundled along with the trial instance of ISD. You'll be taken to the pipeline execution page, where you can see the pipeline's execution as it progresses from one stage to another. This pipeline has five stages as shown below: If you click the \" Pause \" button, your pipeline execution will be paused, and it will come to a halt at the specified stage. Click on the \u201c Resume execution \u201d button to continue your pipeline execution. To see the pipeline view, click on the \" Pipeline Builder \" button. The pipeline view shows the various stages of the pipeline and the parameters. You can modify the parameters on this page, but we suggest leaving them alone since this is a trial version of sample application. To know more about the pipeline, here . Once the pipeline has been executed, your approval gate will be waiting for you to approve or reject it. Click on \" Approval \" stage and then click \" Approval Request \" to approve or reject the approval gate. Click on the \" Git Repo \" file to see the configured parameters. This page displays the Application name, Pipeline name, Gate details, and the configured repository details. In this case approval gate is configured with Git Repository. You can check the parameters and approve the gate if everything looks good. If not, you have the option to reject it. Click the \u201c Approve \u201d or \u201c Reject \u201d button. You have the option to provide comments when approving or rejecting the gate. Note If the specified gate is approved, the pipeline execution will proceed to the next stage. If the specified gate is rejected, the pipeline will come to a halt. Your application's deployment has been completed successfully. As shown in the image below, there are no pending approvals, policy violations, or verification failures. The details can also be found on the pipeline execution page, as all of the stages have been completed successfully. Application Deployment Report After your application deployment, you can see the Deployment report. Click on \u201c Deployments \u201d to see the Application deployment details and the history. You can see the Application deployment details, such as the number of environments, pipeline, deployment time, initiate by, ImageID, and their status as shown in the image below. In the ISD SaaS Trial instance, users can create an Application, Integration, Policy, and Agents. To learn how to create, click on the links below. Application Integration Policy Agent Cloud Providers are restricted for ISD SaaS Trial users.","title":"Trial User Guide"},{"location":"Trial%20User%20Guide/#trial-user-guide","text":"","title":"Trial User Guide"},{"location":"Trial%20User%20Guide/#login-isd-instance","text":"This is your ISD Trial Instance's login page. Enter the User ID and Password that you received via email. Note If you have any issues, please contact us at opsmxsaashelp@opsmx.io. After you log in you will see the Application Dashboard (refer to the screenshot below).","title":"Login ISD Instance"},{"location":"Trial%20User%20Guide/#isd-saas-trial-workflow","text":"","title":"ISD SaaS Trial Workflow"},{"location":"Trial%20User%20Guide/#application-dashboard","text":"We have created a sample application for you since this is a Trial version. It comes with a pre-configured pipeline that allows you to deploy a sample image directly into a target Kubernetes cluster. To do so, follow the steps below: After your successful login, the Application Dashboard appears and it gives you high-level overviews of your applications, pipelines along with the following important operational information: Total Applications - The number of applications which you have access to Deployments - The total number of deployments, from all the applications which you have access to Pipeline Failures - Any pipeline failures, in any of the applications which you have access to Pending Approvals - Any approvals which are pending for your action Policy Violations - Any policy violations, in any of the applications which you have access to Verification Failures - Any failures in the verification process within the applications which you have access to As seen in the above image, the total application count is 1. This means, you have access to only one application is the sample application we created for you in this ISD instance. To get a detailed view of your application, click on your application name. It will redirect you to the \" Pipeline Builder \" page and it displays the pipeline(s) and the gate(s) within your application. By default, your application comes with one pipeline called \" K8sdeploydemo \" and two gates, one is an \" Approval \u201d gate and the other is a \u201c Policy \u201d gate. To know more about Application Dashboard, refer here , and to know more about Gates, refer here .","title":"Application Dashboard"},{"location":"Trial%20User%20Guide/#application-deployment","text":"To trigger the deployment of a particular pipeline of your application, click the \u201c Start New Deployment \u201d button. In the \" Start New Deployment \" window, update the following parameters using the drop-down options. Application - This drop down lists all the applications you have access to. Select the application for which you are triggering the execution of the pipeline. Service/Pipeline - This drop down lists the pipeline for that application selected above. Select the pipeline which you intend to execute. Trigger - Will be updated automatically Type - Select the type as Tag or Digest Tags - Select the tags as v1 or v2 or v3 Note: For the sample application that comes bundled with this trial instance of ISD, since you have access to one application and the drop-down menu only displays that application. If you want to be notified by email when the pipeline execution is completed, select the check box \"Notify me when the pipeline completes\" and enter your email address. And then click the \u201c Run \u201d button to start your deployment. To know more about Deployment, refer here . After clicking on the \u201cRun\u201d button, It immediately triggers the execution of the pipeline and starts deploying the sample ImageID into the sample Kubernetes cluster. Both the sample image & the Kubernetes cluster comes bundled along with the trial instance of ISD. You'll be taken to the pipeline execution page, where you can see the pipeline's execution as it progresses from one stage to another. This pipeline has five stages as shown below: If you click the \" Pause \" button, your pipeline execution will be paused, and it will come to a halt at the specified stage. Click on the \u201c Resume execution \u201d button to continue your pipeline execution. To see the pipeline view, click on the \" Pipeline Builder \" button. The pipeline view shows the various stages of the pipeline and the parameters. You can modify the parameters on this page, but we suggest leaving them alone since this is a trial version of sample application. To know more about the pipeline, here . Once the pipeline has been executed, your approval gate will be waiting for you to approve or reject it. Click on \" Approval \" stage and then click \" Approval Request \" to approve or reject the approval gate. Click on the \" Git Repo \" file to see the configured parameters. This page displays the Application name, Pipeline name, Gate details, and the configured repository details. In this case approval gate is configured with Git Repository. You can check the parameters and approve the gate if everything looks good. If not, you have the option to reject it. Click the \u201c Approve \u201d or \u201c Reject \u201d button. You have the option to provide comments when approving or rejecting the gate. Note If the specified gate is approved, the pipeline execution will proceed to the next stage. If the specified gate is rejected, the pipeline will come to a halt. Your application's deployment has been completed successfully. As shown in the image below, there are no pending approvals, policy violations, or verification failures. The details can also be found on the pipeline execution page, as all of the stages have been completed successfully.","title":"Application Deployment"},{"location":"Trial%20User%20Guide/#application-deployment-report","text":"After your application deployment, you can see the Deployment report. Click on \u201c Deployments \u201d to see the Application deployment details and the history. You can see the Application deployment details, such as the number of environments, pipeline, deployment time, initiate by, ImageID, and their status as shown in the image below. In the ISD SaaS Trial instance, users can create an Application, Integration, Policy, and Agents. To learn how to create, click on the links below. Application Integration Policy Agent Cloud Providers are restricted for ISD SaaS Trial users.","title":"Application Deployment Report"}]}